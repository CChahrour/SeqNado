{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"SeqNado","text":"<p>A Snakemake-based bioinformatics toolkit for analyzing sequencing data from ATAC-seq, ChIP-seq, CUT&amp;Tag, RNA-seq, SNP analysis, Methylation, CRISPR screens, and Micro-Capture-C experiments.</p> <p>Welcome to SeqNado! SeqNado is a powerful bioinformatics tool designed to simplify the analysis and integration of high-throughput sequencing data. It supports a wide range of sequencing assays and provides advanced features for multiomics data processing.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Multiomics Data Processing: Analyze and integrate data from multiple omics layers.</li> <li>Configurable Workflows: Predefined workflows for ATAC, ChIP, RNA, and more.</li> <li>Third-Party Tool Integration: Seamless integration with popular bioinformatics tools.</li> <li>Advanced Data Processing: Includes features like spike-in normalization, blacklist removal, and genome tiling.</li> </ul>"},{"location":"#supported-assays","title":"Supported Assays","text":"<p>SeqNado supports the following sequencing assays:</p> <ul> <li>ATAC-seq: Chromatin accessibility profiling.</li> <li>ChIP-seq: Protein-DNA interaction analysis.</li> <li>CRISPR: CRISPR screening analysis.</li> <li>CUT&amp;Tag: Epigenomic profiling.</li> <li>MCC: Micro Capture-C.</li> <li>Methylation: DNA methylation analysis.</li> <li>RNA-seq: Transcriptome analysis.</li> <li>SNP Analysis: Single nucleotide polymorphism detection.</li> </ul>"},{"location":"#use-cases","title":"Use Cases","text":"<p>SeqNado is ideal for:</p> <ul> <li>Researchers analyzing high-throughput sequencing data.</li> <li>Bioinformaticians integrating multiomics datasets.</li> <li>Labs requiring reproducible and scalable workflows.</li> </ul>"},{"location":"#additional-features","title":"Additional Features","text":"<p>SeqNado includes the following advanced capabilities:</p> <ul> <li>Spike-in Normalization: Calculate normalization factors for spike-in controls.</li> <li>Data Visualization: Generate publication-ready plots and figures.</li> <li>UCSC Hub Generation: Create UCSC genome browser hubs for data sharing.</li> <li>Genome Browser Plots: Generate visualizations for genome-wide data, including UCSC genome browser hubs.</li> <li>Quantification Methods: Comprehensive tools for read count quantification, grouped read counts, and combined read counts.</li> <li>Machine Learning Dataset Creation: Prepare datasets for machine learning applications.</li> <li>GEO/SRA Downloads: Download fastq files from GEO/SRA for processing.</li> </ul> <p>These features are fully customizable through configuration files, making SeqNado adaptable to a variety of research needs.</p>"},{"location":"#get-started","title":"Get Started","text":"<p>Follow the step-by-step guide to get up and running:</p> <ol> <li>Installation: Set up the SeqNado environment.</li> <li>Initialisation: Configure your local environment (CLI: seqnado init).</li> <li>Genome Setup: Manage reference genomes and indexes (CLI: seqnado genomes).</li> <li>Configuration: Define your experiment parameters (CLI: seqnado config).</li> <li>GEO/SRA Download: Download FASTQ files from public repositories (CLI: seqnado download).</li> <li>Design Guide: Create your sample metadata design (CLI: seqnado design).</li> <li>Pipeline Overview: Run the workflow (CLI: seqnado pipeline) and explore Outputs.</li> <li>Output Examples: See real example outputs from test data runs.</li> </ol> <p>For a quick end-to-end example, see the Quick Start guide.</p>"},{"location":"SUMMARY/","title":"SUMMARY","text":"<ul> <li>Home</li> <li>Getting Started<ul> <li>Quick Start</li> <li>Installation</li> <li>Initialisation</li> <li>Genome Setup</li> </ul> </li> <li>Usage<ul> <li>Configuration</li> <li>Design Guide</li> <li>GEO/SRA Download</li> <li>Pipeline Overview</li> <li>Outputs</li> <li>Output Examples</li> <li>Normalisation Methods</li> <li>Third-Party Tools</li> <li>CLI Reference</li> </ul> </li> <li>Reference<ul> <li>API Overview</li> <li>Core Types</li> <li>Configuration API</li> <li>Inputs API</li> <li>Outputs API</li> <li>Assay Configurations</li> <li>Tool Config Examples</li> <li>Citation Guidelines</li> </ul> </li> <li>Help<ul> <li>Troubleshooting</li> <li>HPC Clusters</li> <li>FAQ</li> </ul> </li> </ul>"},{"location":"assays/","title":"Assay-Specific Tool Configurations","text":"<p>This page shows which tools are automatically configured for each assay type when using the <code>for_assay()</code> factory method.</p>"},{"location":"assays/#assay-types","title":"Assay Types","text":""},{"location":"assays/#rna","title":"RNA","text":"<p>Tools configured: <code>bamnado</code>, <code>deeptools</code>, <code>fastqc</code>, <code>fastqscreen</code>, <code>homer</code>, <code>qualimap</code>, <code>salmon</code>, <code>samtools</code>, <code>star</code>, <code>subread</code>, <code>trimgalore</code></p> <p>RNA sequencing - measures gene expression levels</p>"},{"location":"assays/#atac","title":"ATAC","text":"<p>Tools configured: <code>bamnado</code>, <code>bowtie2</code>, <code>deeptools</code>, <code>fastqc</code>, <code>fastqscreen</code>, <code>homer</code>, <code>lanceotron</code>, <code>macs</code>, <code>meme</code>, <code>picard</code>, <code>qualimap</code>, <code>samtools</code>, <code>subread</code>, <code>trimgalore</code></p> <p>Assay for Transposase-Accessible Chromatin - identifies open chromatin regions</p>"},{"location":"assays/#snp","title":"SNP","text":"<p>Tools configured: <code>bcftools</code>, <code>bowtie2</code>, <code>fastqc</code>, <code>fastqscreen</code>, <code>qualimap</code>, <code>samtools</code>, <code>trimgalore</code></p> <p>Single Nucleotide Polymorphism analysis - identifies genetic variants</p>"},{"location":"assays/#chip","title":"CHIP","text":"<p>Tools configured: <code>bamnado</code>, <code>bowtie2</code>, <code>deeptools</code>, <code>fastqc</code>, <code>fastqscreen</code>, <code>homer</code>, <code>lanceotron</code>, <code>macs</code>, <code>meme</code>, <code>picard</code>, <code>qualimap</code>, <code>samtools</code>, <code>subread</code>, <code>trimgalore</code></p> <p>Chromatin Immunoprecipitation sequencing - maps protein-DNA interactions</p>"},{"location":"assays/#cuttag","title":"CUT&amp;TAG","text":"<p>Tools configured: <code>bamnado</code>, <code>bowtie2</code>, <code>deeptools</code>, <code>fastqc</code>, <code>fastqscreen</code>, <code>homer</code>, <code>lanceotron</code>, <code>macs</code>, <code>meme</code>, <code>picard</code>, <code>qualimap</code>, <code>samtools</code>, <code>seacr</code>, <code>subread</code>, <code>trimgalore</code></p>"},{"location":"assays/#meth","title":"METH","text":"<p>Tools configured: <code>bowtie2</code>, <code>fastqc</code>, <code>fastqscreen</code>, <code>methyldackel</code>, <code>picard</code>, <code>qualimap</code>, <code>samtools</code>, <code>trimgalore</code></p> <p>DNA methylation analysis - maps methylation patterns</p>"},{"location":"assays/#mcc","title":"MCC","text":"<p>Tools configured: <code>bamnado</code>, <code>bowtie2</code>, <code>deeptools</code>, <code>fastqc</code>, <code>fastqscreen</code>, <code>lanceotronmcc</code>, <code>qualimap</code>, <code>samtools</code>, <code>trimgalore</code></p>"},{"location":"assays/#crispr","title":"CRISPR","text":"<p>Tools configured: <code>bowtie2</code>, <code>cutadapt</code>, <code>fastqc</code>, <code>fastqscreen</code>, <code>mageck</code>, <code>qualimap</code>, <code>qualimap</code>, <code>samtools</code>, <code>subread</code></p> <p>CRISPR screening analysis - analyzes guide RNA performance</p>"},{"location":"assays/#multiomics","title":"MULTIOMICS","text":"<p>Tools configured: </p>"},{"location":"citation/","title":"Citation Guidelines","text":"<p>When publishing results from SeqNado, please cite:</p> <ol> <li>SeqNado itself (citation pending - check GitHub releases for latest version)</li> <li>Key tools used in your specific analysis (see References section below)</li> <li>Snakemake workflow manager: M\u00f6lder F, Jablonski KP, Letcher B, et al. Sustainable data analysis with Snakemake. F1000Research. 2021;10:33.</li> <li>Reference genomes used (e.g., hg38, mm10)</li> </ol>"},{"location":"citation/#example-acknowledgment","title":"Example Acknowledgment","text":"<p>\"Data analysis was performed using SeqNado v1.0.2 (Chahrour, C and Smith, AL, 2024), which incorporates Bowtie2 (Langmead &amp; Salzberg, 2012) for alignment, MACS2 (Zhang et al., 2008) for peak calling, and deepTools (Ram\u00edrez et al., 2016) for coverage track generation. Workflows were managed with Snakemake (M\u00f6lder et al., 2021) within Apptainer containers.\"</p>"},{"location":"citation/#tools","title":"Tools","text":"<p>Tools are organized by category, matching the structure of the <code>seqnado tools</code> CLI command. For more information about any tool, use <code>seqnado tools &lt;toolname&gt;</code>.</p>"},{"location":"citation/#download","title":"Download","text":""},{"location":"citation/#sra-toolkit-fasterq-dump","title":"SRA Toolkit (fasterq-dump)","text":"<p>Purpose: Fast extraction of sequences from SRA files Version: 3.0.10 Usage: Download sequencing data from NCBI Sequence Read Archive Reference: National Center for Biotechnology Information. SRA Toolkit: Sequence Read Archive tools and libraries. 2023. https://github.com/ncbi/sra-tools.</p>"},{"location":"citation/#quality-control","title":"Quality Control","text":""},{"location":"citation/#fastq-screen","title":"FastQ Screen","text":"<p>Purpose: Screen sequencing reads against a set of databases Version: 0.16.0 Usage: Screen reads against multiple reference genomes Reference: Steven W. Wingett and Simon Andrews. FastQ Screen: A tool for multi-genome mapping and quality control. F1000Research, 7(1338):1338, 2018. https://doi.org/10.12688/f1000research.15931.2</p>"},{"location":"citation/#fastqc","title":"FastQC","text":"<p>Purpose: Quality control for high-throughput sequencing data Version: 0.12.1 Usage: Generate quality metrics for sequencing data Reference: Simon Andrews. FastQC. 2010. https://www.bioinformatics.babraham.ac.uk/projects/fastqc/.</p>"},{"location":"citation/#qualimap","title":"Qualimap","text":"<p>Purpose: Quality assessment tool for next-generation sequencing data Version: 2.3 Usage: Compute alignment metrics and coverage statistics Reference: Konstantin Okonechnikov, Ana Conesa, and Fernando Garc\u00eda-Alcalde. Qualimap 2: advanced multi-sample quality control for high-throughput sequencing data. Bioinformatics, 32(2):292\u2013294, 2016. https://doi.org/10.1093/bioinformatics/btv566</p>"},{"location":"citation/#preprocessing","title":"Preprocessing","text":""},{"location":"citation/#cutadapt","title":"Cutadapt","text":"<p>Purpose: Remove adapter sequences from sequencing reads Version: 5.1 Usage: Remove adapter sequences and trim low-quality bases Reference: Marcel Martin. Cutadapt removes adapter sequences from high-throughput sequencing reads. EMBnet.journal, 17(1):10\u201312, 2011. https://doi.org/10.14806/ej.17.1.200</p>"},{"location":"citation/#flash","title":"FLASH","text":"<p>Purpose: Fast length adjustment of short reads (FLASH) to improve genome assemblies Version: 1.2.11 Usage: Merge overlapping paired-end reads Reference: Tanja Mago\u010d and Steven L. Salzberg. FLASH: fast length adjustment of short reads to improve genome assemblies. Bioinformatics, 27(21):2957\u20132963, 2011. https://doi.org/10.1093/bioinformatics/btr507</p>"},{"location":"citation/#trim-galore","title":"Trim Galore","text":"<p>Purpose: Wrapper around Cutadapt and FastQC for quality and adapter trimming Version: 0.6.10 Usage: Combines Cutadapt with quality control Reference: Felix Krueger. Trim galore. 2023. https://www.bioinformatics.babraham.ac.uk/projects/trim_galore/.</p>"},{"location":"citation/#alignment","title":"Alignment","text":""},{"location":"citation/#bowtie2","title":"Bowtie2","text":"<p>Purpose: Fast and sensitive read mapping to large genomes Version: 2.5.4 Usage: Align reads to reference genomes Reference: Ben Langmead and Steven L. Salzberg. Fast gapped-read alignment with Bowtie 2. Nature Methods, 9(4):357\u2013359, 2012. https://doi.org/10.1038/nmeth.1923</p>"},{"location":"citation/#minimap2","title":"minimap2","text":"<p>Purpose: Fast pairwise sequence alignment tool Version: 2.30 Usage: Fast alignment for long reads (PacBio/Nanopore) Reference: Heng Li. Minimap2: pairwise alignment for nucleotide sequences. Bioinformatics, 34(18):3094\u20133100, 2018. https://doi.org/10.1093/bioinformatics/bty191</p>"},{"location":"citation/#picard","title":"Picard","text":"<p>Purpose: Tools for manipulating high-throughput sequencing data and formats Version: 3.4.0 Usage: Duplicate marking and BAM processing Reference: Picard toolkit. 2019. https://broadinstitute.github.io/picard/.</p>"},{"location":"citation/#samtools","title":"SAMtools","text":"<p>Purpose: Tools for interacting with SAM/BAM format files Version: 1.22.1 Usage: Sorting, indexing, filtering SAM/BAM files Reference: Petr Danecek, James K Bonfield, Jennifer Liddle, John Marshall, Valeriu Ohan, Martin O Pollard, Andrew Whitwham, Thomas Keane, Shane A McCarthy, Robert M Davies, and Heng Li. Twelve years of SAMtools and BCFtools. GigaScience, 10(2):giab008, 2021. https://doi.org/10.1093/gigascience/giab008</p>"},{"location":"citation/#star","title":"STAR","text":"<p>Purpose: Ultrafast universal RNA-seq aligner Version: 2.7.11b Usage: High-speed splicing-aware RNA-seq alignment Reference: Alexander Dobin, Carrie A. Davis, Felix Schlesinger, Jorg Drenkow, Chris Zaleski, Sonali Jha, Philippe Batut, Mark Chaisson, and Thomas R. Gingeras. STAR: ultrafast universal RNA-seq aligner. Bioinformatics, 29(1):15\u201321, 2013. https://doi.org/10.1093/bioinformatics/bts635</p>"},{"location":"citation/#analysis","title":"Analysis","text":""},{"location":"citation/#bamnado","title":"BamNado","text":"<p>Purpose: SeqNado BAM file manipulation and analysis tool Version: 0.4.4 Usage: Calculate scaling factors and spike-in normalization Reference: Smith, Alastair L. BamNado: BAM file manipulation and analysis tool. 2024. https://pypi.org/project/bamnado/.</p>"},{"location":"citation/#bcftools","title":"BCFtools","text":"<p>Purpose: Tools for BCF/VCF format variant files Version: 1.22 Usage: Process VCF/BCF variant files Reference: Petr Danecek, James K Bonfield, Jennifer Liddle, John Marshall, Valeriu Ohan, Martin O Pollard, Andrew Whitwham, Thomas Keane, Shane A McCarthy, Robert M Davies, and Heng Li. Twelve years of SAMtools and BCFtools. GigaScience, 10(2):giab008, 2021. https://doi.org/10.1093/gigascience/giab008</p>"},{"location":"citation/#bedtools","title":"BEDTools","text":"<p>Purpose: Tools for genomic arithmetic and feature analysis Version: 2.31.1 Usage: Genomic interval manipulation and analysis Reference: Aaron R. Quinlan and Ira M. Hall. BEDTools: a flexible suite of utilities for comparing genomic features. Bioinformatics, 26(6):841\u2013842, 2010. https://doi.org/10.1093/bioinformatics/btq033</p>"},{"location":"citation/#cooler","title":"Cooler","text":"<p>Purpose: Tools for high-resolution interactions and HiC contact matrices Version: 0.10.4 Usage: Handle genomically-labeled arrays and Hi-C data Reference: Nezar Abdennur and Leonid A. Mirny. Cooler: scalable storage for Hi-C data and other genomically labeled arrays. Bioinformatics, 36(1):311\u2013316, 2020. https://doi.org/10.1093/bioinformatics/btz540</p>"},{"location":"citation/#findpeaks-homer","title":"findPeaks (HOMER)","text":"<p>Purpose: Identify genomic peaks in ChIP-seq or ATAC-seq data (HOMER) Version: 5.1 Usage: Identify genomic peaks in ChIP-seq or ATAC-seq data Reference: Sven Heinz, Christopher Benner, Nathanael Spann, Eric Bertolino, Yin C. Lin, Peter Laslo, Jason X. Cheng, Cornelis Murre, Harinder Singh, and Christopher K. Glass. Simple Combinations of Lineage-Determining Transcription Factors Prime cis-Regulatory Elements Required for Macrophage and B Cell Identities. Molecular Cell, 38(4):576\u2013589, 2010. https://doi.org/10.1016/j.molcel.2010.05.004</p>"},{"location":"citation/#homer","title":"HOMER","text":"<p>Purpose: Tools for ChIP-seq, DNase-seq, and other genomic analysis Version: 5.1 Usage: Peak calling, motif discovery, annotation Reference: Sven Heinz, Christopher Benner, Nathanael Spann, Eric Bertolino, Yin C. Lin, Peter Laslo, Jason X. Cheng, Cornelis Murre, Harinder Singh, and Christopher K. Glass. Simple Combinations of Lineage-Determining Transcription Factors Prime cis-Regulatory Elements Required for Macrophage and B Cell Identities. Molecular Cell, 38(4):576\u2013589, 2010. https://doi.org/10.1016/j.molcel.2010.05.004</p>"},{"location":"citation/#lanceotron","title":"LanceOtron","text":"<p>Purpose: Peak caller for high-resolution chromatin analysis Version: 1.2.7 Usage: Machine learning-based peak calling Reference: Lance D Hentges, Martin J Sergeant, Christopher B Cole, Damien J Downes, Jim R Hughes, and Stephen Taylor. LanceOtron: a deep learning peak caller for genome sequencing experiments. Bioinformatics, pages btac525, 2022. https://doi.org/10.1093/bioinformatics/btac525</p>"},{"location":"citation/#macs2","title":"MACS2","text":"<p>Purpose: Model-based analysis of ChIP-Seq data Version: 2.2.9.1 Usage: Peak calling for ChIP-seq and ATAC-seq Reference: Yong Zhang, Tao Liu, Clifford A Meyer, J\u00e9r\u00f4me Eeckhoute, David S Johnson, Bradley E Bernstein, Chad Nusbaum, Richard M Myers, Myles Brown, Wei Li, and X Shirley Liu. Model-based analysis of ChIP-seq (MACS). Genome Biology, 9(9):R137, 2008. https://doi.org/10.1186/gb-2008-9-9-r137</p>"},{"location":"citation/#mageck","title":"MAGeCK","text":"<p>Purpose: Model-based Analysis of Genome-wide CRISPR-Cas9 Knockout data Version: 0.5.9.5 Usage: CRISPR screen analysis for essential gene identification Reference: Wei Li, Han Xu, Tengfei Xiao, Le Cong, Michael I Love, Feng Zhang, Rafael A Irizarry, Jun S Liu, Myles Brown, and X Shirley Liu. MAGeCK enables robust identification of essential genes from genome-scale CRISPR/Cas9 knockout screens. Genome Biology, 15(12):554, 2014. https://doi.org/10.1186/s13059-014-0554-4</p>"},{"location":"citation/#maketagdirectory-homer","title":"makeTagDirectory (HOMER)","text":"<p>Purpose: Prepare and organize ChIP-seq tag directories (HOMER) Version: 5.1 Usage: Prepare and organize ChIP-seq tag directories Reference: Sven Heinz, Christopher Benner, Nathanael Spann, Eric Bertolino, Yin C. Lin, Peter Laslo, Jason X. Cheng, Cornelis Murre, Harinder Singh, and Christopher K. Glass. Simple Combinations of Lineage-Determining Transcription Factors Prime cis-Regulatory Elements Required for Macrophage and B Cell Identities. Molecular Cell, 38(4):576\u2013589, 2010. https://doi.org/10.1016/j.molcel.2010.05.004</p>"},{"location":"citation/#mccnado","title":"MCCNado","text":"<p>Purpose: Micro-Capture-C (MCC) sequencing data processing tool Version: 0.1.6 Usage: Analyze chromatin 3D interactions (Micro-Capture-C) Reference: Alastair L. Smith. MCCNado: Micro-Capture-C data processing tool. 2024. https://pypi.org/project/mccnado.</p>"},{"location":"citation/#meme-suite","title":"MEME Suite","text":"<p>Purpose: MEME Suite motif discovery and analysis tools Version: 5.5.9 Usage: DNA motif discovery and analysis Reference: T. L. Bailey, M. Boden, F. A. Buske, M. Frith, C. E. Grant, L. Clementi, J. Ren, W. W. Li, and W. S. Noble. Meme SUITE: tools for motif discovery and searching. Nucleic Acids Research, 37(Web Server):W202\u2013W208, 2009. https://doi.org/10.1093/nar/gkp335</p>"},{"location":"citation/#methyldackel","title":"MethylDackel","text":"<p>Purpose: Tools for analyzing DNA methylation from bisulfite sequencing data Version: 0.6.1 Usage: Extract methylation metrics from bisulfite-seq Reference: Devon Ryan. MethylDackel. 2021. https://github.com/dpryan79/MethylDackel.</p>"},{"location":"citation/#seacr","title":"SEACR","text":"<p>Purpose: Sparse enrichment analysis for CUT&amp;RUN Version: 1.3 Usage: Peak calling optimized for CUT&amp;Tag/CUT&amp;RUN Reference: Michael P. Meers, Dan Tenenbaum, and Steven Henikoff. Peak calling by Sparse Enrichment Analysis for CUT&amp;RUN chromatin profiling. Epigenetics &amp; Chromatin, 12(1):42, 2019. https://doi.org/10.1186/s13072-019-0287-4</p>"},{"location":"citation/#visualization","title":"Visualization","text":""},{"location":"citation/#deeptools","title":"deepTools","text":"<p>Purpose: Tools for processing and visualizing deep sequencing data Version: 3.5.6 Usage: BigWig generation, heatmaps, and profile plots Reference: Fidel Ram\u00edrez, Devon P Ryan, Bj\u00f6rn Gr\u00fcning, Vivek Bhardwaj, Fabian Kilpert, Andreas S Richter, Steffen Heyne, Friederike D\u00fcndar, and Thomas Manke. deepTools2: a next generation web server for deep-sequencing data analysis. Nucleic Acids Research, 44(W1):W160\u2013W165, 2016. https://doi.org/10.1093/nar/gkw257</p>"},{"location":"citation/#plotnado","title":"PlotNado","text":"<p>Purpose: SeqNado genome browser visualization and plotting tool Version: 0.1.dev101 Usage: Publication-ready genomic region visualizations Reference: Alastair L. Smith. PlotNado: genome browser visualization tool. 2023. https://github.com/alsmith151/plotnado.</p>"},{"location":"citation/#trackhub","title":"trackhub","text":"<p>Purpose: Python library to work with track hubs Version: 1.0 Usage: UCSC Genome Browser track hub library Reference: Ryan K. Dale, Laura H. Matzat, and Elissa P. Lei. Trackhub: A Library for creating and remotely hosting UCSC Genome Browser track hubs. F1000Research, 10:121, 2021. https://doi.org/10.12688/f1000research.50107.2</p>"},{"location":"citation/#tracknado","title":"TrackNado","text":"<p>Purpose: Track hub creation tool for UCSC Genome Browser Version: \u22650.3.1 Usage: Create and host UCSC track hubs Reference: Alastair L. Smith. TrackNado: a python library and cli tool to rapidly generate complex ucsc genome browser track hubs. 2024. https://pypi.org/project/tracknado.</p>"},{"location":"citation/#reporting","title":"Reporting","text":""},{"location":"citation/#multiqc","title":"MultiQC","text":"<p>Purpose: Aggregate quality control reports from multiple QC tools Version: 1.31 Usage: Aggregate QC reports across samples into interactive HTML Reference: Philip Ewels, M\u00e5ns Magnusson, Sverker Lundin, and Max K\u00e4ller. MultiQC: summarize analysis results for multiple tools and samples in a single report. Bioinformatics, 32(19):3047\u20133048, 2016. https://doi.org/10.1093/bioinformatics/btw354</p>"},{"location":"citation/#quarto","title":"Quarto","text":"<p>Purpose: Scientific and technical publishing system for reports Version: 1.8.25 Usage: Generate analysis reports with code and narrative Reference: Posit Software, PBC. Quarto: An open-source scientific and technical publishing system. 2022. https://quarto.org/.</p>"},{"location":"citation/#quantification","title":"Quantification","text":""},{"location":"citation/#featurecounts","title":"featureCounts","text":"<p>Purpose: Count reads overlapping genomic features (genes/exons) Version: 2.1.1 Usage: Gene-level read quantification for RNA-seq Reference: Yang Liao, Gordon K. Smyth, and Wei Shi. featureCounts: an efficient general purpose program for assigning sequence reads to genomic features. Bioinformatics, 30(7):923\u2013930, 2014. https://doi.org/10.1093/bioinformatics/btt656</p>"},{"location":"citation/#quantnado","title":"QuantNado","text":"<p>Purpose: SeqNado multiomics quantification and dataset creation tool Version: 0.2.5 Usage: Generate quantified datasets for ML analysis Reference: Catherine Chahrour and Alastair L. Smith. QuantNado: multiomics machine learning dataset generation tool. 2024. https://pypi.org/project/QuantNado.</p>"},{"location":"citation/#salmon","title":"Salmon","text":"<p>Purpose: Quantification of gene expression from RNA-seq data Version: 1.10.3 Usage: Alignment-free transcript quantification Reference: Rob Patro, Geet Duggal, Michael I. Love, Rafael A. Irizarry, and Carl Kingsford. Salmon provides fast and bias-aware quantification of transcript expression. Nature Methods, 14(4):417\u2013419, 2017. https://doi.org/10.1038/nmeth.4197</p>"},{"location":"citation/#subread","title":"Subread","text":"<p>Purpose: High-performance read alignment, quantification and mutation discovery Version: 2.1.1 Usage: High-performance read alignment and quantification Reference: Yang Liao, Gordon K. Smyth, and Wei Shi. The Subread aligner: fast, accurate and scalable read mapping by seed-and-vote. Nucleic Acids Research, 41(10):e108, 2013. https://doi.org/10.1093/nar/gkt214</p>"},{"location":"citation/#utilities","title":"Utilities","text":""},{"location":"citation/#apptainer","title":"Apptainer","text":"<p>Purpose: Container runtime for running Singularity/Apptainer images on HPC clusters Version: User-managed (see installation docs) Usage: Run containerized tools in HPC environments Reference: Apptainer Project Contributors. Apptainer. 2023. https://apptainer.org/.</p>"},{"location":"citation/#bedtobigbed","title":"bedToBigBed","text":"<p>Purpose: Convert BED format files to compressed BigBed format Version: 482 Usage: Convert BED to BigBed format Reference: W. James Kent, Charles W. Sugnet, Terrence S. Furey, Krishna M. Roskin, Tom H. Pringle, Alan M. Zahler, and David Haussler. The human genome browser at UCSC. Genome Research, 12(5):996\u20131006, 2002. https://doi.org/10.1101/gr.229102</p>"},{"location":"citation/#pigz","title":"pigz","text":"<p>Purpose: Parallel gzip compression utility Version: 2.8 Usage: Fast parallel compression/decompression Reference: Mark Adler. Pigz: Parallel Implementation of GZip. 2015. https://zlib.net/pigz/.</p>"},{"location":"citation/#snakemake","title":"Snakemake","text":"<p>Purpose: Workflow management system for reproducible and scalable data analysis Version: 9.14.5 Usage: Workflow management and execution Reference: Felix M\u00f6lder, Kim Philipp Jablonski, Brice Letcher, Michael B. Hall, Christopher H. Tomkins-Tinch, Vanessa Sochat, Jan Forster, Soohyun Lee, Sven O. Twardziok, Alexander Kanitz, Andreas Wilm, Manuel Holtgrewe, Sven Rahmann, Sven Nahnsen, and Johannes K\u00f6ster. Sustainable data analysis with Snakemake. F1000Research, 10:33, 2021. https://doi.org/10.12688/f1000research.29032.3</p>"},{"location":"citation/#ucsc-tools","title":"UCSC Tools","text":"<p>Purpose: UCSC genome browser command-line utilities Version: 482 Usage: BigWig creation and genomic format conversion Reference: W. James Kent, Charles W. Sugnet, Terrence S. Furey, Krishna M. Roskin, Tom H. Pringle, Alan M. Zahler, and David Haussler. The human genome browser at UCSC. Genome Research, 12(5):996\u20131006, 2002. https://doi.org/10.1101/gr.229102</p>"},{"location":"cli/","title":"CLI Reference","text":"<p>\u2190 Back to main page</p>"},{"location":"cli/#cli-reference","title":"CLI Reference","text":"<p>This page provides a complete reference of all available SeqNado commands and options.</p> <p>For quick examples and typical usage patterns, see the Quick Start Guide.</p> <p>SeqNado CLI</p> <p>Initialize your environment, build configs, create design files, and run pipelines. Use --help on any subcommand for details.</p> <p>Usage:</p> <pre><code>$ seqnado [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>-v, --version</code>: Show version and exit.</li> <li><code>--verbose</code>: Enable verbose logging (DEBUG level).</li> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>init</code>: Initialize SeqNado user environment.</li> <li><code>config</code>: Build a workflow configuration YAML for...</li> <li><code>tools</code>: List and explore bioinformatics tools...</li> <li><code>download</code>: Download FASTQ files from GEO/SRA using a...</li> <li><code>design</code>: Generate a SeqNado design CSV from FASTQ...</li> <li><code>pipeline</code>: Run the data processing pipeline for ASSAY...</li> <li><code>genomes</code>: Manage genome configurations</li> </ul>"},{"location":"cli/#cli-seqnado-init","title":"<code>seqnado init</code>","text":"<p>Initialize SeqNado user environment.</p> <ul> <li>Logs the current Conda environment if active (optional).</li> <li>Runs packaged Apptainer/Singularity init (if <code>apptainer</code> on PATH).</li> <li>Ensures ~/.config/seqnado/genome_config.json exists (template or preset).</li> </ul> <p>Usage:</p> <pre><code>$ seqnado init [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--preset / --no-preset</code>: Use packaged preset genomes instead of the editable template.  [default: no-preset]</li> <li><code>-n, --dry-run</code>: Show actions without executing them.</li> <li><code>-v, --verbose</code>: Increase logging verbosity.</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#cli-seqnado-config","title":"<code>seqnado config</code>","text":"<p>Build a workflow configuration YAML for the selected ASSAY. If no assay is provided, multiomics mode is used.</p> <p>Usage:</p> <pre><code>$ seqnado config [OPTIONS] [ASSAY]\n</code></pre> <p>Arguments:</p> <ul> <li><code>[ASSAY]</code>: rna, atac, snp, chip, cat, meth, mcc, crispr, multiomics. If omitted, multiomics mode is used.</li> </ul> <p>Options:</p> <ul> <li><code>--make-dirs / --no-make-dirs</code>: Create/don't create the output project directory or fastq subdir.  [default: make-dirs]</li> <li><code>--render-options / --no-render-options</code>: Render all options (even if not used by the workflow).  [default: no-render-options]</li> <li><code>-o, --output PATH</code>: Explicit path for the rendered config file.</li> <li><code>-v, --verbose</code>: Increase logging verbosity.</li> <li><code>--interactive / --no-interactive</code>: Interactively prompt for config values. Non-interactive mode only works for single assay configs (except MCC and multiomics).  [default: interactive]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#seqnado-tools","title":"<code>seqnado tools</code>","text":"<p>List and explore bioinformatics tools available in the SeqNado pipeline.</p> <p>Usage:</p> <pre><code>$ seqnado tools [OPTIONS] [TOOL]\n</code></pre> <p>Arguments:</p> <ul> <li><code>[TOOL]</code>: Specific tool name to get help for (e.g., fastqc, deeptools)</li> </ul> <p>Options:</p> <ul> <li><code>-l, --list</code>: List all available tools with descriptions.</li> <li><code>-c, --category TEXT</code>: Filter tools by category name or number. Use without a value to interactively select a category.</li> <li><code>--options</code>: Show tool options/help from the container (requires tool name and apptainer).</li> <li><code>--citation</code>: Show the BibTeX citation for a tool (requires tool name).</li> <li><code>-s, --subcommand TEXT</code>: Specify a tool subcommand for help (e.g. plotHeatmap).</li> <li><code>-v, --verbose</code>: Increase logging verbosity.</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#seqnado-download","title":"<code>seqnado download</code>","text":"<p>Download FASTQ files from GEO/SRA using a metadata TSV file and optionally generate a design file.</p> <p>Usage:</p> <pre><code>$ seqnado download [OPTIONS] METADATA_TSV\n</code></pre> <p>Arguments:</p> <ul> <li><code>METADATA_TSV</code>: TSV file from GEO/ENA with columns: run_accession, sample_title, library_name, and library_layout (PAIRED or SINGLE).  [required]</li> </ul> <p>Options:</p> <ul> <li><code>-o, --outdir PATH</code>: Output directory for downloaded FASTQ files.  [default: fastqs]</li> <li><code>-a, --assay TEXT</code>: Assay type for generating design file after download. If not provided, only downloads FASTQs.</li> <li><code>-d, --design-output PATH</code>: Output path for design CSV (default: metadata_{assay}.csv in outdir).</li> <li><code>-c, --cores INTEGER</code>: Number of cores/parallel jobs.  [default: 4]</li> <li><code>--preset [a|lc|ld|le|ls|ss|t]</code>: Snakemake job profile preset.  [default: le]</li> <li><code>--profile, --profiles PATH</code>: Path to a Snakemake profile directory (overrides --preset).</li> <li><code>-n, --dry-run</code>: Show actions without executing them.</li> <li><code>-v, --verbose</code>: Increase logging verbosity.</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#cli-seqnado-design","title":"<code>seqnado design</code>","text":"<p>Generate a SeqNado design CSV from FASTQ files for ASSAY. If no assay is provided, multiomics mode is used.</p> <p>Usage:</p> <pre><code>$ seqnado design [OPTIONS] [ASSAY] [FASTQ ...]\n</code></pre> <p>Arguments:</p> <ul> <li><code>[ASSAY]</code>: Assay type. Options: rna, atac, snp, chip, cat, meth, mcc, crispr, multiomics. If omitted, multiomics mode is used.</li> <li><code>[FASTQ ...]</code></li> </ul> <p>Options:</p> <ul> <li><code>-o, --output PATH</code>: Output CSV filename (default: metadata_{assay}.csv).</li> <li><code>--ip-to-control TEXT</code>: List of antibody,control pairings for IP assays (e.g. ChIP). Format: 'antibody1:control1,antibody2:control2' If provided will assign a control with a specified name to that ip in the metadata. If not provided, controls will be assigned based on a best-effort matching of sample names.</li> <li><code>--group-by TEXT</code>: Group samples by a regular expression or a column name.</li> <li><code>--auto-discover / --no-auto-discover</code>: Search common folders if none provided.  [default: auto-discover]</li> <li><code>--interactive / --no-interactive</code>: Interactively offer to add missing columns using schema defaults.  [default: interactive]</li> <li><code>--accept-all-defaults</code>: Non-interactive: auto-add only columns that have a schema default.</li> <li><code>--deseq2-pattern TEXT</code>: Regex pattern to extract DESeq2 groups from sample names. First capture group will be used. Example: r'-(\\w+)-rep' for 'sample-GROUP-rep1'</li> <li><code>-v, --verbose</code>: Increase logging verbosity.</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#cli-seqnado-pipeline","title":"<code>seqnado pipeline</code>","text":"<p>Run the data processing pipeline for ASSAY (Snakemake under the hood). Any additional arguments are passed to Snakemake (e.g., <code>seqnado pipeline rna -n</code> for dry-run, <code>--unlock</code>, etc.).</p> <p>Usage:</p> <pre><code>$ seqnado pipeline [OPTIONS] [ASSAY]\n</code></pre> <p>Arguments:</p> <ul> <li><code>[ASSAY]</code>: Assay type (required for single-assay, optional for Multiomic mode)</li> </ul> <p>Options:</p> <ul> <li><code>--configfile PATH</code>: Path to a SeqNado config YAML (default: config_&lt;ASSAY&gt;.yaml).</li> <li><code>--version</code>: Print SeqNado version and exit.</li> <li><code>--preset [a|lc|ld|le|ls|ss|t]</code>: Snakemake job profile preset.  [default: le]</li> <li><code>--profile, --profiles PATH</code>: Path to a Snakemake profile directory (overrides --preset).</li> <li><code>--clean-symlinks / --no-clean-symlinks</code>: Remove symlinks created by previous runs.  [default: no-clean-symlinks]</li> <li><code>-s, --scale-resources FLOAT</code>: Scale memory/time (env: SCALE_RESOURCES).  [default: 1.0]</li> <li><code>-v, --verbose</code>: Increase logging verbosity.</li> <li><code>-q, --queue TEXT</code>: Slurm queue/partition for the <code>ss</code> preset.  [default: short]</li> <li><code>--print-cmd</code>: Print the Snakemake command before running it.</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#cli-seqnado-genomes","title":"<code>seqnado genomes</code>","text":"<p>Manage genome configurations</p> <p>Usage:</p> <pre><code>$ seqnado genomes [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>list</code>: Show packaged and user genome presets.</li> <li><code>edit</code>: Open user genome config in $EDITOR.</li> <li><code>build</code>: Download genome and build indices via...</li> <li><code>fastqscreen</code>: Generate FastqScreen configuration file.</li> </ul>"},{"location":"cli/#seqnado-genomes-list","title":"<code>seqnado genomes list</code>","text":"<p>Show packaged and user genome presets.</p> <p>Usage:</p> <pre><code>$ seqnado genomes list [OPTIONS] [ASSAY]\n</code></pre> <p>Arguments:</p> <ul> <li><code>[ASSAY]</code>: Assay type. Options: rna, atac, snp, chip, cat, meth, mcc, crispr, multiomics  [default: atac]</li> </ul> <p>Options:</p> <ul> <li><code>-v, --verbose</code>: Increase logging verbosity.</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#seqnado-genomes-edit","title":"<code>seqnado genomes edit</code>","text":"<p>Open user genome config in $EDITOR.</p> <p>Usage:</p> <pre><code>$ seqnado genomes edit [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>-v, --verbose</code>: Increase logging verbosity.</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#seqnado-genomes-build","title":"<code>seqnado genomes build</code>","text":"<p>Download genome and build indices via Snakemake.</p> <p>Usage:</p> <pre><code>$ seqnado genomes build [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>-g, --name TEXT</code>: Genome name(s), comma-separated for multiple (e.g., hg38 or hg38,mm39,dm6)  [required]</li> <li><code>-o, --outdir PATH</code>: Output directory for build  [default: /home/runner/work/SeqNado/SeqNado/genome_build]</li> <li><code>-sp, --spikein TEXT</code>: Spike-in genome name for composite builds (e.g., mm39)</li> <li><code>--preset [a|lc|ld|le|ls|ss|t]</code>: Snakemake job profile preset.  [default: le]</li> <li><code>--profile, --profiles PATH</code>: Path to a Snakemake profile directory (overrides --preset).</li> <li><code>-c, --cores INTEGER</code>: Number of cores/parallel jobs.  [default: 4]</li> <li><code>--scale-resources FLOAT</code>: Scale memory/time (for build subcommand).  [default: 1.0]</li> <li><code>-n, --dry-run</code>: Show actions without executing them.</li> <li><code>-v, --verbose</code>: Increase logging verbosity.</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cli/#seqnado-genomes-fastqscreen","title":"<code>seqnado genomes fastqscreen</code>","text":"<p>Generate FastqScreen configuration file.</p> <p>Usage:</p> <pre><code>$ seqnado genomes fastqscreen [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>-s, --screen PATH</code>: Output path for fastqscreen config (default: ~/.config/seqnado/fastq_screen.conf)</li> <li><code>-t, --threads INTEGER</code>: Number of threads for Bowtie2  [default: 8]</li> <li><code>--no-contaminants</code>: Exclude contaminant databases</li> <li><code>--contaminant-path PATH</code>: Path to contaminant reference files</li> <li><code>-v, --verbose</code>: Increase logging verbosity.</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"cluster_config/","title":"HPC Clusters","text":"<p>\u2190 Back to main page</p>"},{"location":"cluster_config/#running-seqnado-on-hpc-clusters","title":"Running SeqNado on HPC Clusters","text":"<p>SeqNado is designed to run efficiently on high-performance computing (HPC) clusters using job schedulers. This guide covers setting up and running SeqNado on SLURM-based clusters, which is the recommended and most thoroughly tested configuration.</p>"},{"location":"cluster_config/#quick-start-slurm-clusters","title":"Quick Start: SLURM Clusters","text":"<p>To run SeqNado on a SLURM cluster with containerized environments:</p> <pre><code>seqnado pipeline atac --preset ss --queue short --scale-resources 1.0\n</code></pre> <p>The <code>ss</code> (SLURM Singularity) preset automatically configures job submission to SLURM with container isolation.</p> <p>See CLI options for presets, queues, and scaling: seqnado pipeline.</p>"},{"location":"cluster_config/#slurm-configuration","title":"SLURM Configuration","text":""},{"location":"cluster_config/#preset-ss-slurm-singularity","title":"Preset: <code>ss</code> (SLURM Singularity)","text":"<p>The SLURM Singularity preset uses:</p> <ul> <li>Executor: SLURM job scheduler</li> <li>Containerization: Singularity/Apptainer containers (recommended for HPC environments)</li> <li>Default partition: <code>short</code> (1 hour runtime, 3 GB memory per job)</li> <li>Max parallel jobs: 100</li> </ul>"},{"location":"cluster_config/#key-options","title":"Key Options","text":"<p>When running with the SLURM preset:</p>"},{"location":"cluster_config/#queuepartition","title":"Queue/Partition","text":"<p>Specify the SLURM partition:</p> <pre><code>seqnado pipeline atac --preset ss --queue short\n</code></pre> <p>Common partitions:</p> <ul> <li><code>short</code> - Default, 1 hour runtime, general purpose</li> <li><code>long</code> - Extended runtime (varies by system)</li> <li><code>gpu</code> - GPU-enabled partition (for GPU-accelerated steps like MCC)</li> </ul>"},{"location":"cluster_config/#resource-scaling","title":"Resource Scaling","text":"<p>Scale memory and runtime resources by a factor:</p> <pre><code>seqnado pipeline atac --preset ss --scale-resources 1.5\n</code></pre> <p>A factor of 1.5 increases all memory and time allocations by 50%. Use this if jobs are being killed due to resource limits.</p>"},{"location":"cluster_config/#verbose-output","title":"Verbose Output","text":"<p>Print the generated Snakemake command before execution:</p> <pre><code>seqnado pipeline atac --preset ss --print-cmd\n</code></pre> <p>For a full list of flags, see seqnado pipeline.</p>"},{"location":"cluster_config/#gpu-support","title":"GPU Support","text":"<p>For assays using GPU acceleration (e.g., MCC peak calling):</p> <ol> <li> <p>Submit to a GPU partition: <pre><code>seqnado pipeline atac --preset ss --queue gpu\n</code></pre></p> </li> <li> <p>SeqNado automatically allocates GPU resources for GPU-enabled steps.</p> </li> </ol>"},{"location":"cluster_config/#multiomics-workflows","title":"Multiomics Workflows","text":"<p>For multiomics experiments combining multiple assays:</p> <pre><code>seqnado pipeline --preset ss --configfile config.yaml\n</code></pre> <p>Ensure your configuration file includes all assays and their respective genomes.</p>"},{"location":"cluster_config/#other-execution-options","title":"Other Execution Options","text":"<p>While SLURM+Singularity is recommended for HPC, SeqNado provides several other profiles:</p>"},{"location":"cluster_config/#local-execution-presets","title":"Local Execution Presets","text":"<p>These options are useful for development, testing, or non-HPC environments:</p>"},{"location":"cluster_config/#le-local-execution","title":"<code>le</code> (Local Execution)","text":"<p>Standard local execution with environment isolation:</p> <pre><code>seqnado pipeline atac --preset le\n</code></pre> <p>Suitable for:</p> <ul> <li>Development machines</li> <li>Local testing</li> <li>Systems without job schedulers</li> </ul>"},{"location":"cluster_config/#lc-local-cluster","title":"<code>lc</code> (Local Cluster)","text":"<p>Local execution with job-level parallelization (GNU parallel):</p> <pre><code>seqnado pipeline atac --preset lc\n</code></pre> <p>Useful for:</p> <ul> <li>Multi-CPU workstations</li> <li>Quick local runs with parallelization</li> </ul>"},{"location":"cluster_config/#ls-local-single-threaded","title":"<code>ls</code> (Local Single-threaded)","text":"<p>Single-threaded local execution:</p> <pre><code>seqnado pipeline atac --preset ls\n</code></pre> <p>Useful for:</p> <ul> <li>Debugging</li> <li>Testing without parallelization</li> </ul>"},{"location":"cluster_config/#container-options","title":"Container Options","text":"<p>By default, all presets use Singularity/Apptainer containers for reproducibility. To use a local Conda environment instead:</p> <p>Modify your workflow configuration YAML:</p> <pre><code>container: null  # Disable containers\n</code></pre> <p>Then run with any preset. The workflow will execute with your current Python environment.</p>"},{"location":"cluster_config/#configuration-files","title":"Configuration Files","text":""},{"location":"cluster_config/#genome-configuration","title":"Genome Configuration","text":"<p>Ensure genomes are configured before running pipelines:</p> <pre><code>seqnado genomes list atac\n</code></pre> <p>More details: seqnado genomes.</p>"},{"location":"cluster_config/#workflow-configuration","title":"Workflow Configuration","text":"<p>Generate an assay-specific configuration:</p> <pre><code>seqnado config atac --output config_atac.yaml\n</code></pre> <p>More details: seqnado config.</p> <p>Edit the YAML to customize:</p> <ul> <li>Input/output paths</li> <li>Reference genomes</li> <li>Analysis parameters</li> <li>Resource allocations</li> </ul>"},{"location":"cluster_config/#design-metadata","title":"Design Metadata","text":"<p>Generate metadata CSV from FASTQ files:</p> <pre><code>seqnado design atac /path/to/fastqs/*.fastq.gz\n</code></pre> <p>More details: seqnado design.</p>"},{"location":"cluster_config/#troubleshooting","title":"Troubleshooting","text":""},{"location":"cluster_config/#jobs-terminated-due-to-resource-limits","title":"Jobs Terminated Due to Resource Limits","text":"<p>If Snakemake jobs are killed with <code>out of memory</code> or timeout errors:</p> <pre><code>seqnado pipeline atac --preset ss --scale-resources 2.0 --queue long\n</code></pre> <ul> <li>Increase <code>--scale-resources</code> factor</li> <li>Switch to a partition with longer walltime</li> <li>Check cluster documentation for memory limits</li> </ul>"},{"location":"cluster_config/#apptainersingularity-not-found","title":"Apptainer/Singularity Not Found","text":"<p>SeqNado prefers Apptainer (modern Singularity fork). If unavailable:</p> <ol> <li>Install Apptainer on your cluster</li> <li>Or switch to local environment execution (modify config YAML)</li> <li>Or request Singularity installation from cluster admin</li> </ol>"},{"location":"cluster_config/#slurm-submission-errors","title":"SLURM Submission Errors","text":"<p>Verify SLURM is available:</p> <pre><code>sinfo  # List SLURM partitions\nsqueue # Check submitted jobs\n</code></pre> <p>Add <code>--print-cmd</code> to see the exact Snakemake command and submission details.</p>"},{"location":"cluster_config/#container-image-download-issues","title":"Container Image Download Issues","text":"<p>SeqNado pulls container images on first use. If downloads fail due to network restrictions:</p> <ol> <li>Use cluster's container cache if available</li> <li>Pre-download and cache images on compute nodes</li> <li>Contact cluster support for container registry access</li> </ol>"},{"location":"cluster_config/#advanced-custom-snakemake-configuration","title":"Advanced: Custom Snakemake Configuration","text":"<p>For advanced users, profiles can be customized by editing the configuration files in:</p> <pre><code>~/.config/seqnado/profiles/profile_slurm_singularity/\n</code></pre> <p>Refer to Snakemake documentation for configuration options.</p>"},{"location":"cluster_config/#support","title":"Support","text":"<p>For issues specific to cluster execution:</p> <ol> <li>Check cluster documentation for scheduler syntax and available partitions</li> <li>Verify containers are accessible from compute nodes</li> <li>Test with <code>--preset le</code> on the login node first</li> <li>Use <code>--print-cmd</code> to debug generated Snakemake commands</li> </ol>"},{"location":"configuration/","title":"Configuration","text":"<p>\u2190 Back to main page</p>"},{"location":"configuration/#configuration","title":"Configuration","text":"<p>Build your analysis configuration after genome setup (see Genomes for genome configuration).</p>"},{"location":"configuration/#what-configuration-does","title":"What Configuration Does","text":"<p>The <code>seqnado config</code> command generates a YAML configuration file that defines all workflow parameters for your analysis. This file acts as a blueprint for the entire pipeline run:</p> <ul> <li>Specifies tools and versions to use for each step (alignment, peak calling, quantification, etc.)</li> <li>Sets tool-specific parameters (e.g., peak caller mode, strandedness, normalisation method)</li> <li>Defines output locations and naming conventions</li> <li>Captures assay-specific choices (which normalisation method? which peak caller? which pileup method?)</li> <li>Enables reproducibility by version-locking the configuration and making it version-controlled</li> </ul> <p>The configuration file is generated based on your assay type. You can review, edit, and customize it before running the pipeline. Changes to the config do not affect samples already processed \u2014 each analysis can use different parameters by pointing to different config files.</p>"},{"location":"configuration/#information-to-know-before-configuration","title":"Information to Know Before Configuration","text":"<p>\u26a0\ufe0f CRITICAL: Before running <code>seqnado config</code>, you must first run <code>seqnado init</code> to configure your reference genome(s). See Genomes.</p> <p>Once you have configured genomes, you'll be asked about your configuration choices during <code>seqnado config</code>. SeqNado automatically detects some parameters from your FASTQ files (sequencing type, read length, adapter content), but you should know these details upfront:</p> Information Why It Matters Example Reference genome &amp; build REQUIRED \u2014 Configure via <code>seqnado init</code> before running config hg38, mm39, mm10, dm6, or custom build Strandedness (RNA-seq only) SeqNado will ask during config; check with sequencing facility Unstranded (0), forward (1), or reverse (2) \u2014 usually dUTP-based kits are reverse-stranded Spike-in species (if applicable) You'll specify this during config; confirm what you used Drosophila dm6, lambda phage, methylation controls (Lambda, 250bp-v1, 2kb-unmod), etc. Control/input samples (ChIP-seq only) Not asked during config, but required in Design file if using with-input normalisation Do you have paired input controls? Name them as <code>samplename_input</code> in design file GTF annotation (RNA-seq only) You'll need this for quantification; verify it matches your genome build GRCh38 GTF for hg38; mm10 GTF for mm10 Peak type expectations (ChIP/ATAC/CAT) Helps you choose peak caller during config Narrow (TFs, H3K4me3) vs broad (H3K27me3, H3K36me3)"},{"location":"configuration/#questions-asked-during-configuration","title":"Questions Asked During Configuration","text":"<p>The <code>seqnado config</code> command guides you through a series of interactive questions tailored to your assay type. Below are the complete questions for each assay, with defaults shown in parentheses.</p>"},{"location":"configuration/#global-questions-all-assays-except-snp-crispr","title":"Global Questions (All Assays Except SNP &amp; CRISPR)","text":"<p>These questions appear for ATAC, ChIP, CAT, RNA, MCC, and Methylation:</p> <pre><code>Make Bigwigs? (default: yes)\n  \u251c\u2500 Bigwig method(s) \u2014 comma-separated (default: deeptools; options: deeptools, bamnado)\n  \u251c\u2500 Binsize for bigwigs (default: 10)\n  \u2514\u2500 Bigwig scaling method(s) \u2014 comma-separated (default: unscaled; options: unscaled, csaw)\n\nPerform plotting? (default: no)\n  \u251c\u2500 Path to coordinates BED file (optional)\n  \u2514\u2500 Path to genes BED file (optional)\n\nMake heatmaps? (default: no)\n\nGenerate GEO submission files? (default: no)\n\nMake UCSC hub? (default: no)\n  \u251c\u2500 UCSC hub directory (default: seqnado_output/hub/)\n  \u251c\u2500 Email address (default: $USER@example.com)\n  \u251c\u2500 Genome name for hub (default: genome name from config)\n  \u2514\u2500 Color by field (default: samplename)\n</code></pre>"},{"location":"configuration/#atac-seq-specific","title":"ATAC-seq Specific","text":"<pre><code>Shift ATAC reads? (default: yes)\n\nCall peaks? (default: yes)\n  \u251c\u2500 Peak calling method(s) \u2014 comma-separated (default: lanceotron; options: macs, seacr, lanceotron)\n  \u251c\u2500 Generate consensus counts from Design merge column? (default: no)\n  \u2514\u2500 Run motif analysis on called peaks? (default: no)\n      \u2514\u2500 Motif analysis method(s) \u2014 if yes (default: homer; options: homer, meme)\n\nMake dataset for ML? (default: no)\n  \u2514\u2500 Use regions BED file? (default: yes)\n      \u2514\u2500 Path to regions BED file (default: path/to/regions.bed)\n         OR Binsize for dataset (default: 1000)\n</code></pre>"},{"location":"configuration/#chip-seq-specific","title":"ChIP-seq Specific","text":"<pre><code>Call peaks? (default: yes)\n  \u251c\u2500 Peak calling method(s) \u2014 comma-separated (default: lanceotron; options: macs, seacr, lanceotron)\n  \u251c\u2500 Generate consensus counts from Design merge column? (default: no)\n  \u2514\u2500 Run motif analysis on called peaks? (default: no)\n      \u2514\u2500 Motif analysis method(s) \u2014 if yes (default: homer)\n\nDo you have spike-in? (default: no)\n  \u251c\u2500 Normalisation method(s) \u2014 comma-separated (default: orlando; options: orlando, with-input, deseq2, edger, csaw)\n  \u251c\u2500 Reference genome (default: hg38)\n  \u251c\u2500 Spike-in genome (default: dm6)\n  \u2514\u2500 Spike-in control gene names \u2014 if using deseq2 or edger (default: AmpR,Cas9_3p,Cas9_5p)\n\nMake dataset for ML? (default: no)\n  \u2514\u2500 Use regions BED file? (default: yes)\n      \u2514\u2500 Path to regions BED file (default: path/to/regions.bed)\n         OR Binsize for dataset (default: 1000)\n</code></pre>"},{"location":"configuration/#cuttag-cat-specific","title":"CUT&amp;Tag (CAT) Specific","text":"<pre><code>Shift CAT reads? (default: no)\n\nCall peaks? (default: yes)\n  \u251c\u2500 Peak calling method(s) \u2014 comma-separated (default: seacr; options: macs, seacr, lanceotron)\n  \u251c\u2500 Generate consensus counts from Design merge column? (default: no)\n  \u2514\u2500 Run motif analysis on called peaks? (default: no)\n      \u2514\u2500 Motif analysis method(s) \u2014 if yes (default: homer)\n\nDo you have spike-in? (default: no)\n  \u251c\u2500 Normalisation method(s) \u2014 comma-separated (default: orlando)\n  \u251c\u2500 Reference genome (default: hg38)\n  \u251c\u2500 Spike-in genome (default: dm6)\n  \u2514\u2500 Spike-in control gene names \u2014 if using deseq2 or edger (default: AmpR,Cas9_3p,Cas9_5p)\n\nMake dataset for ML? (default: no)\n  \u2514\u2500 Use regions BED file? (default: yes)\n      \u2514\u2500 Path to regions BED file\n         OR Binsize for dataset\n</code></pre>"},{"location":"configuration/#rna-seq-specific","title":"RNA-seq Specific","text":"<pre><code>Do you have spike-in? (default: no)\n  \u251c\u2500 Normalisation method(s) \u2014 comma-separated (default: deseq2; options: orlando, with-input, deseq2, edger, csaw)\n  \u251c\u2500 Reference genome (default: hg38)\n  \u251c\u2500 Spike-in genome (default: spikein_rna)\n  \u2514\u2500 Spike-in control gene names \u2014 if using deseq2 or edger (default: AmpR,Cas9_3p,Cas9_5p)\n\nQuantification method? (default: feature_counts; options: feature_counts, salmon)\n  \u2514\u2500 Strandedness? \u2014 if feature_counts (default: 0; options: 0=unstranded, 1=forward, 2=reverse)\n\nSalmon index path? \u2014 if salmon method (default: path/to/salmon_index)\n\nRun DESeq2? (default: no)\n</code></pre>"},{"location":"configuration/#mcc-capture-c-specific","title":"MCC (Capture-C) Specific","text":"<pre><code>Call peaks? (default: yes)\n  \u251c\u2500 Peak calling method(s) \u2014 comma-separated (default: lanceotronmcc; options: macs, seacr, lanceotron, lanceotronmcc)\n  \u251c\u2500 Generate consensus counts from Design merge column? (default: no)\n  \u2514\u2500 Run motif analysis on called peaks? (default: no)\n      \u2514\u2500 Motif analysis method(s) \u2014 if yes (default: homer)\n\nPath to viewpoints file (required; default: path/to/viewpoints.bed)\n\nResolutions for MCC cooler files \u2014 comma-separated (default: 100,1000)\n</code></pre>"},{"location":"configuration/#methylation-specific","title":"Methylation Specific","text":"<pre><code>Call methylation? (default: no)\n  \u2514\u2500 Spike-in genomes \u2014 comma-separated, if yes (default: Lambda,250bp-v1,2kb-unmod)\n\nMethylation assay? (default: taps; options: taps, bsseq)\n</code></pre>"},{"location":"configuration/#snp-calling-specific","title":"SNP Calling Specific","text":"<pre><code>Call SNPs? (default: yes)\n  \u251c\u2500 SNP calling method? (default: bcftools; options: bcftools)\n  \u2514\u2500 Annotate SNPs? (default: no)\n      \u2514\u2500 Path to SNP database \u2014 if yes (default: path/to/snp_database)\n\nGenerate GEO submission files? (default: no)\n</code></pre>"},{"location":"configuration/#crispr-specific","title":"CRISPR Specific","text":"<pre><code>Use MAGeCK for guide RNA analysis? (default: no)\n\nGenerate GEO submission files? (default: no)\n</code></pre>"},{"location":"configuration/#understanding-multi-select-questions","title":"Understanding Multi-Select Questions","text":"<p>Some questions allow comma-separated selections for multiple values: - Peak calling method(s): Can use MACS, SEACR, and Lanceotron simultaneously - Normalisation method(s): Can run Orlando and DESeq2 on the same data - Motif analysis method(s): Can run both Homer and MEME on peaks - Bigwig method(s): Can generate with both deeptools and bamnado</p> <p>Example: <pre><code>Peak calling method(s) (comma-separated for multiple): macs, seacr, lanceotron\n</code></pre></p> <p>The pipeline will run all specified methods and generate outputs for each.</p>"},{"location":"configuration/#resource-constraints-to-consider","title":"Resource Constraints to Consider","text":"<p>Before finalizing your configuration, review your compute environment:</p> <ul> <li>Memory per sample: Does your cluster have enough RAM for large BAM files (deeptools, Salmon, variant calling)?</li> <li>Runtime limits: Do you have wall-clock time limits? Some tools (STAR, MACS2, DESeq2) can be slow on large files.</li> <li>Storage: Will intermediate files (unsorted BAMs, uncompressed bigwigs) fit on your filesystem?</li> <li>Parallelization: How many samples can you process in parallel without overwhelming resources?</li> </ul> <p>See the Troubleshooting guide for guidance on resource requirements per tool.</p>"},{"location":"configuration/#running-seqnado-config","title":"Running <code>seqnado config</code>","text":"<p>The <code>seqnado config</code> command interactively builds a YAML configuration file for your selected assay. It asks questions appropriate to your assay type and generates a configuration that you can review and customize before running the pipeline.</p>"},{"location":"configuration/#assay-types","title":"Assay Types","text":"Assay CLI name When to Use ATAC-seq <code>atac</code> Open chromatin profiling (Tn5-based) ChIP-seq <code>chip</code> Chromatin immunoprecipitation CRISPR analysis <code>crispr</code> CRISPR screen analysis CUT&amp;Tag <code>cat</code> Chromatin profiling by tagmentation (low background) MCC <code>mcc</code> Capture-C or similar 3C-derived methods Methylation <code>meth</code> Bisulfite or TAPS methylation calling RNA-seq <code>rna</code> Quantification from RNA-seq reads SNP analysis <code>snp</code> Variant calling and annotation <p>For all available arguments and flags, see: seqnado config.</p>"},{"location":"configuration/#example-usage","title":"Example Usage","text":""},{"location":"configuration/#build-a-configuration-for-chip-seq","title":"Build a Configuration for ChIP-seq","text":"<pre><code>seqnado config chip --output chip_config.yaml\n</code></pre>"},{"location":"configuration/#interactive-multiomics-configuration-multiple-assays","title":"Interactive Multiomics Configuration (Multiple Assays)","text":"<pre><code>seqnado config --make-dirs --interactive\n</code></pre>"},{"location":"configuration/#third-party-tools","title":"Third Party Tools","text":"<p>SeqNado integrates with specialized tools for each analysis step. Before running the pipeline, review the guidance below for tools critical to your assay. Default parameters are sensible for most experiments, but customization may be necessary for specific data, assays, and experimental designs.</p>"},{"location":"configuration/#supported-tools-reference","title":"Supported Tools Reference","text":"<p>Below is a comprehensive list of tools integrated into SeqNado, organized by function. \u26a0\ufe0f Key configuration warnings are included for critical tools.</p>"},{"location":"configuration/#alignment-indexing","title":"Alignment &amp; Indexing","text":"<ul> <li>bowtie2 \u2014 Maps sequencing reads to a reference genome (ATAC, ChIP, CUT&amp;Tag, SNP)</li> <li>STAR \u2014 Splice-aware aligner for RNA-seq data (RNA)</li> <li>salmon \u2014 Pseudoalignment-based RNA quantification (RNA; optional alternative to alignment)</li> <li>\u26a0\ufe0f Requires compatible reference index: GTF version must match your genome build (e.g., GRCh38 GTF for hg38)</li> <li>Faster than alignment-based methods but less flexible for debugging strandedness</li> <li>Generate a Salmon index before running: <code>salmon index -t transcripts.fa -i salmon_index_hg38</code></li> </ul>"},{"location":"configuration/#read-processing","title":"Read Processing","text":"<ul> <li>samtools \u2014 BAM/SAM file manipulation and sorting</li> <li>picard \u2014 Java tools for high-throughput sequencing data manipulation</li> <li>cutadapt \u2014 Removes adapter sequences from reads</li> <li>trim-galore \u2014 Wrapper for Cutadapt and FastQC for quality control</li> </ul>"},{"location":"configuration/#peak-calling-chip-seq-atac-seq-cuttag-mcc","title":"Peak Calling (ChIP-seq, ATAC-seq, CUT&amp;Tag, MCC)","text":"<ul> <li>MACS2 \u2014 Model-based peak calling</li> <li> <p>\u26a0\ufe0f Peak calling mode depends on your mark:</p> <ul> <li>Narrow mode (default) for transcription factors and sharp marks (H3K4me3, H3K27ac)</li> <li>Broad mode for diffuse marks (H3K27me3, H3K36me3). Without <code>--broad</code>, you'll miss 90% of broad domains</li> <li>For weak ChIP-seq with few peaks, consider switching to SEACR or Lanceotron instead</li> </ul> </li> <li> <p>SEACR \u2014 Peak caller optimized for low-background data (CUT&amp;Tag)</p> </li> <li> <p>Configure stringency based on expected noise:</p> <ul> <li><code>stringent</code> mode (recommended for CUT&amp;Tag) reduces false positives</li> <li><code>relaxed</code> mode if you're missing expected peaks</li> <li>Threshold values control sensitivity vs. specificity trade-off</li> </ul> </li> <li> <p>Lanceotron \u2014 Deep learning\u2013based peak caller for broad and narrow peaks</p> </li> <li>No hyper-parameter tuning needed; model is pre-trained</li> <li> <p>Can be slow on large files; consider testing on a sample first</p> </li> <li> <p>lanceotronmcc \u2014 Specialized Lanceotron variant for MCC interaction peaks</p> </li> </ul>"},{"location":"configuration/#quantification-rna-seq","title":"Quantification (RNA-seq)","text":"<ul> <li>featureCounts (subread package) \u2014 Assigns aligned reads to genomic features for RNA-seq quantification</li> <li> <p>\u26a0\ufe0f Critical GTF and strandedness configuration:</p> <ul> <li>Default parameters count reads at the exon level (<code>-t exon</code>) and aggregate by gene_id</li> <li>Must verify GTF attribute match: Does your GTF use <code>gene_id</code> or <code>gene_name</code>? featureCounts requires exact match or all counts will be zero</li> <li>Strandedness must match library prep: Use <code>0</code> (unstranded), <code>1</code> (forward), or <code>2</code> (reverse). Using wrong strandedness results in 50\u201390% fewer counts</li> <li>Paired-end mode (<code>-p --countReadPairs</code>) is auto-detected from FASTQ files</li> <li>If all genes get zero counts, check GTF feature attribute match first</li> </ul> </li> <li> <p>Salmon \u2014 Faster pseudoalignment-based quantification (requires compatible index; see Alignment &amp; Indexing above)</p> </li> </ul>"},{"location":"configuration/#bigwig-generation-visualization","title":"Bigwig Generation &amp; Visualization","text":"<ul> <li>deeptools bamCoverage \u2014 Generates BigWig files from BAM alignments</li> <li>**Using deeptools' native <code>--normalizeUsing</code> ** \u2014 To use deeptools' built-in normalization methods (<code>RPKM</code>, <code>CPM</code>, <code>BPM</code>, <code>RPGC</code>), select <code>unscaled</code> for your bigwig scaling method, then manually edit <code>third_party_tools.deeptools.bam_coverage.command_line_arguments</code> to add <code>--normalizeUsing</code> (e.g., <code>\"--binSize 10 --normalizeUsing RPKM\"</code>). This disables SeqNado's scaling entirely. Example use case: comparing standard RPKM-normalized bigwigs across studies</li> <li>Bigwig scaling method \u2014 You choose during config (options: <code>unscaled</code>, <code>csaw</code>):<ul> <li><code>unscaled</code>: Raw read coverage without normalization; useful for visual inspection and as input for downstream analysis tools</li> <li><code>csaw</code> (ChIP-Seq Analysis with Windows): Applies scaling factors between samples to equalize library depth while preserving broad features; recommended when comparing ChIP-seq samples or using spike-in controls; see Normalisation Methods</li> </ul> </li> <li>Spike-in normalisation for bigwigs \u2014 If you selected spike-in normalisation (Orlando, with-input, DESeq2, or edgeR) during config, scale factors are automatically calculated and applied to bigwig generation, producing spike-in\u2013normalized bigwigs for downstream analysis; see Normalisation Methods</li> </ul> <p>Info</p> <p>How SeqNado prevents conflicts between <code>--normalizeUsing</code> and <code>--scaleFactor</code>: The default deeptools config includes <code>--normalizeUsing RPKM</code>. However, when you select spike-in or csaw normalization, SeqNado automatically removes <code>--normalizeUsing</code> and applies only <code>--scaleFactor</code>. This prevents deeptools from silently ignoring your scale factors (since <code>--normalizeUsing</code> overrides <code>--scaleFactor</code> in deeptools). Result: your spike-in/csaw scale factors apply correctly without unwanted RPKM normalization</p> <ul> <li> <p>bamnado \u2014 Alternative tool for BigWig generation and BAM manipulation</p> </li> <li> <p>deeptools heatmap \u2014 Creates heatmaps from BigWig files around genomic coordinates</p> </li> <li> <p>deeptools metaplot \u2014 Generates metaplots of signal around features</p> </li> </ul>"},{"location":"configuration/#motif-analysis-peak-regions","title":"Motif Analysis (peak regions)","text":"<ul> <li>Homer \u2014 Motif discovery and annotation in peak regions</li> <li>MEME \u2014 Alternative motif discovery tool</li> </ul>"},{"location":"configuration/#variant-calling-snp","title":"Variant Calling (SNP)","text":"<ul> <li>bcftools \u2014 SNP calling and VCF manipulation</li> <li>SnpEff/SnpSift \u2014 SNP annotation and variant functional impact prediction</li> </ul>"},{"location":"configuration/#methylation-specialized","title":"Methylation &amp; Specialized","text":"<ul> <li>methyldackel \u2014 Extract methylation calls from bisulfite-seq data</li> <li>MAGeCK \u2014 Statistical analysis of CRISPR screen data</li> <li>UCSC utilities \u2014 Convert and manage genome tracks in UCSC format</li> </ul>"},{"location":"configuration/#data-analysis-normalisation","title":"Data Analysis &amp; Normalisation","text":"<ul> <li> <p>DESeq2 (R/Bioconductor) \u2014 Differential expression analysis (RNA-seq)</p> </li> <li> <p>edgeR (R/Bioconductor) \u2014 Differential expression with spike-in normalisation</p> </li> <li> <p>\u26a0\ufe0f Spike-in normalisation setup:</p> <ul> <li>Requires correct spike-in genome specification (e.g., <code>dm6</code> for Drosophila)</li> <li>Control gene names must match spike-in reference GTF (e.g., <code>ERCC</code>)</li> <li>With-input normalisation requires ChIP and input samples paired in design file \u2014 see Design guide</li> </ul> </li> <li> <p>Orlando \u2014 Spike-in normalisation method for chromatin-based assays (ChIP, CAT)</p> </li> <li> <p>Recommended for spike-in data with balanced endogenous and exogenous reads</p> </li> <li> <p>with-input \u2014 Normalisation using paired input controls (ChIP-seq only)</p> </li> <li>Requires input samples correctly paired in design file</li> <li> <p>Alternative to spike-in normalisation when spike-ins unavailable</p> </li> <li> <p>CSAW \u2014 Cyclic shift aware normalisation; produces merged bigwigs</p> </li> <li>Recommended for spike-in data with unbalanced read distributions</li> <li>See Normalisation Methods for detailed comparison</li> </ul>"},{"location":"configuration/#configuration-logic-tool-interactions","title":"Configuration Logic &amp; Tool Interactions","text":"<p>See the Pipeline Overview for guidance on which tools to use for each assay type.</p> <p>For detailed normalisation methods comparison, see Normalisation Methods.</p> <p>For configuration command options and usage patterns, see seqnado config.</p>"},{"location":"configuration/#common-pitfalls-and-best-practices","title":"Common Pitfalls and Best Practices","text":""},{"location":"configuration/#pitfalls-to-avoid","title":"Pitfalls to Avoid","text":"<p>Assuming defaults are correct without validation     - Problem: Accepting default peak caller (lanceotron), GTF attributes, or strandedness without checking your specific data    - Fix: For each new assay/GTF/strandedness combo, test peak calling or quantification on 1\u20132 samples first; spot-check BAM files and counts</p> <p>Mismatched GTF and genome builds    - Problem: Using GRCh37 GTF with hg38 genome, or mm10 GTF with mm39    - Fix: Verify your annotation version matches your genome build at download time; document version numbers in your README</p> <p>Wrong peak calling mode for your biological mark    - Problem: Using MACS2 narrow mode for H3K27me3 (broad mark) \u2192 misses 90% of signal; using broad mode for H3K4me3 (sharp mark) \u2192 thousands of false positives    - Fix: Know your mark. H3K4me3, H3K27ac, TF binding \u2192 narrow. H3K27me3, H3K36me3, H3K9me3 \u2192 broad. Test on a rep.</p> <p>Forgetting to pair ChIP and input samples in design file    - Problem: Configuring \"with-input\" normalisation but not ensuring control sample pairs in Design    - Fix: Before running pipeline, review design file to confirm ChIP\u2192input pairing syntax matched for all samples</p> <p>Ignoring resource constraints    - Problem: Setting memory-intensive parameters (STAR <code>--limitSjdbInsertNsj</code>, deeptools multi-threaded) on systems without available RAM    - Fix: Test on 1 sample and monitor resource usage (<code>top</code>, cluster monitoring); adjust thread count or binsize if needed</p>"},{"location":"configuration/#best-practices","title":"Best Practices","text":"<p>\u2705 Test before large-scale runs - Run <code>seqnado snakemake ... -n</code> (dry-run) to visualize the workflow DAG before execution - Test peak calling or quantification on 1\u20132 samples to validate your tool selections - Spot-check intermediate outputs: BAM file headers (correct chromosome names?), peak files (reasonable count?), count matrices (non-zero?), BigWigs (visible in IGV?)</p> <p>\u2705 Version-control your configuration files - Commit config YAML files to git so analysis is fully reproducible - Create assay-specific configs (e.g., <code>config_chip_h3k27ac.yaml</code>, <code>config_rna_pe150.yaml</code>) so you can reuse templates - Different analyses can and should use different configs \u2014 this is your version control</p> <p>\u2705 Validate reference files upfront - Before running the full pipeline, verify:   - GTF file: Spot-check a few known genes and their feature definitions   - Spike-in genome: Confirm the spike-in species (dm6? ecoli?) is included in your genome build   - Salmon index: If using Salmon, ensure the index matches your GTF and genome version   - bedtools/peaks BED files: Verify chromosome names match your genome (e.g., <code>chr1</code> vs <code>1</code>)</p> <p>\u2705 Monitor the first few samples carefully - Check the first sample's outputs in detail before running the full cohort - Verify BAM file alignment rate (expect &gt;90% for most data) - Check peak files are reasonable (not zero peaks, not millions of false positives) - Confirm BigWig tracks look correct in IGV (visible signal? expected chromosome coverage?) - This catches configuration errors early and saves days of compute time</p> <p>\u2705 Use meaningful output names - Use the <code>--output</code> flag to give your config file a descriptive name: <code>seqnado config rna --output lps_response_config.yaml</code> - This helps keep track of different analyses without confusion</p> <p>See Also:</p> <ul> <li>Design Guide - Create experimental design files</li> <li>Tools Reference - Configure tool-specific options</li> <li>Troubleshooting - Configuration issues</li> </ul>"},{"location":"design/","title":"Design Guide","text":"<p>\u2190 Back to main page</p>"},{"location":"design/#design-guide","title":"Design Guide","text":"<p>The <code>seqnado design</code> command generates a design CSV file from FASTQ files for a specific assay. If no assay is provided, the tool operates in multiomics mode.</p> <p>For full arguments and flags, see the CLI reference: seqnado design.</p>"},{"location":"design/#fastq-files","title":"FASTQ Files","text":"<p>After generating the configuration and project directory using <code>seqnado config</code>, you need to link your FASTQ files into the <code>fastqs</code> directory. This ensures that the pipeline can locate and process your input data.</p>"},{"location":"design/#symlinking-fastq-files","title":"Symlinking FASTQ Files","text":"<p>Use the following command to create symbolic links for your FASTQ files:</p> <pre><code>ln -s /path/to/your/fastq/files/* &lt;project_directory&gt;/fastqs/\n</code></pre> <p>Replace <code>/path/to/your/fastq/files/</code> with the directory containing your FASTQ files and <code>&lt;project_directory&gt;</code> with the path to the project directory created by <code>seqnado config</code>.</p>"},{"location":"design/#example","title":"Example","text":"<p>If your FASTQ files are located in <code>/data/fastq/</code> and your project directory is <code>rna_project</code>, run:</p> <pre><code>ln -s /data/fastq/* rna_project/fastqs/\n</code></pre> <p>This will create symbolic links to all FASTQ files in the <code>fastqs</code> directory of your project. The glob pattern <code>*</code> expands to all files in the source directory.</p>"},{"location":"design/#safe-naming-strategies-for-fastq-files-critical","title":"Safe Naming Strategies for FASTQ Files (Critical)","text":"<p>Before linking your FASTQ files, ensure they follow a consistent naming convention. The <code>seqnado design</code> command parses filenames to infer sample metadata (replicates, antibodies, controls, groups), so proper naming is essential for successful pipeline execution.</p> <p>Below are recommended naming strategies for each assay type:</p> <ul> <li> <p>ATAC-seq:   <pre><code>sample-name-rep1_R1.fastq.gz\nsample-name-rep1_R2.fastq.gz\n</code></pre></p> </li> <li> <p>ChIP-seq:   <pre><code>sample-name-rep1_Antibody_R1.fastq.gz\nsample-name-rep1_Antibody_R2.fastq.gz\nsample-name-rep2_Input_R1.fastq.gz\nsample-name-rep2_Input_R2.fastq.gz\n</code></pre></p> </li> <li><code>Antibody</code>: Name of the antibody used for ChIP.</li> <li> <p><code>Input</code>: Control sample.</p> </li> <li> <p>RNA-seq:   <pre><code>sample-name-rep1_R1.fastq.gz\nsample-name-rep1_R2.fastq.gz\nsample-name-rep2_R1.fastq.gz\nsample-name-rep2_R2.fastq.gz\n</code></pre></p> </li> <li><code>sample-name</code>: Unique identifier for the sample.</li> <li><code>rep1</code>, <code>rep2</code>: Biological or technical replicate number.</li> <li><code>R1</code>, <code>R2</code>: Read pair (forward and reverse).</li> </ul> <p>Using these naming conventions ensures that the pipeline can correctly parse and process your data.</p>"},{"location":"design/#example-usage","title":"Example Usage","text":""},{"location":"design/#generate-a-design-csv-for-atac-seq","title":"Generate a Design CSV for ATAC-seq","text":"<pre><code>seqnado design atac fastqs/*\n</code></pre> <p>This command reads all FASTQ files in the <code>fastqs/</code> directory (the <code>*</code> glob pattern expands to every file) and generates a design CSV file named <code>metadata.csv</code> in your project directory.</p>"},{"location":"design/#generate-a-design-csv-for-chip-seq-with-explicit-control-pairing","title":"Generate a Design CSV for ChIP-seq with explicit control pairing","text":"<p>For ChIP-seq experiments, the design CSV requires both IP FASTQ files and optionally control FASTQ files. The tool can infer these relationships based on file naming conventions.</p>"},{"location":"design/#simple-case","title":"Simple Case","text":"<p>For simple cases with a single control or when no control is needed, for example:</p> <ul> <li>SAMPLE1_H3K27ac_R1.fastq.gz</li> <li>SAMPLE1_H3K27ac_R2.fastq.gz</li> <li>SAMPLE1_Menin_R1.fastq.gz</li> <li>SAMPLE1_Menin_R2.fastq.gz</li> <li>SAMPLE1_input_R1.fastq.gz</li> <li>SAMPLE1_input_R2.fastq.gz</li> <li>SAMPLE_2_H3K27ac_R1.fastq.gz</li> <li>SAMPLE_2_H3K27ac_R2.fastq.gz</li> </ul> <p>The command would be:</p> <pre><code>seqnado design chip fastqs/* \n</code></pre> <p>The control will either be left blank if no appropriate files are in the directory or a single control sharing the same sample ID will be broadcast to all IP samples sharing that sample ID. e.g.:</p> assay sample_id ip control r1 r2 r1_control r2_control scaling_group ChIP SAMPLE1 H3K27ac input SAMPLE1_H3K27ac_R1.fastq.gz SAMPLE1_H3K27ac_R2.fastq.gz SAMPLE1_input_R1.fastq.gz SAMPLE1_input_R2.fastq.gz default ChIP SAMPLE1 Menin input SAMPLE1_Menin_R1.fastq.gz SAMPLE1_Menin_R2.fastq.gz SAMPLE1_input_R1.fastq.gz SAMPLE1_input_R2.fastq.gz default ChIP SAMPLE_2 H3K27ac SAMPLE_2_H3K27ac_R1.fastq.gz SAMPLE_2_H3K27ac_R2.fastq.gz default"},{"location":"design/#complex-case-with-multiple-controls-and-ambiguity-in-pairing","title":"Complex Case with Multiple Controls and Ambiguity in Pairing","text":"<p>If there are multiple controls, specify which control corresponds to each IP using the <code>--ip-to-control</code> option. For example:</p> <p>We want the single fixed control <code>sf-input</code> to be used for the <code>H3K27ac</code> IP, and the double fixed <code>df-input</code> control to be used for the <code>Menin</code> IP. The FASTQ files are as follows:</p> <ul> <li>SAMPLE1_H3K27ac_R1.fastq.gz</li> <li>SAMPLE1_H3K27ac_R2.fastq.gz </li> <li>SAMPLE1_sf-input_R1.fastq.gz</li> <li>SAMPLE1_sf-input_R2.fastq.gz</li> <li>SAMPLE1_Menin_R1.fastq.gz</li> <li>SAMPLE1_Menin_R2.fastq.gz</li> <li>SAMPLE1_df-input_R1.fastq.gz  </li> <li>SAMPLE1_df-input_R2.fastq.gz</li> </ul> <p>The command would be:</p> <pre><code>seqnado design chip fastqs/* --ip-to-control \"H3K27ac:sf-input,Menin:df-input\"\n</code></pre> <p>This will generate a design CSV file with the appropriate control pairings. e.g.,</p> assay sample_id ip control r1 r2 r1_control r2_control scaling_group ChIP SAMPLE1 H3K27ac sf-input SAMPLE1_H3K27ac_R1.fastq.gz SAMPLE1_H3K27ac_R2.fastq.gz SAMPLE1_sf-input_R1.fastq.gz SAMPLE1_sf-input_R2.fastq.gz default ChIP SAMPLE1 Menin df-input SAMPLE1_Menin_R1.fastq.gz SAMPLE1_Menin_R2.fastq.gz SAMPLE1_df-input_R1.fastq.gz SAMPLE1_df-input_R2.fastq.gz default"},{"location":"design/#rna-seq-grouping-for-deseq2","title":"RNA-seq grouping for DESeq2","text":"<p>For RNA-seq experiments using spike-in normalization with DESeq2, the design command automatically detects experimental groups from sample names. Two columns are generated:</p> <ul> <li><code>group</code>: The experimental group name (e.g., control, treated, WT, KO, vehicle, drug)</li> <li><code>deseq2</code>: Binary encoding where 0 = control/reference group, 1 = treatment/comparison group</li> </ul> <p>The tool detects groups using several strategies:</p> <ol> <li>Keyword detection: Recognizes common keywords like control, treated, WT, KO, vehicle, DMSO</li> <li>Pattern extraction: Extracts group information from sample naming patterns (e.g., <code>sample-GROUP-rep1</code>)</li> <li>Custom patterns: Use <code>--deseq2-pattern</code> to specify a custom regex pattern for group extraction</li> </ol> <p>Example:</p> <p>For samples named: - <code>rna-spikein-control-rep1_R1.fastq.gz</code> - <code>rna-spikein-treated-rep1_R1.fastq.gz</code></p> <p>The generated design will include:</p> assay sample_id r1 r2 scaling_group group deseq2 RNA rna-spikein-control-rep1 ... ... default control 0 RNA rna-spikein-treated-rep1 ... ... default treated 1 <p>The control/reference group is automatically identified and assigned <code>deseq2=0</code>, while treatment groups receive <code>deseq2=1</code>.</p> <p>Best Practices for Sample Naming:</p> <p>To ensure reliable automatic group detection, follow these naming conventions:</p> <ol> <li>Include group identifier before replicate number:</li> <li>Good: <code>sample-control-rep1</code>, <code>sample-treated-rep2</code></li> <li>Good: <code>batch1-WT-rep1</code>, <code>batch1-KO-rep2</code></li> <li> <p>Avoid: <code>sample-rep1-control</code> (group after replicate)</p> </li> <li> <p>Use hyphens or underscores as separators:</p> </li> <li>Good: <code>experiment-drug-day0-rep1</code> or <code>experiment_vehicle_day0_rep1</code></li> <li> <p>Avoid: <code>experimentdrugday0rep1</code> (no separators)</p> </li> <li> <p>Use recognized keywords for control groups:</p> </li> <li>Recognized: <code>control</code>, <code>ctrl</code>, <code>untreated</code>, <code>vehicle</code>, <code>mock</code>, <code>dmso</code>, <code>wt</code>, <code>wildtype</code>, upper or lower case.</li> <li> <p>Example: <code>sample-vehicle-rep1</code> will be automatically identified as the reference group</p> </li> <li> <p>Avoid ambiguous covariate naming:</p> </li> <li> <p>Good: <code>drug-day0-rep1</code>, <code>drug-day7-rep1</code> (group before timepoint)</p> </li> <li> <p>Be consistent across replicates:</p> </li> <li>Good: <code>exp-control-rep1</code>, <code>exp-control-rep2</code>, <code>exp-treated-rep1</code>, <code>exp-treated-rep2</code></li> <li>Avoid: Mixing naming schemes between replicates</li> </ol> <pre><code>seqnado design rna fastqs/* --deseq2-pattern \"-(WT|MUT)-\"\n</code></pre> <p>This extracts groups from patterns like <code>sample-WT-day0_R1.fastq.gz</code> and <code>sample-MUT-day0_R1.fastq.gz</code>.</p> <p>Multi-Group Comparisons:</p> <p>The automatic binary encoding (<code>deseq2</code> column with 0/1) only works for 2-group comparisons (e.g., control vs treated). If your experiment has 3 or more groups (e.g., <code>DMSO-00hr</code>, <code>dTAG-00hr</code>, <code>dTAG-24hr</code>), the tool will:</p> <ol> <li>Populate the <code>group</code> column with all detected groups</li> <li>Leave the <code>deseq2</code> column empty</li> <li>Display a warning message</li> </ol> <p>For multi-group comparisons, you must manually edit the design CSV file to specify contrasts. Common approaches:</p> <ul> <li>Reference-level coding: Assign <code>0</code> to your reference group (e.g., control), and <code>1</code> to all other groups. This requires running separate contrasts pairwise.</li> <li>Treatment contrasts: Map each group to a numeric code (e.g., <code>0</code> = DMSO, <code>1</code> = dTAG-00hr, <code>2</code> = dTAG-24hr) \u2014 but note that standard DESeq2 design formulas expect binary columns, so this requires advanced configuration in the <code>config.yaml</code>.</li> <li>Design matrix: Use the <code>~0 + group</code> formula in your DESeq2 configuration to compare all groups simultaneously.</li> </ul> <p>Consult the Tools Reference and the Troubleshooting guide if you need help configuring multi-group contrasts.</p>"},{"location":"design/#multiomics-mode","title":"Multiomics Mode","text":"<pre><code>seqnado design \n</code></pre> <p>For examples of additional options (auto-discovery, grouping, patterns), consult seqnado design.</p> <p>See Also:</p> <ul> <li>Pipeline Overview - Run your analysis</li> <li>CLI Reference - Complete design command options</li> <li>Troubleshooting - Design file issues</li> </ul>"},{"location":"examples/","title":"Output Examples","text":"<p>This page showcases example outputs from SeqNado pipelines to help you understand what to expect from your analyses. All examples are based on real test data processed through the pipeline.</p>"},{"location":"examples/#seqnado-qc-report","title":"SeqNado QC Report","text":"<p>The main <code>seqnado_report.html</code> provides a MultiQC report with comprehensive quality control metrics.</p>"},{"location":"examples/#report-sections","title":"Report Sections","text":""},{"location":"examples/#1-general-statistics","title":"1. General Statistics","text":"<p>View high-level sample information and key metrics:</p> <ul> <li>Total reads: Raw sequencing depth</li> <li>Mapped reads: Alignment success rate</li> <li>Duplication rate: PCR duplicate percentage</li> <li>GC content: Library GC distribution</li> <li>Insert size: Fragment size metrics (PE data)</li> </ul>"},{"location":"examples/#2-fastqc-results","title":"2. FastQC Results","text":"<p>Quality metrics on raw reads:</p> <ul> <li>Per base sequence quality: Quality scores across read positions</li> <li>Per sequence quality scores: Overall read quality distribution</li> <li>Per base sequence content: Nucleotide balance</li> <li>Sequence duplication levels: Library complexity indicators</li> <li>Adapter content: Contamination levels</li> </ul>"},{"location":"examples/#3-alignment-metrics","title":"3. Alignment Metrics","text":"<p>Mapping statistics from Bowtie2 (DNA assays) or STAR (RNA-seq):</p> <ul> <li>Alignment rates: Percentage uniquely mapped, multimapped, unmapped</li> <li>Paired-end concordance: Proper pair percentages</li> <li>Insert size distribution: Fragment size histograms</li> </ul>"},{"location":"examples/#4-peak-calling-summary-chipataccuttag","title":"4. Peak Calling Summary (ChIP/ATAC/CUT&amp;Tag)","text":"<p>Peak detection results:</p> <ul> <li>Number of peaks: Total peaks called per caller</li> <li>FRiP scores: Fraction of Reads in Peaks (if enabled)</li> <li>Peak caller comparison: Overlap between MACS2, HOMER, LanceOtron, SEACR</li> </ul>"},{"location":"examples/#5-library-complexity","title":"5. Library Complexity","text":"<p>Picard duplicate metrics:</p> <ul> <li>Unique reads: Non-duplicate read counts</li> <li>Duplication rates: PCR duplicate percentages</li> <li>Library complexity estimates: From Picard MarkDuplicates metrics</li> </ul>"},{"location":"examples/#chip-seq-example-output","title":"ChIP-seq Example Output","text":""},{"location":"examples/#directory-structure","title":"Directory Structure","text":"<pre><code>seqnado_output/chip/\n\u251c\u2500\u2500 seqnado_report.html                    # Main QC dashboard\n\u251c\u2500\u2500 protocol.txt                           # Data processing protocol\n\u251c\u2500\u2500 aligned/\n\u2502   \u251c\u2500\u2500 chip-rx_MLL.bam                    # Final processed BAM\n\u2502   \u251c\u2500\u2500 chip-rx_MLL.bam.bai\n\u2502   \u251c\u2500\u2500 chip-rx_input.bam\n\u2502   \u2514\u2500\u2500 chip-rx_input.bam.bai\n\u251c\u2500\u2500 bigwigs/\n\u2502   \u251c\u2500\u2500 bamnado/\n\u2502   \u2502   \u251c\u2500\u2500 chip-rx_MLL.bigWig\n\u2502   \u2502   \u2514\u2500\u2500 chip-rx_input.bigWig\n\u2502   \u251c\u2500\u2500 deeptools/\n\u2502   \u2502   \u251c\u2500\u2500 chip-rx_MLL.bigWig\n\u2502   \u2502   \u2514\u2500\u2500 chip-rx_input.bigWig\n\u2502   \u2514\u2500\u2500 homer/\n\u2502       \u251c\u2500\u2500 chip-rx_MLL.bigWig\n\u2502       \u2514\u2500\u2500 chip-rx_input.bigWig\n\u251c\u2500\u2500 peaks/\n\u2502   \u251c\u2500\u2500 macs2/\n\u2502   \u2502   \u2514\u2500\u2500 chip-rx_MLL.bed               # Simplified 3-column BED\n\u2502   \u251c\u2500\u2500 homer/\n\u2502   \u2502   \u2514\u2500\u2500 chip-rx_MLL.bed\n\u2502   \u2514\u2500\u2500 lanceotron/\n\u2502       \u2514\u2500\u2500 chip-rx_MLL.bed\n\u251c\u2500\u2500 qc/\n\u2502   \u251c\u2500\u2500 fastqc_raw/\n\u2502   \u2502   \u251c\u2500\u2500 chip-rx_MLL_1_fastqc.html\n\u2502   \u2502   \u251c\u2500\u2500 chip-rx_MLL_2_fastqc.html\n\u2502   \u2502   \u251c\u2500\u2500 chip-rx_input_1_fastqc.html\n\u2502   \u2502   \u2514\u2500\u2500 chip-rx_input_2_fastqc.html\n\u2502   \u251c\u2500\u2500 fastq_screen/                      # If enabled\n\u2502   \u2502   \u251c\u2500\u2500 chip-rx_MLL_1_screen.html\n\u2502   \u2502   \u2514\u2500\u2500 chip-rx_input_1_screen.html\n\u2502   \u251c\u2500\u2500 qualimap_bamqc/\n\u2502   \u2502   \u251c\u2500\u2500 chip-rx_MLL/qualimapReport.html\n\u2502   \u2502   \u2514\u2500\u2500 chip-rx_input/qualimapReport.html\n\u2502   \u251c\u2500\u2500 alignment_stats.tsv\n\u2502   \u2514\u2500\u2500 library_complexity/\n\u2502       \u251c\u2500\u2500 chip-rx_MLL.metrics\n\u2502       \u2514\u2500\u2500 chip-rx_input.metrics\n\u251c\u2500\u2500 hub/\n\u2502   \u2514\u2500\u2500 seqnado_hub.hub.txt\n\u2514\u2500\u2500 tag_dirs/\n    \u2514\u2500\u2500 chip-rx_MLL/\n</code></pre>"},{"location":"examples/#example-peak-file-content","title":"Example Peak File Content","text":"<p>SeqNado outputs simplified 3-column BED files for all peak callers:</p> <p>BED format (<code>chip-rx_MLL.bed</code>):</p> <pre><code>chr1    3054728    3055228\nchr1    3669834    3670334\nchr2    5847291    5847791\n...\n</code></pre> <p>Columns:</p> <ol> <li>Chromosome</li> <li>Start position</li> <li>End position</li> </ol>"},{"location":"examples/#atac-seq-example-output","title":"ATAC-seq Example Output","text":""},{"location":"examples/#directory-structure_1","title":"Directory Structure","text":"<pre><code>seqnado_output/atac/\n\u251c\u2500\u2500 seqnado_report.html\n\u251c\u2500\u2500 protocol.txt\n\u251c\u2500\u2500 aligned/\n\u2502   \u251c\u2500\u2500 atac_sample.bam                    # Tn5-shifted, filtered BAM\n\u2502   \u2514\u2500\u2500 atac_sample.bam.bai\n\u251c\u2500\u2500 bigwigs/\n\u2502   \u251c\u2500\u2500 bamnado/\n\u2502   \u2502   \u2514\u2500\u2500 atac_sample.bigWig\n\u2502   \u251c\u2500\u2500 deeptools/\n\u2502   \u2502   \u2514\u2500\u2500 atac_sample.bigWig\n\u2502   \u2514\u2500\u2500 homer/\n\u2502       \u2514\u2500\u2500 atac_sample.bigWig\n\u251c\u2500\u2500 peaks/\n\u2502   \u2514\u2500\u2500 lanceotron/                        # Default peak caller for ATAC\n\u2502       \u2514\u2500\u2500 atac_sample.bed\n\u251c\u2500\u2500 qc/\n\u2502   \u251c\u2500\u2500 fastqc_raw/\n\u2502   \u251c\u2500\u2500 qualimap_bamqc/\n\u2502   \u2502   \u2514\u2500\u2500 atac_sample/\n\u2502   \u2502       \u2514\u2500\u2500 qualimapReport.html\n\u2502   \u251c\u2500\u2500 alignment_stats.tsv\n\u2502   \u2514\u2500\u2500 library_complexity/\n\u2502       \u2514\u2500\u2500 atac_sample.metrics\n\u2514\u2500\u2500 hub/\n    \u2514\u2500\u2500 seqnado_hub.hub.txt\n</code></pre> <p>Note</p> <p>All intermediate BAM processing stages (sorting, blacklist removal, duplicate removal, Tn5 shifting, filtering) are temporary and automatically deleted. Only the final <code>aligned/{sample}.bam</code> is retained.</p>"},{"location":"examples/#atac-seq-quality-indicators","title":"ATAC-seq Quality Indicators","text":"<p>Key metrics to check in the MultiQC report:</p> Metric Good Quality What to Look For Nucleosome periodicity Clear peaks at ~200bp intervals Visible in insert size distribution Mitochondrial % &lt;10% Low mitochondrial read contamination FRiP score &gt;30% High fraction of reads in peaks Unique reads &gt;80% Good library complexity"},{"location":"examples/#fragment-size-distribution","title":"Fragment Size Distribution","text":"<p>ATAC-seq shows characteristic nucleosome-free (~150bp) and mono-nucleosome (~200bp) peaks, visible in the insert size distribution within the MultiQC report.</p>"},{"location":"examples/#qualimap-bam-qc-report","title":"Qualimap BAM QC Report","text":"<p>The Qualimap reports provide detailed alignment quality metrics. For RNA-seq, <code>qualimap_rnaseq</code> is used instead of <code>qualimap_bamqc</code>.</p>"},{"location":"examples/#key-visualisations","title":"Key Visualisations","text":"<p>Coverage Histogram</p> <ul> <li>Distribution of genome coverage depths</li> <li>Helps identify over/under-sequenced regions</li> <li>Shows sequencing uniformity</li> </ul> <p>Insert Size Distribution</p> <ul> <li>Fragment size histogram for paired-end data</li> <li>Critical for ATAC-seq quality assessment</li> <li>Reveals nucleosome positioning</li> </ul> <p>GC Content Distribution</p> <ul> <li>AT/GC bias detection</li> <li>Compares observed vs theoretical</li> <li>Identifies contamination or bias</li> </ul> <p>Mapping Quality</p> <ul> <li>Distribution of MAPQ scores</li> <li>Higher scores = more confident alignments</li> <li>Helps assess multi-mapping issues</li> </ul>"},{"location":"examples/#example-fastq-screen-results","title":"Example FastQ Screen Results","text":"<p>FastQ Screen checks for contamination across reference genomes (when enabled via <code>run_fastq_screen</code>):</p>"},{"location":"examples/#typical-clean-sample","title":"Typical Clean Sample","text":"<pre><code>Library: chip-rx_MLL_1\nGenome          %Mapping    %One_hit    %Multi_hit    Status\n--------------------------------------------------------------\nHuman (hg38)    98.2%       85.4%       12.8%         OK\nMouse (mm10)     0.8%        0.5%        0.3%         OK\nE. coli          0.0%        0.0%        0.0%         OK\nAdapters         0.3%        0.3%        0.0%         OK\nPhiX             0.0%        0.0%        0.0%         OK\n</code></pre>"},{"location":"examples/#concerning-sample-contamination","title":"Concerning Sample (Contamination)","text":"<pre><code>Library: sample_contaminated\nGenome          %Mapping    %One_hit    %Multi_hit    Status\n--------------------------------------------------------------\nHuman (hg38)    65.2%       58.4%        6.8%         WARNING\nMouse (mm10)    32.8%       29.5%        3.3%         WARNING\nE. coli          1.2%        1.1%        0.1%         WARNING\n</code></pre>"},{"location":"examples/#homer-tag-directory","title":"HOMER Tag Directory","text":"<p>HOMER creates tag directories for downstream analysis:</p> <pre><code>tag_dirs/chip-rx_MLL/\n\u251c\u2500\u2500 tagInfo.txt                     # Read statistics\n\u251c\u2500\u2500 tagLengthDistribution.txt       # Fragment sizes\n\u251c\u2500\u2500 tagCountDistribution.txt        # Tag depth per position\n\u251c\u2500\u2500 freqDistribution.txt            # Frequency statistics\n\u251c\u2500\u2500 chr1.tags.tsv                   # Per-chromosome tags\n\u251c\u2500\u2500 chr2.tags.tsv\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"examples/#bigwig-coverage-tracks","title":"BigWig Coverage Tracks","text":"<p>BigWig files provide genome-wide signal visualisation.</p>"},{"location":"examples/#file-naming-convention","title":"File Naming Convention","text":"<p>BigWig files are organised by tool, scaling method, and individual vs merged:</p> <pre><code>Individual samples:\n- bigwigs/deeptools/chip-rx_MLL.bigWig              # Unscaled\n- bigwigs/bamnado/chip-rx_MLL.bigWig\n- bigwigs/homer/chip-rx_MLL.bigWig\n- bigwigs/deeptools/csaw/chip-rx_MLL.bigWig         # CSAW-normalised\n- bigwigs/deeptools/spikein/orlando/chip-rx_MLL.bigWig  # Spike-in normalised\n\nMerged consensus groups:\n- bigwigs/deeptools/merged/consensus_group.bigWig             # Unscaled merged\n- bigwigs/deeptools/merged/csaw/consensus_group.bigWig        # CSAW-scaled merged\n- bigwigs/deeptools/merged/spikein/orlando/consensus_group.bigWig  # Spike-in scaled merged\n</code></pre> <p>See Pipeline Outputs \u2014 Normalisation factor calculation for a full explanation of how per-sample and merged scale factors are derived.</p> <p>For RNA-seq, stranded tracks include <code>_plus</code> and <code>_minus</code> suffixes:</p> <pre><code>- bigwigs/deeptools/rna_sample_plus.bigWig\n- bigwigs/deeptools/rna_sample_minus.bigWig\n</code></pre>"},{"location":"examples/#loading-in-ucsc-genome-browser","title":"Loading in UCSC Genome Browser","text":"<ol> <li>Upload BigWig files to a web-accessible location</li> <li>Or use the auto-generated hub at <code>hub/seqnado_hub.hub.txt</code></li> <li>Tracks display sample signal across genome</li> <li>Compare multiple samples side-by-side</li> </ol>"},{"location":"examples/#geo-submission-files","title":"GEO Submission Files","text":"<p>Ready-to-submit files for GEO/SRA (when enabled):</p> <pre><code>geo_submission/\n\u251c\u2500\u2500 samples_table.txt                       # Sample metadata (TSV format)\n\u251c\u2500\u2500 md5sums.txt                             # Combined checksums\n\u251c\u2500\u2500 raw_data_checksums.txt                  # Checksums for raw FASTQs\n\u251c\u2500\u2500 processed_data_checksums.txt            # Checksums for processed files\n\u251c\u2500\u2500 upload_instructions.txt                 # GEO upload instructions\n\u251c\u2500\u2500 chip-rx_MLL_1.fastq.gz                  # Symlinks to raw FASTQ R1\n\u251c\u2500\u2500 chip-rx_MLL_2.fastq.gz                  # Symlinks to raw FASTQ R2\n\u251c\u2500\u2500 chip-rx_MLL_deeptools_unscaled.bigWig   # Renamed processed files\n\u251c\u2500\u2500 chip-rx_MLL_macs2.bed                   \n\u2514\u2500\u2500 chip/                                   # Upload directory\n</code></pre> <p>Files are flattened from the nested directory structure into a single directory with descriptive filenames that encode the tool and scaling method.</p>"},{"location":"examples/#genome-browser-plots-plotnado","title":"Genome Browser Plots (PlotNado)","text":"<p>Publication-ready visualisations of genomic regions (when plotting coordinates are configured):</p>"},{"location":"examples/#output-files","title":"Output Files","text":"<pre><code>genome_browser_plots/\n\u251c\u2500\u2500 MYC_promoter.svg             # Named region from BED file\n\u251c\u2500\u2500 chr1-1000000-1005000.svg     # Unnamed region uses coordinates\n\u2514\u2500\u2500 template.toml                # PlotNado configuration template\n</code></pre> <p>Plot filenames are derived from the Name column in the input BED file, or from <code>{chr}-{start}-{end}</code> if no name is provided. Output format can be <code>svg</code>, <code>png</code>, or <code>pdf</code> as configured.</p>"},{"location":"examples/#tips-for-exploring-outputs","title":"Tips for Exploring Outputs","text":""},{"location":"examples/#quick-quality-check","title":"Quick Quality Check","text":"<pre><code># Check main report\nfirefox seqnado_output/chip/seqnado_report.html\n\n# Count peaks called\nwc -l seqnado_output/chip/peaks/macs2/*.bed\n\n# View alignment stats\nsamtools flagstat seqnado_output/chip/aligned/chip-rx_MLL.bam\n\n# Check bigwig file\nbigWigInfo seqnado_output/chip/bigwigs/deeptools/chip-rx_MLL.bigWig\n</code></pre>"},{"location":"examples/#finding-specific-results","title":"Finding Specific Results","text":"<pre><code># All HTML reports\nfind seqnado_output/ -name \"*.html\"\n\n# All peak files\nfind seqnado_output/ -name \"*.bed\"\n\n# All coverage tracks\nfind seqnado_output/ -name \"*.bigWig\"\n</code></pre>"},{"location":"examples/#understanding-file-formats","title":"Understanding File Formats","text":""},{"location":"examples/#bam-files","title":"BAM Files","text":"<ul> <li>Binary alignment format (<code>.bam</code> extension)</li> <li>Stores aligned sequencing reads</li> <li>Includes alignment quality, CIGAR strings, and flags</li> </ul>"},{"location":"examples/#bigwig-files","title":"BigWig Files","text":"<ul> <li>Binary coverage track format (<code>.bigWig</code> extension)</li> <li>Efficient genome browser visualisation</li> <li>Contains normalised signal values</li> </ul>"},{"location":"examples/#bed-files","title":"BED Files","text":"<ul> <li>Tab-delimited genomic coordinates (<code>.bed</code> extension)</li> <li>SeqNado peak outputs use 3-column BED: chr, start, end</li> <li>Standard BED can include additional columns (name, score, strand)</li> </ul>"},{"location":"examples/#fastq-files","title":"FastQ Files","text":"<ul> <li>Raw sequencing reads (<code>.fastq.gz</code> extension)</li> <li>Four lines per read: header, sequence, +, quality scores</li> <li>Usually gzip compressed (.gz)</li> </ul> <p>For more information on interpreting these outputs for your specific experiment, consult the Pipeline Overview.</p>"},{"location":"faq/","title":"FAQ","text":"<p>\u2190 Back to main page</p>"},{"location":"faq/#faq","title":"FAQ","text":""},{"location":"faq/#pipeline-initialisation","title":"Pipeline initialisation","text":""},{"location":"faq/#workflow-defines-configfile-config_chipyml-but-it-is-not-present-or-accessible","title":"Workflow defines configfile config_chip.yml but it is not present or accessible.","text":"<p>This error occurs when the pipeline is run without a config file present in the working directory. Ensure that seqnado-config has been run before starting the pipeline and that you are in the new directory created by seqnado-config.</p> <p>Follow the Configuration Guide instructions to create a config file.</p>"},{"location":"faq/#singularity-configuration","title":"Singularity configuration","text":""},{"location":"faq/#workflow-error","title":"Workflow Error","text":"<p>Failed to pull singularity image from library://asmith151/seqnado/seqnado_pipeline:latest: FATAL: Unable to get library client configuration: remote has no library client (see https://apptainer.org/docs/user/latest/endpoint.html#no-default-remote)</p> <p>Fix:</p> <p>re-run seqnado init: See the Initialisation Guide</p> <p>or</p> <pre><code>apptainer remote add --no-login SylabsCloud cloud.sylabs.io  \napptainer remote use SylabsCloud  \n</code></pre>"},{"location":"faq/#optional-configuration","title":"Optional configuration","text":""},{"location":"faq/#can-i-merge-multiple-samples-into-a-single-sample","title":"Can I merge multiple samples into a single sample?","text":"<p>Yes, you can merge multiple samples into a single sample to generate merged bigWig files and consensus peaks. To do this, you need to create a design file that specifies the samples to be merged. The design file should have a column named \"merge\" that specifies the samples to be merged e.g.:</p> sample r1 r2 deseq2 merge rna1 /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna1_2.fastq.gz /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna1_1.fastq.gz control control rna2 /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna2_2.fastq.gz /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna2_1.fastq.gz control control rna3 /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna3_2.fastq.gz /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna3_1.fastq.gz control control rna4 /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna4_2.fastq.gz /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna4_1.fastq.gz treated treated rna5 /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna5_2.fastq.gz /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna5_1.fastq.gz treated treated rna6 /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna6_2.fastq.gz /tmp/pytest-of-asmith/pytest-7/data2/2024-01-13_rna_test/rna6_1.fastq.gz treated treated"},{"location":"genomes/","title":"Genome Setup","text":"<p>\u2190 Back to main page</p>"},{"location":"genomes/#genome-setup","title":"Genome Setup","text":"<p>After successful initialization of SeqNado (Initialisation), use <code>seqnado genomes</code> to manage reference genomes.</p>"},{"location":"genomes/#subcommands","title":"Subcommands","text":"Subcommand Description <code>list</code> Show available genome configurations <code>edit</code> Open the user genome config in <code>$EDITOR</code> <code>build</code> Download a genome from UCSC and build indices via Snakemake <code>fastqscreen</code> Generate a FastqScreen configuration file"},{"location":"genomes/#building-a-genome","title":"Building a Genome","text":"<p><code>seqnado genomes build</code> downloads the FASTA, GTF, chromosome sizes, and blacklist from UCSC, then builds Bowtie2 and STAR indices.</p>"},{"location":"genomes/#dependencies","title":"\u26a0\ufe0f Dependencies","text":"<p>The genome build workflow requires samtools, Bowtie2, and STAR. These are not installed by default in a basic SeqNado environment.</p> <p>Use <code>--preset</code> to ensure dependencies are available:</p> <ul> <li><code>--preset ls</code> (recommended) \u2014 Uses Apptainer/Singularity to provide all tools</li> <li><code>--preset ss</code> \u2014 On SLURM clusters with Apptainer/Singularity</li> <li><code>--preset lc</code> \u2014 Local execution with Conda + Apptainer</li> <li><code>--preset le</code> (default) \u2014 Requires manual installation of dependencies</li> </ul> <p>All examples below include <code>--preset ls</code>. If using a different environment, adjust accordingly.</p>"},{"location":"genomes/#single-genome","title":"Single genome","text":"<pre><code>seqnado genomes build --name hg38 --outdir /path/to/genomes --preset ls\n</code></pre>"},{"location":"genomes/#multiple-genomes","title":"Multiple genomes","text":"<p>Comma-separate names to build several genomes in one run:</p> <pre><code>seqnado genomes build --name hg38,mm39,dm6 --outdir /path/to/genomes --preset ls\n</code></pre>"},{"location":"genomes/#spike-in-composite-genome","title":"Spike-in (composite) genome","text":"<p>Combine a primary genome with a spike-in. This downloads both genomes, concatenates their FASTA and GTF, and builds composite indices:</p> <pre><code>seqnado genomes build --name hg38 --spikein dm6 --outdir /path/to/genomes --preset ls\n</code></pre> <p>The composite genome is named <code>hg38_dm6</code> and spike-in chromosomes are prefixed (e.g. <code>dm6_chr2L</code>).</p>"},{"location":"genomes/#dry-run","title":"Dry run","text":"<p>Preview planned jobs without executing them:</p> <pre><code>seqnado genomes build --name hg38 --outdir /path/to/genomes --preset ls --dry-run\n</code></pre>"},{"location":"genomes/#what-gets-built","title":"What gets built","text":"<p>For each genome, the workflow produces the following output structure:</p> <pre><code>&lt;outdir&gt;/&lt;genome&gt;/\n\u251c\u2500\u2500 sequence/\n\u2502   \u251c\u2500\u2500 &lt;genome&gt;.fa          # FASTA (downloaded from UCSC)\n\u2502   \u251c\u2500\u2500 &lt;genome&gt;.fa.fai      # samtools faidx index\n\u2502   \u2514\u2500\u2500 &lt;genome&gt;.chrom.sizes # chromosome sizes\n\u251c\u2500\u2500 genes/\n\u2502   \u2514\u2500\u2500 &lt;genome&gt;.ncbiRefSeq.gtf  # gene annotations\n\u251c\u2500\u2500 bt2_index/\n\u2502   \u2514\u2500\u2500 &lt;genome&gt;.*.bt2      # Bowtie2 index\n\u251c\u2500\u2500 STAR_2.7.10b/            # STAR index directory\n\u2514\u2500\u2500 &lt;genome&gt;-blacklist.bed.gz  # ENCODE blacklist regions\n</code></pre>"},{"location":"genomes/#genome-config-auto-update","title":"Genome config auto-update","text":"<p>On successful completion, the build automatically registers the genome in <code>~/.config/seqnado/genome_config.json</code>. This makes it immediately available for pipeline runs \u2014 no manual editing needed.</p>"},{"location":"genomes/#build-options","title":"Build options","text":"Option Default Description <code>--name</code>, <code>-n</code> (required) Genome name(s), comma-separated <code>--outdir</code>, <code>-o</code> <code>./genome_build</code> Output directory <code>--spikein</code>, <code>-sp</code> \u2014 Spike-in genome name for composite builds <code>--preset</code> <code>le</code> Snakemake profile preset (see below) <code>--profile</code> \u2014 Path to a Snakemake profile directory (overrides --preset) <code>--cores</code>, <code>-c</code> <code>4</code> Number of cores available to Snakemake; controls max parallelism and threads per rule <code>--scale-resources</code> <code>1.0</code> Scale memory/time requests <code>--dry-run</code> off Preview the Snakemake DAG without executing <code>--verbose</code>, <code>-v</code> off Print the full Snakemake command"},{"location":"genomes/#presets","title":"Presets","text":"<p>Presets select a Snakemake execution profile. For genome builds, use a preset that includes samtools, Bowtie2, and STAR:</p> Preset Tools included? Environment Description <code>le</code> \u274c No Local Requires manual tool installation (not recommended for genome builds) <code>ls</code> \u2705 Yes Local Singularity/Apptainer containers (recommended) <code>lc</code> \u2705 Yes Local Conda + Singularity <code>ld</code> \u2705 Yes Local Docker + Conda <code>ss</code> \u2705 Yes SLURM cluster Singularity/Apptainer containers on HPC <code>t</code> \u2705 Yes Local Testing/development"},{"location":"genomes/#listing-genomes","title":"Listing Genomes","text":"<p>Show all configured genomes and their paths:</p> <pre><code>seqnado genomes list\n</code></pre>"},{"location":"genomes/#editing-genome-config","title":"Editing Genome Config","text":"<p>Open <code>~/.config/seqnado/genome_config.json</code> in your editor:</p> <pre><code>seqnado genomes edit\n</code></pre> <p>Set <code>$EDITOR</code> to your preferred editor (defaults to <code>nano</code>).</p>"},{"location":"genomes/#fastqscreen-configuration","title":"FastqScreen Configuration","text":"<p>FastQ Screen checks for sample contamination by aligning reads against a set of reference genomes. SeqNado can auto-generate the <code>fastq_screen.conf</code> configuration file from your built genomes.</p> <p>Key distinction: - <code>--contaminant-path</code> = input (where your contaminant reference indices are located) - <code>--screen</code> = output (where to save the generated config file)</p>"},{"location":"genomes/#generating-the-config","title":"Generating the config","text":"<pre><code>seqnado genomes fastqscreen\n</code></pre> <p>This reads your genome config (<code>~/.config/seqnado/genome_config.json</code>), finds each genome's Bowtie2 index, and writes a <code>fastq_screen.conf</code> with a <code>DATABASE</code> entry per genome. Organism names (Human, Mouse, Drosophila, etc.) are inferred automatically from the genome prefix (e.g. <code>hg38</code> \u2192 Human, <code>mm39</code> \u2192 Mouse).</p>"},{"location":"genomes/#adding-contaminant-databases","title":"Adding contaminant databases","text":"<p>By default, the command prompts for a path to contaminant reference files. If provided, it adds common contaminant screens (E. coli, PhiX, rRNA, adapters, etc.).</p> <p>A pre-built set of contaminant references is available. Download and extract it:</p> <pre><code>wget https://userweb.molbiol.ox.ac.uk/public/project/milne_group/seqnado/genomes/fastqscreen_reference.tar.gz\ntar -xzf fastqscreen_reference.tar.gz\n</code></pre> <p>Then generate the config with contaminants:</p> <pre><code># Quick example: contaminants in current directory\nseqnado genomes fastqscreen --contaminant-path ./fastqscreen_reference\n\n# Specify custom output path\nseqnado genomes fastqscreen --contaminant-path ./fastqscreen_reference --screen /path/to/my_fastq_screen.conf\n\n# Skip contaminants entirely\nseqnado genomes fastqscreen --no-contaminants\n</code></pre> <p>The contaminant directory should contain Bowtie2 indices organised in subdirectories:</p> <pre><code>fastqscreen_reference/\n\u251c\u2500\u2500 E_coli/Ecoli.*bt2\n\u251c\u2500\u2500 PhiX/phi_plus_SNPs.*bt2\n\u251c\u2500\u2500 rRNA/GRCm38_rRNA.*bt2\n\u251c\u2500\u2500 Vectors/Vectors.*bt2\n\u251c\u2500\u2500 Adapters/Contaminants.*bt2\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"genomes/#options","title":"Options","text":"Option Default Description <code>--screen</code>, <code>-s</code> <code>~/.config/seqnado/fastq_screen.conf</code> Output path: Where to write the generated <code>fastq_screen.conf</code> <code>--contaminant-path</code> (prompted) Input path: Directory containing contaminant Bowtie2 indices <code>--threads</code>, <code>-t</code> <code>8</code> Bowtie2 threads used by FastQ Screen <code>--no-contaminants</code> off Skip contaminant databases <p>See Also:</p> <ul> <li>Configuration Guide - Configure your analysis</li> <li>CLI Reference - Complete genomes command options</li> <li>Troubleshooting - Genome setup issues</li> </ul>"},{"location":"geo_download/","title":"GEO/SRA Data Download","text":"<p>This document describes how to use SeqNado to download data from GEO/SRA.</p>"},{"location":"geo_download/#quick-start","title":"Quick Start","text":""},{"location":"geo_download/#1-get-metadata-from-geoena","title":"1. Get metadata from GEO/ENA","text":"<p>First, obtain the metadata TSV file from GEO or ENA. For example: - Go to ENA Browser - Search for your project (e.g., PRJNA1234567) - Download the \"TSV\" report with run information</p> <p>Required columns: - <code>run_accession</code> (e.g., SRR123456) - <code>sample_title</code> (sample name) - <code>library_name</code> (e.g., GSM identifier) - <code>library_layout</code> (PAIRED or SINGLE) - Required for download</p> <p>The <code>library_layout</code> column is essential for determining whether to create one or two FASTQ files per sample.</p> <p>It is advisable to alter the <code>sample_title</code> column to use seqnado naming conventions, removing any spaces.  See Configuration for more details.</p>"},{"location":"geo_download/#2-download-fastqs","title":"2. Download FASTQs","text":"<p>Run the download command:</p> <pre><code>seqnado download filereport_read_run_PRJNA1234567.tsv \\\n    --outdir fastqs \\\n    --cores 8\n</code></pre> <p>This will: - Parse the metadata TSV - Download all FASTQ files using prefetch/fasterq-dump - Retry failed downloads with scaled resources on each attempt - Compress and rename files to: <code>{GSM}-{sample}_R1.fastq.gz</code></p>"},{"location":"geo_download/#3-generate-design-file-optional","title":"3. Generate design file (optional)","text":"<p>To also generate a SeqNado design file:</p> <pre><code>seqnado download filereport_read_run_PRJNA1234567.tsv \\\n    --outdir fastqs \\\n    --assay rna \\\n    --design-output metadata_rna.csv \\\n    --cores 8\n</code></pre> <p>Or run separately after download:</p> <pre><code>seqnado design rna --output metadata_rna.csv fastqs/*.fastq.gz\n</code></pre>"},{"location":"geo_download/#command-reference","title":"Command Reference","text":"<pre><code>seqnado download [OPTIONS] METADATA_TSV\n</code></pre>"},{"location":"geo_download/#required-arguments","title":"Required Arguments","text":"<ul> <li><code>METADATA_TSV</code>: Path to TSV file from GEO/ENA with run information</li> </ul>"},{"location":"geo_download/#options","title":"Options","text":"<ul> <li><code>-o, --outdir PATH</code>: Output directory for FASTQ files (default: fastqs)</li> <li><code>-a, --assay TEXT</code>: Assay type for design file generation (rna, atac, chip, etc.)</li> <li><code>-d, --design-output PATH</code>: Output path for design CSV</li> <li><code>-c, --cores INT</code>: Number of parallel downloads (default: 4)</li> <li><code>--preset TEXT</code>: Snakemake profile preset (le/lsf/ss) (default: le)</li> <li><code>--profile PATH</code> / <code>--profiles PATH</code>: Path to a Snakemake profile directory (overrides --preset)</li> <li><code>-n, --dry-run</code>: Show what would be downloaded without downloading</li> <li><code>-v, --verbose</code>: Increase logging verbosity</li> </ul>"},{"location":"geo_download/#examples","title":"Examples","text":""},{"location":"geo_download/#download-only","title":"Download only","text":"<pre><code>seqnado download filereport.tsv --outdir fastqs -c 10\n</code></pre>"},{"location":"geo_download/#download-generate-rna-seq-design","title":"Download + generate RNA-seq design","text":"<pre><code>seqnado download filereport.tsv \\\n    --outdir fastqs \\\n    --assay rna \\\n    -c 8\n</code></pre>"},{"location":"geo_download/#download-chip-seq-data-design","title":"Download ChIP-seq data + design","text":"<pre><code>seqnado download filereport.tsv \\\n    --outdir fastqs \\\n    --assay chip \\\n    --design-output metadata_chip.csv\n</code></pre>"},{"location":"geo_download/#dry-run-to-see-what-would-happen","title":"Dry run to see what would happen","text":"<pre><code>seqnado download filereport.tsv --dry-run\n</code></pre>"},{"location":"geo_download/#file-naming","title":"File Naming","text":"<p>Downloaded files are automatically named based on library layout:</p>"},{"location":"geo_download/#paired-end-data","title":"Paired-End Data","text":"<pre><code>{library_name}-{sample_title}_R1.fastq.gz\n{library_name}-{sample_title}_R2.fastq.gz\n</code></pre>"},{"location":"geo_download/#single-end-data","title":"Single-End Data","text":"<pre><code>{library_name}-{sample_title}.fastq.gz\n</code></pre> <p>For example: - Paired: <code>GSM12345-WT_rep1_R1.fastq.gz</code>, <code>GSM12345-WT_rep1_R2.fastq.gz</code> - Single: <code>GSM12345-WT_rep1.fastq.gz</code></p>"},{"location":"geo_download/#library-layout-detection","title":"Library Layout Detection","text":"<p>The download command uses the <code>library_layout</code> column from your TSV to determine how to process each sample:</p> <ul> <li>PAIRED: Uses <code>geo_download_paired</code> rule \u2192 creates <code>_R1.fastq.gz</code> and <code>_R2.fastq.gz</code></li> <li>SINGLE: Uses <code>geo_download_single</code> rule \u2192 creates <code>.fastq.gz</code> (no R1/R2 suffix)</li> </ul> <p>This approach ensures proper file structure without creating empty placeholder files.</p>"},{"location":"geo_download/#troubleshooting","title":"Troubleshooting","text":""},{"location":"geo_download/#download-fails","title":"Download fails","text":"<p>The download rule includes automatic retry logic via Snakemake's resource scaling \u2014 memory and time are doubled on each retry attempt. Check logs for details: - Full logging in <code>logs/geo_download/{sample}.log</code></p>"},{"location":"geo_download/#missing-columns-in-tsv","title":"Missing columns in TSV","text":"<p>Make sure your TSV has these required columns: - <code>run_accession</code> - <code>sample_title</code> - <code>library_name</code> - <code>library_layout</code> (with values 'PAIRED' or 'SINGLE')</p> <p>The <code>library_layout</code> column is typically included in TSV downloads from ENA. If it's missing from your source: 1. Check the SRA/GEO database for the layout information 2. Add it manually to your TSV file 3. Or download the full metadata from ENA which includes this column</p>"},{"location":"geo_download/#memory-issues","title":"Memory issues","text":"<p>If downloads run out of memory, adjust the resources in the Snakemake profile or reduce the number of parallel downloads with <code>-c</code>.</p>"},{"location":"geo_download/#integration-with-seqnado-pipeline","title":"Integration with SeqNado Pipeline","text":"<p>After downloading and generating a design file, you can run the full SeqNado pipeline:</p> <pre><code># 1. Download data\nseqnado download filereport.tsv --outdir fastqs --assay rna\n\n# 2. Generate config\nseqnado config rna\n\n# 3. Run pipeline\nseqnado pipeline rna -c 20\n</code></pre>"},{"location":"initialisation/","title":"Initialisation","text":"<p>\u2190 Back to main page</p>"},{"location":"initialisation/#initialisation","title":"Initialisation","text":"<p>After successful installation of SeqNado (Installation).</p>"},{"location":"initialisation/#initialize-the-workflow","title":"Initialize the Workflow","text":"<p>Run the following command to initialize the SeqNado workflow in your project directory:</p> <pre><code>seqnado init\n</code></pre> <p>This will create the necessary configuration files and directory structure for your environment.</p>"},{"location":"initialisation/#additional-initialization-options","title":"Additional Initialization Options","text":"<p>For all available flags and details, see the CLI reference: seqnado init.</p>"},{"location":"initialisation/#example-usage","title":"Example Usage","text":"<p>To initialize SeqNado with preset genomes and verbose logging:</p> <pre><code>seqnado init --preset --verbose\n</code></pre> <p>To perform a dry run and preview the initialization steps:</p> <pre><code>seqnado init --dry-run\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<p>\u2190 Back to main page</p>"},{"location":"installation/#installation","title":"Installation","text":"<p>SeqNado can be installed using either <code>mamba</code> or <code>pip</code>. Follow the steps below to set up the package:</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing SeqNado, ensure that you have the following tools installed on your system:</p> <ul> <li> <p>Mamba/Conda: Required for managing environments and dependencies. Install Conda from Miniconda or Anaconda, and then install Mamba:   <pre><code>conda install -n base -c conda-forge mamba\n</code></pre></p> </li> <li> <p>Pip: Comes pre-installed with Python. Verify installation:   <pre><code>pip --version\n</code></pre></p> </li> </ul> <p>If these tools are not installed, follow the links provided to set them up before proceeding with SeqNado installation.</p>"},{"location":"installation/#install-from-bioconda","title":"Install from Bioconda","text":"<p>SeqNado is available on Bioconda. To install: <pre><code>mamba install -c bioconda seqnado\n</code></pre></p>"},{"location":"installation/#install-from-pypi","title":"Install from PyPI","text":"<p>SeqNado is also available on PyPI. To install: <pre><code>pip install seqnado\n</code></pre></p>"},{"location":"installation/#initialize-after-install","title":"Initialize after install","text":"<p>Once installed, initialize SeqNado in your environment:</p> <pre><code>seqnado init\n</code></pre> <p>For all flags and details, see the CLI reference: seqnado init.</p> <p>See Also:</p> <ul> <li>Initialisation Guide - Set up your SeqNado environment</li> <li>Quick Start - Complete workflow example</li> <li>Troubleshooting - Common installation issues</li> </ul>"},{"location":"normalisation/","title":"Normalisation Methods","text":"<p>SeqNado supports several normalisation strategies for generating coverage bigwig files. This page documents the exact formula used by each method, how per-sample factors are applied, and how factors are derived for merged consensus-group bigwigs.</p>"},{"location":"normalisation/#quick-start-tldr","title":"Quick Start (TL;DR)","text":"<p>ChIP-seq with spike-in? Use <code>orlando</code> for simplicity or <code>with_input</code> if you have paired input controls. RNA-seq? Use <code>deseq2</code> or <code>edgeR</code> \u2014 they correct for compositional bias. No spike-in and expect similar global levels across conditions? Use <code>csaw</code>. Need help choosing? See Choosing a Method below.</p>"},{"location":"normalisation/#summary-table","title":"Summary Table","text":"Method Assay Input data Per-sample formula Merged formula Signal Unit unscaled Any BAM files \\(1\\) \\(1\\) As set in deeptools/bamnado/homer configuration orlando ChIP-seq, CUT&amp;TAG, CUT&amp;RUN Spike-in BAM read counts \\(10^6 / S_{\\text{ip}}\\) \\(10^6 / \\sum_i S_{\\text{ip},i}\\) RRPM (spike-in reference-adjusted RPM) with_input ChIP-seq, CUT&amp;TAG, CUT&amp;RUN Spike-in BAM read counts (IP + input) \\((S_{\\text{ctrl}} \\times 10^7) / (S_{\\text{ip}} \\times R_{\\text{ctrl}})\\) \\((\\sum S_{\\text{ctrl},i} \\times 10^7) / (\\sum S_{\\text{ip},i} \\times \\sum R_{\\text{ctrl},i})\\) RRPM (IP enrichment over spike-in-normalized input) deseq2 RNA-seq Spike-in gene count matrix DESeq2 median-ratio \\(\\hat{s}_j\\) Arithmetic mean \\(\\bar{\\hat{s}}\\) Library-size normalized edgeR RNA-seq Spike-in gene count matrix edgeR TMM \\(\\hat{f}_j^{\\text{TMM}}\\) Arithmetic mean \\(\\bar{\\hat{f}}^{\\text{TMM}}\\) Library-size normalized csaw ChIP-seq, CUT&amp;TAG, CUT&amp;RUN, ATAC-seq (RNA-seq: see note) Genomic bin read counts \\(\\bar{L} / L_j\\) \\(1 / \\sum_i (1/s_i)\\) CPM (library-size normalized, within group)"},{"location":"normalisation/#spike-in-normalisation","title":"Spike-in Normalisation","text":"<p>Spike-in normalisation uses a known amount of exogenous material (chromatin or RNA from a different species) added to each library before sequencing. Because the amount added is constant, the number of reads mapping to the spike-in reflects sequencing depth and can be used to normalise samples to a comparable scale. SeqNado implements three spike-in strategies \u2014 two based on total spike-in read counts (orlando, with_input) and two based on gene-level counting from a spike-in-aware count matrix (deseq2, edgeR).</p>"},{"location":"normalisation/#orlando-reads-per-million-spike-in","title":"Orlando (Reads-Per-Million Spike-in)","text":"<p>Reference: Orlando DA, Chen MW, Brown VE, Solanki S, Choi YJ, Olson ER, Fritz CC, Bradner JE, Guenther MG. Quantitative ChIP-Seq Normalization Reveals Global Modulation of the Epigenome. Cell Reports. 2014;9(3):1163\u20131170. doi:10.1016/j.celrep.2014.10.018</p> <p>Designed for: ChIP-seq, CUT&amp;TAG, CUT&amp;RUN (any assay that uses chromatin spike-in).</p> <p>Concept: Scale each sample so that one million spike-in reads would have been sequenced, making signal proportional to the absolute amount of chromatin immunoprecipitated.</p> <p>In plain terms</p> <p>You added a fixed amount of exogenous chromatin (e.g. Drosophila) to each ChIP sample before sequencing. Samples that were sequenced more deeply will produce more spike-in reads, but the amount of spike-in chromatin was the same. By dividing every sample's signal by its spike-in read count, you remove the effect of unequal sequencing depth and make signals directly comparable across samples \u2014 a bigger signal in the bigwig means more protein was genuinely bound, not just that more reads were generated.</p> <p>Per-sample formula:</p> \\[ \\text{scale_factor} = \\frac{10^6}{S_{\\text{ip}}} \\] <p>where \\(S_{\\text{ip}}\\) is the number of reads aligning to the spike-in genome for that sample. This scales each sample so that 1 million spike-in reads = 1 unit of scale factor. A sample with twice as many spike-in reads gets a factor of 0.5 (downscaled) so that its signal looks equivalent to a sample sequenced less deeply.</p> <p>Merged bigwig: The merged BAM contains reads from all samples in the consensus group. The factor is computed from the pooled spike-in counts \u2014 equivalent to performing the normalisation on the merged BAM directly:</p> \\[ \\text{scale_factor}_{\\text{merged}} = \\frac{10^6}{\\displaystyle\\sum_i S_{\\text{ip},i}} \\] <p>In plain terms</p> <p>For the merged track, we add up the spike-in reads from all samples in the group and use that total. This is equivalent to asking: \"if we treated all these libraries as one big pooled experiment, what would the spike-in normalisation factor be?\" Using the sum (rather than averaging the per-sample factors) gives the correct scaling factor when samples differ in sequencing depth.</p> <p>Output: <code>seqnado_output/{assay}/resources/orlando/normalisation_factors.json</code></p>"},{"location":"normalisation/#with-input-spike-in-input-normalised","title":"With-Input (Spike-in Input-Normalised)","text":"<p>Designed for: ChIP-seq, CUT&amp;TAG, CUT&amp;RUN (requires both a chromatin spike-in and a paired input control sample).</p> <p>Concept: Corrects for both sequencing depth (via spike-in) and IP efficiency (via the paired input control), so the final signal represents the fraction of chromatin that is specifically immunoprecipitated relative to background.</p> <p>In plain terms</p> <p>The Orlando method removes differences in sequencing depth, but two IP experiments can still appear different if one had more efficient immunoprecipitation (more protein pulled down from the same DNA input). The with-input method adds a second correction: it compares the spike-in-normalised IP signal to the spike-in-normalised input control signal. Since input reflects total chromatin (background), dividing IP by input gives you the enrichment: how much more DNA is bound in the IP versus the random background. The result is a direct measure of specific protein binding, robust to both sequencing depth and IP pulldown efficiency differences between samples.</p> <p>Per-sample formula:</p> <p>For each IP sample paired with its input control, define the spike-in-normalised read density for the IP (\\(\\rho_{\\text{ip}}\\)) and the input control (\\(\\rho_{\\text{ctrl}}\\)):</p> \\[ \\rho_{\\text{ip}} = \\frac{R_{\\text{ip}}}{S_{\\text{ip}}}, \\qquad \\rho_{\\text{ctrl}} = \\frac{R_{\\text{ctrl}}}{S_{\\text{ctrl}}} \\] <p>where \\(R\\) is the number of reads mapping to the reference genome and \\(S\\) is the number of reads mapping to the spike-in genome. The relative signal (IP enrichment over background) is then normalised to a reads-per-million scale:</p> \\[ \\text{scale_factor} = \\frac{\\rho_{\\text{ip}}}{\\rho_{\\text{ctrl}}} \\times \\frac{10^7}{R_{\\text{ip}}} \\] <p>Expanding:</p> \\[ \\text{scale_factor} = \\frac{S_{\\text{ctrl}} \\times 10^7}{S_{\\text{ip}} \\times R_{\\text{ctrl}}} \\] <p>Important: This formula applies only to IP samples. Input control samples are treated separately \u2014 they receive a scale factor of 1 (unscaled), as they do not undergo the IP/input correction. When input samples are visualised as tracks (if configured to do so), they appear unscaled.</p> <p>Merged bigwig: The per-sample normalisation table (<code>resources/with_input/normalisation_factors.tsv</code>) already contains the IP and paired-input read counts for each sample. SeqNado sums these across all samples in the group and applies the same formula as for a single sample \u2014 mathematically equivalent to running the calculation on the merged BAM directly:</p> \\[ \\text{scale_factor}_{\\text{merged}} = \\frac{\\displaystyle\\sum_i S_{\\text{ctrl},i} \\times 10^7}{\\displaystyle\\sum_i S_{\\text{ip},i} \\times \\displaystyle\\sum_i R_{\\text{ctrl},i}} \\] <p>In plain terms</p> <p>For the merged track, we pool the spike-in and reference read counts from all samples in the group and apply the same formula as for a single sample. This is mathematically identical to running the normalisation on the merged BAM file.</p> <p>Output: <code>seqnado_output/{assay}/resources/with_input/normalisation_factors.json</code></p>"},{"location":"normalisation/#deseq2-size-factors-spike-in-genes","title":"DESeq2 Size Factors (Spike-in Genes)","text":"<p>Reference: Love MI, Huber W, Anders S. Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2. Genome Biology. 2014;15(12):550. doi:10.1186/s13059-014-0550-8</p> <p>Designed for: RNA-seq.</p> <p>Concept: Uses DESeq2's <code>estimateSizeFactors()</code> to derive normalisation factors from a count matrix of spike-in genome features. If spike-in gene names are provided in the configuration, those genes are used as <code>controlGenes</code>; otherwise the standard median-ratio method is applied to all genes.</p> <p>In plain terms</p> <p>Instead of counting all spike-in reads in bulk, this method counts reads falling on individual spike-in genes (annotated features). For each gene, it calculates how that gene's count in each sample compares to a reference (the geometric mean across all samples), then takes the median of these per-gene ratios as the normalisation factor. Why median instead of mean? Because a few extremely highly expressed spike-in genes would skew a mean-based estimate; the median is robust to outliers. This approach\u2014comparing each sample to a geometric mean reference\u2014is the same logic used widely in RNA-seq differential expression analysis and handles compositional bias well.</p> <p>Per-sample formula: DESeq2 size factors are the median of per-gene count ratios relative to the geometric mean across all samples:</p> \\[ \\hat{s}_j = \\operatorname{median}_g \\left( \\frac{k_{gj}}{\\left(\\prod_{j'} k_{gj'}\\right)^{1/J}} \\right) \\] <p>where \\(k_{gj}\\) is the count for gene \\(g\\) in sample \\(j\\) and \\(J\\) is the total number of samples. The bigwig generator divides the raw signal by \\(\\hat{s}_j\\) to equalise depth across samples.</p> <p>Merged bigwig: Arithmetic mean of per-sample size factors (approximation; re-fitting the DESeq2 model is not applicable):</p> \\[ \\text{scale_factor}_{\\text{merged}} = \\frac{1}{N} \\sum_i \\hat{s}_i \\] <p>In plain terms</p> <p>DESeq2 fits a statistical model to estimate how each gene's count depends on the sample and other factors. This model requires replicate samples to work correctly\u2014it fits the full data to estimate both per-sample size factors and per-gene variability. When you merge replicates into a single BAM, you lose the replicate structure, so re-fitting the model would not be statistically valid. Instead, SeqNado uses the arithmetic mean of the per-sample factors as a practical approximation. The merged track represents a pooled, higher-coverage view of the group signal, useful for visualisation, but is not itself a statistically normalised sample in the same sense that individual replicates are.</p> <p>Output: <code>seqnado_output/{assay}/resources/deseq2/normalisation_factors.json</code></p>"},{"location":"normalisation/#edger-tmm-spike-in-genes","title":"edgeR TMM (Spike-in Genes)","text":"<p>Reference: Robinson MD, Oshlack A. A scaling normalization method for differential expression analysis of RNA-seq data. Genome Biology. 2010;11(3):R25. doi:10.1186/gb-2010-11-3-r25</p> <p>Designed for: RNA-seq.</p> <p>Concept: Uses edgeR's Trimmed Mean of M-values (TMM) normalisation (<code>calcNormFactors()</code>) computed on spike-in gene counts. If spike-in gene names are provided, TMM is computed using only those genes as the reference subset; otherwise all genes are used. After factor calculation the spike-in genes are removed from the count matrix.</p> <p>In plain terms</p> <p>TMM works similarly to DESeq2 but with a different approach. For each sample, compare its per-gene counts to a reference sample on a log scale (M-values = log fold-changes). Average these comparisons across genes to estimate library size differences. The \"trimming\" step removes the most extreme genes (those with the most dramatic fold-changes) before averaging, preventing a handful of highly expressed genes from dominating the estimate. This is particularly useful for RNA-seq where a few genes can dominate the read count. The result is a robust library size correction that handles compositional bias.</p> <p>Per-sample formula: For each sample \\(j\\) relative to a reference sample \\(r\\), TMM computes a weighted mean of log fold changes after trimming extreme values:</p> \\[ \\log_2 \\hat{f}_j^{\\text{TMM}} = \\frac{\\displaystyle\\sum_{g \\in \\mathcal{G}^*} w_{gj} \\, M_{gj}^r}{\\displaystyle\\sum_{g \\in \\mathcal{G}^*} w_{gj}} \\] <p>where \\(M_{gj}^r = \\log_2\\!\\left(\\tfrac{k_{gj}/N_j}{k_{gr}/N_r}\\right)\\) is the log fold change, \\(w_{gj}\\) is an inverse-variance weight, and \\(\\mathcal{G}^*\\) is the set of genes remaining after trimming. The effective library size is \\(N_j \\cdot \\hat{f}_j^{\\text{TMM}}\\).</p> <p>Merged bigwig: Arithmetic mean of per-sample TMM factors (approximation; same rationale as DESeq2 \u2014 the merged BAM has no replicates for the model to work with):</p> \\[ \\text{scale_factor}_{\\text{merged}} = \\frac{1}{N} \\sum_i \\hat{f}_i^{\\text{TMM}} \\] <p>In plain terms</p> <p>Like DESeq2, TMM factors come from a model that is designed to work across replicate samples. Merging replicates into a single BAM removes the replicate structure that the model depends on for statistical inference. SeqNado uses the average of the per-sample TMM factors as a practical approximation. The merged track serves as a high-coverage visualisation aid (cleaner, less noisy) rather than as a statistically normalised sample.</p> <p>Output: <code>seqnado_output/{assay}/resources/edgeR/normalisation_factors.json</code></p>"},{"location":"normalisation/#csaw-library-size-scaling","title":"CSAW Library-Size Scaling","text":"<p>Reference: Lun ATL, Smyth GK. csaw: a Bioconductor package for differential binding analysis of ChIP-seq data using sliding windows. Nucleic Acids Research. 2016;44(5):e45. doi:10.1093/nar/gkv1191</p> <p>Designed for: ChIP-seq, CUT&amp;TAG, CUT&amp;RUN, ATAC-seq. Technically applicable to RNA-seq (it is equivalent to reads-per-million normalisation), but DESeq2 or edgeR are strongly preferred for RNA-seq because they additionally correct for compositional bias \u2014 see Choosing a method below.</p> <p>Concept: Equalise read depth across samples within a scaling group by comparing the total number of reads falling into randomly sampled genomic bins. This normalises for library size differences without relying on exogenous spike-in material.</p> <p>In plain terms</p> <p>Sometimes you don't have a spike-in, but you still need to make samples comparable. CSAW solves this by counting reads in many small windows tiled across the genome and asking: \"how many reads did each sample produce in total?\" Samples that were sequenced more deeply get scaled down and shallower ones get scaled up, so that all samples appear to have the same total read count. This corrects for sequencing depth differences but not for genuine biological differences in the amount of immunoprecipitated chromatin \u2014 it is most appropriate when you expect the global level of the mark to be similar across conditions.</p> <p>Per-sample formula:</p> <p>Reads from each sample's BAM are counted in fixed-size genomic bins using featureCounts. Within a scaling group of \\(N\\) samples:</p> \\[ \\text{scale_factor}_j = \\frac{\\bar{L}}{L_j}, \\qquad \\bar{L} = \\frac{1}{N}\\sum_i L_i \\] <p>where \\(L_j\\) is the total bin read count (library size) for sample \\(j\\) and \\(\\bar{L}\\) is the group mean.</p> <p>Interpretation of factors: - Samples with larger libraries receive factors \\(&lt;1\\) (downscaled) \u2014 these were sequenced more deeply relative to the group average. - Samples with smaller libraries receive factors \\(&gt;1\\) (upscaled) \u2014 these were sequenced less deeply relative to the group average. - Factors always scale towards a common library size equal to the group mean.</p> <p>Merged bigwig: The merged BAM is the physical concatenation of all per-sample BAMs, so its total library size is \\(\\sum_i L_i\\). Because each per-sample factor is \\(s_i = \\bar{L} / L_i\\), we have \\(L_i = \\bar{L} / s_i\\), and the correct scale factor for the merged BAM is:</p> \\[ \\text{scale_factor}_{\\text{merged}} = \\frac{\\bar{L}}{\\displaystyle\\sum_i L_i} = \\frac{1}{\\displaystyle\\sum_i \\tfrac{1}{s_i}} \\] <p>The merged factor is the harmonic mean of the per-sample factors.</p> <p>In plain terms</p> <p>When you merge replicates into a single BAM, that file contains all reads combined. A merged BAM of three replicates has roughly 3\u00d7 the reads of any single replicate. If you scaled it like an individual replicate, it would look 3\u00d7 taller \u2014 not useful for comparison. Instead, SeqNado uses the harmonic mean to ensure the merged track sits at the right scale.</p> <p>Concrete example: Three replicates sequenced at 10M, 20M, and 30M reads (group mean = 20M). Per-sample factors: [20/10, 20/20, 20/30] = [2.0, 1.0, 0.67]. Merged BAM has 60M total reads, so correct merged factor should be 20/60 = 0.33. Using arithmetic mean: (2.0+1.0+0.67)/3 = 1.22 \u2717 wrong. Using harmonic mean: 1/(\u00bd.0 + 1/1.0 + 1/0.67) = 1/(0.5+1.0+1.5) = \u2153.0 = 0.33 \u2713 correct. Harmonic mean works because scaling factors relate inversely to library size\u2014when you concatenate BAMs, you need a formula that respects this inverse relationship.</p> <p>Scaling factors are stored in <code>seqnado_output/{assay}/resources/{group}_scaling_factors.tsv</code>.</p>"},{"location":"normalisation/#unscaled-no-normalisation","title":"Unscaled (No Normalisation)","text":"<p>When normalisation is not enabled, bigwigs are generated with no scaling factor applied. Signal represents raw read pileup, which is affected by sequencing depth. Use this only for exploratory analysis or when samples are known to have matched sequencing depth.</p> <p>In plain terms</p> <p>No adjustment is made. A sample sequenced to twice the depth will appear twice as tall in the genome browser, regardless of whether there is a genuine biological difference. Only use this if your samples were sequenced to the same depth, or if you just want a quick look at the data without worrying about comparability.</p>"},{"location":"normalisation/#choosing-a-method","title":"Choosing a Method","text":""},{"location":"normalisation/#by-assay-type","title":"By assay type","text":"Assay Recommended methods Notes ChIP-seq / CUT&amp;TAG / CUT&amp;RUN <code>orlando</code>, <code>with_input</code>, <code>csaw</code> Prefer <code>orlando</code> or <code>with_input</code> when a chromatin spike-in was added \u2014 they are purpose-built and more direct than DESeq2/edgeR for this use case. Use <code>csaw</code> when no spike-in is available and you expect similar global levels across conditions. ATAC-seq <code>csaw</code> Library-size normalization is most appropriate for ATAC-seq. RNA-seq <code>deseq2</code>, <code>edgeR</code> These are the standard methods for RNA-seq. <code>orlando</code> and <code>with_input</code> are not applicable. <code>csaw</code> is technically valid but does not correct for compositional bias \u2014 see below."},{"location":"normalisation/#can-csaw-be-used-for-rna-seq","title":"Can CSAW be used for RNA-seq?","text":"<p>Technically yes \u2014 the formula is equivalent to reads-per-million (RPM) normalisation, which is a valid and widely understood approach. However, DESeq2 or edgeR are strongly preferred for RNA-seq for the following reason:</p> <p>In an RNA-seq library, a small number of very highly expressed genes can account for a large fraction of all reads. This means two libraries can appear to have different \"total read counts\" even if the underlying biology is the same, simply because a few dominant genes are present. DESeq2 and edgeR correct for this compositional bias by comparing each gene's count to a reference derived from across many genes, rather than relying on the raw library total. CSAW (and RPM) do not account for this and can produce misleading normalisations in RNA-seq data.</p>"},{"location":"normalisation/#can-orlando-be-used-for-rna-seq","title":"Can Orlando be used for RNA-seq?","text":"<p>It depends on your spike-in strategy:</p> <ul> <li>Synthetic RNA spike-ins (e.g. ERCC): Supported if the spike-in sequences are added to the reference genome used for alignment. Reads mapping to the spike-in sequences are then split out in the same way as chromatin spike-in reads, and the Orlando formula applies directly. Configure this by including the spike-in sequences in your genome reference.</li> <li>Exogenous chromatin spike-in (e.g. Drosophila cells added to the RNA-seq library): Conceptually yes \u2014 if reads are aligned to a combined reference+spike-in genome and the spike-in reads are split out, the Orlando formula applies in exactly the same way as for ChIP-seq. Some labs use this approach to detect global changes in transcriptional output. If your RNA-seq experiment was prepared this way, Orlando normalisation is valid and the SeqNado pipeline should handle it correctly provided the genome configuration includes both species.</li> </ul>"},{"location":"normalisation/#file-locations","title":"File Locations","text":"Output Path Orlando factors <code>seqnado_output/{assay}/resources/orlando/normalisation_factors.json</code> With-input factors <code>seqnado_output/{assay}/resources/with_input/normalisation_factors.json</code> DESeq2 factors <code>seqnado_output/{assay}/resources/deseq2/normalisation_factors.json</code> edgeR factors <code>seqnado_output/{assay}/resources/edger/normalisation_factors.json</code> CSAW factors <code>seqnado_output/{assay}/resources/{group}_scaling_factors.tsv</code>"},{"location":"normalisation/#background-terminology","title":"Background Terminology","text":"<p>This document assumes familiarity with high-throughput sequencing concepts. If you are new to ChIP-seq or RNA-seq normalisation, these terms may be useful:</p> <ul> <li>Spike-in: Known quantity of exogenous material (chromatin from another species, or synthetic RNA) added to each sample before sequencing. Because the amount is constant, reads mapping to spike-in reflect sequencing depth, not biology.</li> <li>IP (immunoprecipitation): In ChIP-seq, the antibody pulls down target protein and its bound DNA. The \"IP\" sample contains what was pulled down; the \"input\" sample is unselected chromatin (background).</li> <li>Reference genome: The genome of interest (e.g., Homo sapiens). In spike-in experiments, reads are split by which genome they map to.</li> <li>Replicates: Multiple independent experiments. Normalisation models (DESeq2, edgeR) use replicates to estimate variability; merged BAMs (pooled replicates) have no replicate structure, so these models cannot be re-fit.</li> <li>Compositional bias (RNA-seq): When highly expressed genes make up a large fraction of all reads, raw library size estimates become misleading. DESeq2/edgeR handle this by comparing genes relative to a geometric mean reference.</li> <li>Geometric mean: The \\(N\\)-th root of the product of \\(N\\) values \u2014 used in DESeq2 as a stable reference that is not affected by any single highly expressed gene.</li> </ul>"},{"location":"outputs/","title":"Outputs","text":"<p>\u2190 Back to main page</p>"},{"location":"outputs/#pipeline-outputs","title":"Pipeline Outputs","text":"<p>All SeqNado analysis results are organized within the <code>seqnado_output/</code> directory (or your custom output directory specified during configuration). This page describes the structure and types of files you can expect from your pipeline runs.</p>"},{"location":"outputs/#general-output-structure","title":"General Output Structure","text":"<pre><code>seqnado_output/{assay}/       # Assay-specific directory\n\u251c\u2500\u2500 seqnado_report.html       # Main interactive QC report (MultiQC)\n\u251c\u2500\u2500 protocol.txt              # Auto-generated data processing protocol\n\u251c\u2500\u2500 aligned/                  # Final BAM alignment files\n\u251c\u2500\u2500 bigwigs/                  # BigWig coverage tracks\n\u251c\u2500\u2500 peaks/                    # Peak calling results (ATAC, ChIP, CUT&amp;Tag)\n\u251c\u2500\u2500 readcounts/               # Quantification files (RNA, CRISPR)\n\u251c\u2500\u2500 qc/                       # Quality control metrics\n\u251c\u2500\u2500 hub/                      # UCSC Genome Browser hub\n\u251c\u2500\u2500 heatmap/                  # DeepTools heatmap and metaplot PDFs\n\u251c\u2500\u2500 motifs/                   # Motif analysis results (if enabled)\n\u251c\u2500\u2500 tag_dirs/                 # HOMER tag directories\n\u251c\u2500\u2500 resources/                # Normalisation factors (spike-in and CSAW)\n\u251c\u2500\u2500 genome_browser_plots/     # PlotNado visualisations (if configured)\n\u251c\u2500\u2500 geo_submission/           # GEO submission-ready files (if enabled)\n\u251c\u2500\u2500 methylation/              # Methylation calls (METH only)\n\u251c\u2500\u2500 variant/                  # VCF files (SNP only)\n\u2514\u2500\u2500 logs/                     # Process execution logs\n</code></pre> <p>Note</p> <p>Not all directories will be present for every assay. The exact output depends on your assay type and configuration options.</p>"},{"location":"outputs/#main-entry-point-seqnado-report","title":"Main Entry Point: SeqNado Report","text":"<p>The <code>seqnado_report.html</code> file is your primary analysis report, generated by MultiQC. It provides:</p> <ul> <li>QC Summary: FastQC, alignment statistics, and quality metrics</li> <li>Sample Overview: All samples displayed with key metrics</li> <li>Peak Statistics: Number of peaks called, genomic distribution (for applicable assays)</li> <li>Library Complexity: Duplication rates and unique read counts</li> <li>Multi-Sample Comparisons: Side-by-side QC metrics</li> </ul> <p>A <code>protocol.txt</code> file is also generated, providing an auto-generated data processing protocol describing the steps performed.</p> <p>Viewing the Report</p> <p>Open <code>seqnado_report.html</code> in any modern web browser. No server required!</p>"},{"location":"outputs/#core-output-files","title":"Core Output Files","text":""},{"location":"outputs/#alignment-files-aligned","title":"Alignment Files (<code>aligned/</code>)","text":"<p>The BAM processing pipeline runs through several intermediate stages (sorting, blacklist filtering, duplicate removal, optional Tn5 shifting, quality filtering), but all intermediate files are temporary and deleted after the pipeline completes. Only the final processed BAM files are retained:</p> <pre><code>aligned/\n\u251c\u2500\u2500 {sample}.bam                  # Final processed BAM\n\u2514\u2500\u2500 {sample}.bam.bai              # BAM index\n</code></pre> <p>Processing chain (intermediates are removed automatically):</p> <p><code>raw \u2192 sorted \u2192 blacklist_regions_removed \u2192 duplicates_removed \u2192 shifted_for_tn5_insertion (ATAC/CUT&amp;Tag only) \u2192 filtered \u2192 final</code></p> <p>File Formats:</p> <ul> <li>BAM: Binary alignment format, viewable with samtools/IGV</li> <li>BAI: Index files for rapid random access</li> </ul>"},{"location":"outputs/#coverage-tracks-bigwigs","title":"Coverage Tracks (<code>bigwigs/</code>)","text":"<p>Genome-wide signal tracks for visualisation, organised by tool and scaling method:</p> <pre><code>bigwigs/\n\u251c\u2500\u2500 {method}/                              # deeptools, homer, or bamnado\n\u2502   \u251c\u2500\u2500 {sample}.bigWig                    # Default unscaled tracks\n\u2502   \u251c\u2500\u2500 csaw/                              # CSAW-normalised individual (if enabled)\n\u2502   \u2502   \u2514\u2500\u2500 {sample}.bigWig\n\u2502   \u251c\u2500\u2500 spikein/                           # Spike-in normalised (if applicable)\n\u2502   \u2502   \u2514\u2500\u2500 {spikein_method}/\n\u2502   \u2502       \u2514\u2500\u2500 {sample}.bigWig\n\u2502   \u2514\u2500\u2500 merged/                            # Consensus group merged tracks\n\u2502       \u251c\u2500\u2500 {group}.bigWig                 # Unscaled merged\n\u2502       \u251c\u2500\u2500 csaw/                          # CSAW-scaled merged (if enabled)\n\u2502       \u2502   \u2514\u2500\u2500 {group}.bigWig\n\u2502       \u2514\u2500\u2500 spikein/                       # Spike-in scaled merged (if applicable)\n\u2502           \u2514\u2500\u2500 {spikein_method}/\n\u2502               \u2514\u2500\u2500 {group}.bigWig\n</code></pre> <p>For RNA-seq, stranded bigwigs are produced with <code>_plus</code> and <code>_minus</code> suffixes:</p> <pre><code>bigwigs/{method}/{sample}_plus.bigWig\nbigwigs/{method}/{sample}_minus.bigWig\n</code></pre> <p>Pileup Tools:</p> <ul> <li>DeepTools: <code>bamCoverage</code>-based tracks (supports all scaling methods, individual and merged)</li> <li>HOMER: <code>makeBigWig.pl</code>-based tracks (unscaled individual and unscaled merged only)</li> <li>BamNado: Custom pileup tool (unscaled and CSAW individual; unscaled and CSAW merged)</li> </ul> <p>Scaling Methods:</p> <ul> <li>unscaled: No normalisation applied</li> <li>csaw: CSAW-based normalisation using binned read counts across samples</li> <li>spikein: Spike-in normalisation using external control DNA (DeepTools only)</li> </ul> <p>Merged Tracks (when <code>consensus_group</code> is set in the design file):</p> <p>Individual-sample bigwigs are complemented by merged tracks for each consensus group, supporting all of the same scaling methods as individual tracks (where applicable). CSAW and spike-in scaled merged bigwigs require the corresponding normalization to be enabled.</p>"},{"location":"outputs/#normalisation-factor-calculation","title":"Normalisation factor calculation","text":"<p>Per-sample bigwigs use a factor calculated individually for each sample. For CSAW, all samples within a scaling group are compared via binned read counts and each sample receives:</p> <pre><code>scale_factor = mean_library_size_of_group / sample_library_size\n</code></pre> <p>Samples with larger libraries are scaled down; samples with smaller libraries are scaled up. The results are written to <code>resources/{group}_scaling_factors.tsv</code>.</p> <p>Merged bigwigs are generated from a BAM produced by <code>samtools merge</code> (concatenating all reads in the consensus group). The scale factor applied to the merged BAM is the arithmetic mean of the per-sample factors for all samples in that group:</p> <pre><code>merged_scale_factor = mean(scale_factor_sample_1, scale_factor_sample_2, ...)\n</code></pre> <p>This ensures the merged track is normalised to the average depth of the constituent samples.</p> <p>For spike-in normalised merged bigwigs, a simple arithmetic mean of per-sample factors would give incorrect results when samples differ in sequencing depth (deeply-sequenced samples contribute far more reads to the merged BAM but their smaller factors would be under-weighted). Instead, SeqNado derives the merged factor from the pooled spike-in counts, equivalent to \"merge-then-split\":</p> <ul> <li>orlando: <code>merged_factor = 1e6 / sum(spikein_reads)</code> \u2014 exact pooled calculation using each sample's <code>aligned/spikein/{sample}_stats.tsv</code></li> <li>with_input: spike-in-weighted mean of per-sample factors, <code>sum(f_i \u00d7 S_ip_i) / sum(S_ip_i)</code>, which correctly weights samples by their sequencing depth</li> <li>deseq2 / edgeR: arithmetic mean fallback (these factors come from fitted statistical models rather than raw spike-in counts)</li> </ul> Per-sample bigwig Merged bigwig Input BAM <code>aligned/{sample}.bam</code> <code>aligned/merged/{group}.bam</code> (samtools merge) Scale factor individual sample factor mean of all samples in group Factor source <code>resources/{group}_scaling_factors.tsv</code> same file, averaged"},{"location":"outputs/#peak-calls-peaks","title":"Peak Calls (<code>peaks/</code>)","text":"<p>Peak calling results are simplified to 3-column BED files (chr, start, end):</p> <pre><code>peaks/\n\u251c\u2500\u2500 {method}/                  # macs2, macs3, homer, lanceotron, or seacr\n\u2502   \u251c\u2500\u2500 {sample}.bed           # Individual sample peaks\n\u2502   \u2514\u2500\u2500 merged/                # Consensus peaks across replicates\n\u2502       \u2514\u2500\u2500 {group}.bed\n</code></pre> <p>Supported Peak Callers:</p> <ul> <li>MACS2: Standard peak calling</li> <li>MACS3: Updated MACS peak calling</li> <li>HOMER: <code>findPeaks</code>-based peak calling</li> <li>LanceOtron: ML-based peak calling</li> <li>SEACR: Sparse Enrichment Analysis for CUT&amp;RUN/CUT&amp;Tag</li> </ul> <p>Peak File Format:</p> <ul> <li>BED: Simple 3-column genomic coordinates (chr, start, end) extracted from each caller's native output</li> </ul>"},{"location":"outputs/#read-counts-readcounts","title":"Read Counts (<code>readcounts/</code>)","text":"<p>Quantification files for RNA-seq and CRISPR assays:</p> <pre><code>readcounts/\n\u251c\u2500\u2500 feature_counts/\n\u2502   \u2514\u2500\u2500 read_counts.tsv         # Combined featureCounts output\n\u2514\u2500\u2500 salmon/                     # RNA-seq only\n    \u2514\u2500\u2500 salmon_counts.csv       # Combined Salmon quantification\n</code></pre>"},{"location":"outputs/#quality-control-qc","title":"Quality Control (<code>qc/</code>)","text":"<p>Comprehensive QC metrics:</p> <pre><code>qc/\n\u251c\u2500\u2500 fastqc_raw/                     # FastQC reports on raw reads\n\u2502   \u251c\u2500\u2500 {sample}_1_fastqc.html      # Read 1 (paired-end)\n\u2502   \u2514\u2500\u2500 {sample}_2_fastqc.html      # Read 2 (paired-end)\n\u251c\u2500\u2500 fastq_screen/                   # Contamination screening (if enabled)\n\u2502   \u251c\u2500\u2500 {sample}_1_screen.html\n\u2502   \u2514\u2500\u2500 {sample}_2_screen.html\n\u251c\u2500\u2500 qualimap_bamqc/                 # BAM quality metrics (non-RNA assays)\n\u2502   \u2514\u2500\u2500 {sample}/\n\u2502       \u2514\u2500\u2500 qualimapReport.html\n\u251c\u2500\u2500 qualimap_rnaseq/                # RNA-specific BAM QC (RNA assay only)\n\u2502   \u2514\u2500\u2500 {sample}/\n\u2502       \u2514\u2500\u2500 qualimapReport.html\n\u251c\u2500\u2500 alignment_stats.tsv             # Aggregated alignment statistics\n\u251c\u2500\u2500 library_complexity/             # Picard duplicate metrics\n\u2502   \u2514\u2500\u2500 {sample}.metrics\n\u2514\u2500\u2500 frip_enrichment/                # FRiP scores (if enabled, peak-calling assays)\n    \u2514\u2500\u2500 {method}/\n        \u251c\u2500\u2500 {sample}_frip.pdf\n        \u2514\u2500\u2500 {sample}_frip.txt\n</code></pre> <p>Note</p> <p>For single-end data, FastQC and FastQ Screen files use <code>{sample}_fastqc.html</code> / <code>{sample}_screen.html</code> without the <code>_1</code>/<code>_2</code> suffix.</p> <p>QC Metrics Include:</p> <ul> <li>Read quality scores per base position</li> <li>GC content distribution</li> <li>Adapter content</li> <li>Duplication rates</li> <li>Mapping statistics</li> <li>Coverage uniformity</li> </ul>"},{"location":"outputs/#ucsc-genome-browser-hub-hub","title":"UCSC Genome Browser Hub (<code>hub/</code>)","text":"<p>Ready-to-load UCSC track hub generated by TracKNado:</p> <pre><code>hub/\n\u2514\u2500\u2500 {hub_name}.hub.txt     # Hub description file (default: seqnado_hub.hub.txt)\n</code></pre> <p>The hub structure (genomes.txt, trackDb.txt, etc.) is generated by TracKNado and includes links to your bigWig and other track files.</p> <p>Usage:</p> <ol> <li>Upload the <code>hub/</code> directory to a web-accessible location</li> <li>Load in UCSC Genome Browser using the hub URL</li> <li>Or use locally with IGV/other genome browsers</li> </ol>"},{"location":"outputs/#heatmaps-heatmap","title":"Heatmaps (<code>heatmap/</code>)","text":"<p>DeepTools-generated heatmaps and metaplots (for assays with peak calling). One set of plots is produced per pileup method \u00d7 scaling method combination, mirroring the bigwig structure:</p> <pre><code>heatmap/\n\u251c\u2500\u2500 {method}/                        # deeptools, homer, or bamnado\n\u2502   \u251c\u2500\u2500 unscaled/\n\u2502   \u2502   \u251c\u2500\u2500 heatmap.pdf              # Signal heatmap over regions of interest\n\u2502   \u2502   \u2514\u2500\u2500 metaplot.pdf             # Average signal profile\n\u2502   \u251c\u2500\u2500 csaw/                        # If CSAW normalisation enabled\n\u2502   \u2502   \u251c\u2500\u2500 heatmap.pdf\n\u2502   \u2502   \u2514\u2500\u2500 metaplot.pdf\n\u2502   \u2514\u2500\u2500 spikein/{spikein_method}/    # If spike-in normalisation enabled\n\u2502       \u251c\u2500\u2500 heatmap.pdf\n\u2502       \u2514\u2500\u2500 metaplot.pdf\n\u2514\u2500\u2500 merged/                          # If consensus groups defined\n    \u2514\u2500\u2500 {method}/\n        \u251c\u2500\u2500 unscaled/\n        \u2502   \u251c\u2500\u2500 heatmap.pdf\n        \u2502   \u2514\u2500\u2500 metaplot.pdf\n        \u2514\u2500\u2500 csaw/                    # If CSAW normalisation enabled\n            \u251c\u2500\u2500 heatmap.pdf\n            \u2514\u2500\u2500 metaplot.pdf\n</code></pre>"},{"location":"outputs/#motif-analysis-motifs","title":"Motif Analysis (<code>motifs/</code>)","text":"<p>Motif enrichment analysis for peak-calling assays (if enabled):</p> <pre><code>motifs/\n\u251c\u2500\u2500 homer/                      # HOMER findMotifsGenome results\n\u2502   \u2514\u2500\u2500 {peak_method}/\n\u2502       \u2514\u2500\u2500 {sample}/\n\u2514\u2500\u2500 meme/                       # MEME-ChIP results (if enabled)\n    \u2514\u2500\u2500 {peak_method}/\n        \u2514\u2500\u2500 {sample}/\n</code></pre>"},{"location":"outputs/#genome-browser-plots-genome_browser_plots","title":"Genome Browser Plots (<code>genome_browser_plots/</code>)","text":"<p>Publication-ready visualisations generated with PlotNado (if configured with plotting coordinates). One set of plots is produced per pileup method \u00d7 scaling method combination:</p> <pre><code>genome_browser_plots/\n\u251c\u2500\u2500 {method}/                              # deeptools, homer, or bamnado\n\u2502   \u251c\u2500\u2500 unscaled/\n\u2502   \u2502   \u251c\u2500\u2500 {region_name}.{format}         # Named regions from BED file\n\u2502   \u2502   \u251c\u2500\u2500 {chr}-{start}-{end}.{format}   # Unnamed regions use coordinates\n\u2502   \u2502   \u2514\u2500\u2500 template.toml                  # PlotNado configuration template\n\u2502   \u251c\u2500\u2500 csaw/                              # If CSAW normalisation enabled\n\u2502   \u2502   \u251c\u2500\u2500 {region_name}.{format}\n\u2502   \u2502   \u2514\u2500\u2500 template.toml\n\u2502   \u2514\u2500\u2500 spikein/{spikein_method}/          # If spike-in normalisation enabled\n\u2502       \u251c\u2500\u2500 {region_name}.{format}\n\u2502       \u2514\u2500\u2500 template.toml\n\u2514\u2500\u2500 merged/                                # If consensus groups defined\n    \u2514\u2500\u2500 {method}/\n        \u251c\u2500\u2500 unscaled/\n        \u2502   \u251c\u2500\u2500 {region_name}.{format}\n        \u2502   \u2514\u2500\u2500 template.toml\n        \u2514\u2500\u2500 csaw/                          # If CSAW normalisation enabled\n            \u251c\u2500\u2500 {region_name}.{format}\n            \u2514\u2500\u2500 template.toml\n</code></pre> <p>Output format can be <code>svg</code>, <code>png</code>, or <code>pdf</code> as configured.</p>"},{"location":"outputs/#geo-submission-geo_submission","title":"GEO Submission (<code>geo_submission/</code>)","text":"<p>Pre-formatted files for GEO/SRA submission (if enabled):</p> <pre><code>geo_submission/\n\u251c\u2500\u2500 samples_table.txt                 # Sample metadata (TSV format)\n\u251c\u2500\u2500 md5sums.txt                       # Combined checksums\n\u251c\u2500\u2500 raw_data_checksums.txt            # Checksums for raw FASTQ files\n\u251c\u2500\u2500 processed_data_checksums.txt      # Checksums for processed files\n\u251c\u2500\u2500 upload_instructions.txt           # Instructions for GEO upload\n\u251c\u2500\u2500 {sample}_1.fastq.gz               # Symlinks to raw FASTQ files\n\u251c\u2500\u2500 {sample}_2.fastq.gz\n\u251c\u2500\u2500 {sample}_{method}_{scale}.bigWig  # Renamed processed bigWig files\n\u251c\u2500\u2500 {sample}_{method}.bed             # Renamed peak files\n\u2514\u2500\u2500 {assay}/                          # Upload directory\n</code></pre>"},{"location":"outputs/#assay-specific-outputs","title":"Assay-Specific Outputs","text":""},{"location":"outputs/#atac-seq","title":"ATAC-seq","text":"<p>ATAC-seq includes Tn5 insertion site correction during BAM processing and supports all peak callers. LanceOtron is the default peak caller.</p> <p>Key outputs:</p> <ul> <li><code>aligned/{sample}.bam</code> -- Tn5-shifted, filtered alignments</li> <li><code>peaks/lanceotron/{sample}.bed</code> -- ML-based peak calls (default)</li> <li><code>bigwigs/{method}/{sample}.bigWig</code> -- Coverage tracks</li> </ul> <p>Key Metrics:</p> <ul> <li>Fragment size distribution (nucleosome periodicity visible in QC report)</li> <li>FRiP (Fraction of Reads in Peaks) score (if enabled)</li> </ul>"},{"location":"outputs/#chip-seq","title":"ChIP-seq","text":"<p>Standard ChIP-seq with support for input controls:</p> <p>Key outputs:</p> <ul> <li><code>aligned/{sample}.bam</code> -- Final alignments</li> <li><code>peaks/{method}/{sample}.bed</code> -- Peak calls (MACS2, HOMER, LanceOtron)</li> <li><code>peaks/{method}/merged/{group}.bed</code> -- Consensus peaks</li> <li><code>tag_dirs/{sample}/</code> -- HOMER tag directories</li> <li><code>motifs/homer/{method}/{sample}/</code> -- Motif analysis (if enabled)</li> </ul> <p>Normalisation resources (if applicable):</p> <ul> <li><code>resources/{spikein_method}/normalisation_factors.json</code> -- Spike-in scaling factors</li> <li><code>resources/binned_counts/read_counts.tsv</code> -- Genomic bin counts for CSAW</li> <li><code>resources/{group}_scaling_factors.tsv</code> -- CSAW scaling factors per consensus group</li> <li><code>bigwigs/deeptools/spikein/{spikein_method}/{sample}.bigWig</code> -- Spike-in normalised tracks</li> <li><code>bigwigs/deeptools/csaw/{sample}.bigWig</code> -- CSAW normalised tracks</li> </ul>"},{"location":"outputs/#cuttag","title":"CUT&amp;Tag","text":"<p>CUT&amp;Tag is a separate assay from ChIP-seq, with SEACR as the default peak caller and optional Tn5 shift correction:</p> <p>Key outputs:</p> <ul> <li><code>aligned/{sample}.bam</code> -- Final alignments (optionally Tn5-shifted)</li> <li><code>peaks/seacr/{sample}.bed</code> -- SEACR peak calls (default)</li> <li><code>bigwigs/{method}/{sample}.bigWig</code> -- Coverage tracks</li> </ul>"},{"location":"outputs/#rna-seq","title":"RNA-seq","text":"<p>RNA-seq alignment uses STAR, with quantification by featureCounts and/or Salmon:</p> <p>Key outputs:</p> <ul> <li><code>aligned/{sample}.bam</code> -- STAR-aligned, processed BAM</li> <li><code>readcounts/feature_counts/read_counts.tsv</code> -- Combined gene-level counts</li> <li><code>readcounts/salmon/salmon_counts.csv</code> -- Salmon quantification (if enabled)</li> <li><code>bigwigs/{method}/{sample}_plus.bigWig</code> -- Stranded coverage (plus strand)</li> <li><code>bigwigs/{method}/{sample}_minus.bigWig</code> -- Stranded coverage (minus strand)</li> <li><code>qc/qualimap_rnaseq/{sample}/qualimapReport.html</code> -- RNA-specific QC</li> </ul>"},{"location":"outputs/#methylation-meth","title":"Methylation (METH)","text":"<p>Methylation calling uses MethylDackel, with support for both bisulfite and TAPS methods:</p> <pre><code>methylation/\n\u251c\u2500\u2500 methyldackel/\n\u2502   \u251c\u2500\u2500 {sample}_{genome}_CpG.bedGraph             # CpG methylation calls\n\u2502   \u251c\u2500\u2500 {sample}_{genome}_CpG_inverted.bedGraph    # TAPS-inverted calls (TAPS method only)\n\u2502   \u2514\u2500\u2500 bias/\n\u2502       \u2514\u2500\u2500 {sample}_{genome}.txt                  # M-bias data\n\u251c\u2500\u2500 methylation_conversion.tsv                     # Conversion rate statistics\n\u2514\u2500\u2500 methylation_conversion.png                     # Conversion rate plot\n</code></pre> <p>Samples are split by genome (reference vs spike-in) with split BAMs at <code>aligned/spikein/{sample}_{genome}.bam</code>.</p>"},{"location":"outputs/#snp-variant-calling","title":"SNP / Variant Calling","text":"<p>Variant calling using bcftools:</p> <pre><code>variant/\n\u251c\u2500\u2500 {sample}.vcf.gz             # Called variants\n\u2514\u2500\u2500 {sample}.anno.vcf.gz        # Annotated variants (if annotation enabled)\n</code></pre> <p>QC stats are produced at <code>qc/variant/{sample}.stats.txt</code>.</p>"},{"location":"outputs/#micro-capture-c-mcc","title":"Micro Capture-C (MCC)","text":"<p>Chromatin contact analysis:</p> <pre><code>mcc/\n\u2514\u2500\u2500 contacts/\n    \u2514\u2500\u2500 {group}/\n        \u2514\u2500\u2500 {group}.mcool      # Multi-resolution contact matrix\n</code></pre>"},{"location":"outputs/#crispr-screens","title":"CRISPR Screens","text":"<p>Guide RNA quantification with optional MAGeCK analysis:</p> <pre><code>readcounts/\n\u251c\u2500\u2500 feature_counts/\n\u2502   \u2514\u2500\u2500 read_counts.tsv                     # featureCounts guide counts (always produced)\n\u2514\u2500\u2500 mageck/                                 # MAGeCK analysis (if enabled)\n    \u251c\u2500\u2500 mageck_count.count.txt              # Raw guide counts\n    \u251c\u2500\u2500 mageck_count.count_normalized.txt   # Normalised counts\n    \u251c\u2500\u2500 mageck_count.countsummary.txt       # Count summary\n    \u251c\u2500\u2500 mageck_mle.gene_summary.txt         # MAGeCK MLE gene-level results\n    \u251c\u2500\u2500 mageck_mle.sgrna_summary.txt        # MAGeCK MLE sgRNA-level results\n    \u2514\u2500\u2500 design_matrix.txt                   # Design matrix used\n</code></pre>"},{"location":"outputs/#accessing-your-results","title":"Accessing Your Results","text":""},{"location":"outputs/#command-line","title":"Command Line","text":"<pre><code># Navigate to output directory\ncd seqnado_output/\n\n# View main report\nfirefox {assay}/seqnado_report.html &amp;\n\n# List peaks\nls -lh {assay}/peaks/macs2/\n\n# Load BAM in IGV\nigv {assay}/aligned/{sample}.bam\n</code></pre>"},{"location":"outputs/#opening-reports","title":"Opening Reports","text":"<p>The HTML reports can be opened directly in your browser:</p> <pre><code># On local machine\nopen seqnado_output/chip/seqnado_report.html\n\n# Via X11 forwarding on HPC\nfirefox seqnado_output/chip/seqnado_report.html &amp;\n\n# Transfer to local machine\nscp -r user@hpc:path/to/seqnado_output/ ./\n</code></pre>"},{"location":"outputs/#finding-specific-outputs","title":"Finding Specific Outputs","text":""},{"location":"outputs/#peak-calling-results","title":"Peak calling results","text":"<pre><code>find seqnado_output/ -name \"*.bed\"\n</code></pre>"},{"location":"outputs/#coverage-tracks-for-visualisation","title":"Coverage tracks for visualisation","text":"<pre><code>find seqnado_output/ -name \"*.bigWig\"\n</code></pre>"},{"location":"outputs/#qc-html-reports","title":"QC HTML reports","text":"<pre><code>find seqnado_output/ -name \"*.html\"\n</code></pre> <p>See Also:</p> <ul> <li>Pipeline Overview - How outputs are generated</li> <li>Tools Reference - Understanding tool-specific outputs</li> </ul>"},{"location":"pipeline/","title":"Pipeline Overview","text":"<p>\u2190 Back to main page</p>"},{"location":"pipeline/#pipeline-overview","title":"Pipeline Overview","text":"<p>The SeqNado pipeline is built on Snakemake and handles the end-to-end processing of various sequencing assays. This page details the standard workflow and assay-specific steps.</p>"},{"location":"pipeline/#usage","title":"Usage","text":"<p>Run the pipeline for a given assay (e.g., ATAC-seq) via slurm using singularity containers using 16 cores:</p> <pre><code>seqnado pipeline atac --cores 16 --preset ss\n</code></pre>"},{"location":"pipeline/#presets","title":"Presets","text":"<p>Presets control where and how jobs are executed. Pick the one that matches your setup:</p> Preset Profile Description <code>le</code> <code>local_environment</code> Local execution, no containers (default) <code>ls</code> <code>local_singularity</code> Local execution with Apptainer/Singularity <code>lc</code> <code>local_conda</code> Local execution with Conda + Apptainer <code>ld</code> <code>local_docker</code> Local execution with Conda + Docker <code>ss</code> <code>slurm_singularity</code> SLURM cluster with Apptainer <code>t</code> Test For testing and development <p>Tip</p> <p>Not sure which to pick? Use <code>le</code> if you're running on your own machine or a login node. Use <code>ss</code> if you're on an HPC cluster with SLURM. See the HPC Clusters guide for cluster setup.</p>"},{"location":"pipeline/#common-options","title":"Common Options","text":"Option Short Description <code>--cores INTEGER</code> <code>-c</code> Number of CPU cores for Snakemake to use (default: 1) <code>--dry-run</code> <code>-n</code> Show what would be executed without running <code>--unlock</code> Unlock the working directory after a failed/interrupted run <code>--rerun-incomplete</code> Re-run jobs left incomplete from a previous run <code>--scale-resources FLOAT</code> <code>-s</code> Scale memory/time requests (default: 1.0) <code>--queue TEXT</code> <code>-q</code> Slurm queue/partition for the <code>ss</code> preset (default: short) <p>Any additional arguments are passed directly to Snakemake (e.g., <code>--printshellcmds</code>).</p> <p>For the full CLI reference, see seqnado pipeline.</p> <p>You can also point to a custom Snakemake profile directory with <code>--profile</code> (or <code>--profiles</code>), which overrides <code>--preset</code>.</p>"},{"location":"pipeline/#general-workflow","title":"General Workflow","text":"<p>Regardless of the assay type, all SeqNado runs follow these core stages:</p> <ol> <li>Quality Control: FastQC checks per-base quality, GC content, and duplication levels. Fastq Screen detects contamination from other organisms \u2014 useful for catching sample swaps or adapter contamination early.</li> <li>Adapter Trimming: Trim Galore removes sequencing adapters and low-quality bases from read ends, which would otherwise cause misalignments or inflate duplicate rates.</li> <li>Alignment: Reads are mapped to the reference genome. DNA-based assays use Bowtie2 (fast, accurate for short reads). RNA-seq uses STAR, which is splice-aware and handles reads spanning exon-exon junctions.</li> <li>Post-processing: BAM files are filtered (remove unmapped reads, low-quality alignments), sorted, and indexed. Duplicates from PCR amplification are marked or removed so they don't inflate signal.</li> <li>Signal Generation: Normalised BigWig tracks are created for visualisation in genome browsers (IGV, UCSC). These let you visually inspect signal across the genome without loading the full BAM.</li> <li>Summarization: All QC metrics are aggregated into a single MultiQC HTML report for quick assessment of the entire run.</li> </ol>"},{"location":"pipeline/#supported-assays","title":"Supported Assays","text":""},{"location":"pipeline/#atac-seq-atac","title":"ATAC-seq (ATAC)","text":"<p>Identifies regions of open chromatin by sequencing DNA accessible to the Tn5 transposase.</p> <ul> <li>Filtering: Mitochondrial reads are removed because Tn5 preferentially inserts into mitochondrial DNA, which would otherwise dominate the library. PCR duplicates are also removed. Reads overlapping ENCODE blacklist regions are discarded to avoid artefactual signal.</li> <li>Tn5 Shift Correction: Reads are shifted +4/-5 bp to account for the 9 bp staggered cut that Tn5 makes on insertion. This centres the signal on the actual insertion site rather than the fragment ends. Controlled by the <code>shift_for_tn5_insertion</code> config option.</li> <li>Peak Calling: MACS2 is the standard choice for most ATAC-seq experiments. LanceOtron uses a deep-learning approach and can be better at detecting broad or weak peaks. HOMER is also available.</li> <li>Consensus Peaks: When samples are grouped via a <code>consensus_group</code> column in the design file, BAMs are merged and peaks are re-called on the combined data to produce a robust consensus peak set.</li> <li>QC: TSS enrichment scores measure signal-to-noise \u2014 a high score (&gt;7) confirms that open chromatin regions are well-captured. Fragment size distributions should show a clear nucleosomal banding pattern. FRiP (Fraction of Reads in Peaks) quantifies how much of your library falls within called peaks.</li> </ul>"},{"location":"pipeline/#chip-seq-chip","title":"ChIP-seq (ChIP)","text":"<p>Maps protein-DNA interactions by sequencing DNA fragments bound to a target protein.</p> <ul> <li>Background Correction: Input or IgG controls are essential to distinguish true binding from background noise. SeqNado pairs each IP sample with its control automatically from the design file.</li> <li>Blacklist Filtering: Reads in ENCODE blacklist regions are removed \u2014 these regions produce artefactually high signal regardless of the experiment.</li> <li>Peak Calling: Use MACS2 narrow mode for transcription factors (sharp, well-defined peaks) and broad mode for histone marks like H3K27me3 or H3K36me3 (wide, diffuse domains). SEACR is an alternative that works well for low-background experiments. HOMER is also available.</li> <li>Consensus Peaks: Merged sample groups produce consensus peak sets from the combined data, useful for defining a common set of regions across replicates.</li> <li>Normalization: Spike-in normalization (using a reference genome like Drosophila) corrects for global differences in pull-down efficiency between samples, which is critical when comparing conditions where total binding levels may change. Multiple normalization methods are available (Orlando, input-based, DESeq2, edgeR).</li> <li>QC: FRiP scores are calculated to measure the proportion of reads falling within peaks \u2014 a key indicator of enrichment quality.</li> </ul>"},{"location":"pipeline/#rna-seq-rna","title":"RNA-seq (RNA)","text":"<p>Quantifies gene expression across the transcriptome.</p> <ul> <li>Alignment: STAR is used because it handles spliced alignments \u2014 RNA-seq reads frequently span exon junctions, which a standard DNA aligner would fail to map.</li> <li>Quantification: featureCounts assigns aligned reads to genes using the genome annotation (GTF), producing a count matrix of genes-by-samples. Salmon is also available as an alternative that uses pseudoalignment for faster quantification without a separate alignment step.</li> <li>Strand-Specific BigWigs: For stranded libraries, separate plus- and minus-strand BigWig tracks are generated so you can visualise sense and antisense transcription independently.</li> <li>Analysis: DESeq2 performs differential expression analysis between conditions defined in your design file. It models count data with appropriate statistics and corrects for multiple testing.</li> <li>QC: Qualimap provides RNA-seq-specific metrics including gene body coverage, 5'/3' bias, and the proportion of reads mapping to exonic, intronic, and intergenic regions.</li> </ul>"},{"location":"pipeline/#cuttag-cat","title":"CUT&amp;Tag (CAT)","text":"<p>A low-input alternative to ChIP-seq that uses protein A-Tn5 fusion to tag chromatin at sites of antibody binding.</p> <ul> <li>Tn5 Shift Correction: Like ATAC-seq, reads are shifted +4/-5 bp to correct for the Tn5 insertion offset, centering signal on the true binding site. Controlled by the <code>shift_for_tn5_insertion</code> config option.</li> <li>Filtering: Filtering is tuned for the characteristically small fragment sizes generated by the targeted Tn5 insertion. CUT&amp;Tag produces very low background. Blacklist regions are also removed.</li> <li>Peak Calling: SEACR is the recommended peak caller for CUT&amp;Tag data \u2014 it was designed for the sparse, low-background signal that CUT&amp;Tag produces, unlike MACS2 which assumes higher background levels. MACS2 and LanceOtron are also available if needed.</li> <li>Consensus Peaks: Merged sample groups produce consensus peak sets from the combined data.</li> <li>Normalization: Spike-in normalization is supported, as with ChIP-seq.</li> </ul>"},{"location":"pipeline/#snp-analysis-snp","title":"SNP Analysis (SNP)","text":"<p>Identifies single nucleotide variants from sequencing data.</p> <ul> <li>Alignment/Processing: Standard Bowtie2 alignment followed by BAM post-processing with duplicate marking, which is especially important for variant calling to avoid false positives from PCR duplicates.</li> <li>Variant Calling: bcftools calls variants and produces VCF/BCF files containing identified variants, their quality scores, and genotype information. Multiallelic sites are split into separate records for downstream analysis.</li> </ul>"},{"location":"pipeline/#methylation-meth","title":"Methylation (METH)","text":"<p>Measures DNA methylation at single-base resolution using bisulfite sequencing.</p> <ul> <li>Processing: Bisulfite treatment converts unmethylated cytosines to uracil (read as thymine), so alignment requires a specialised approach that accounts for C-to-T conversions rather than treating them as mismatches. TAPS (TET-assisted pyridine borane sequencing) is also supported as an alternative chemistry \u2014 methylation values are automatically inverted to produce the correct output.</li> <li>Spike-in BAM Splitting: When spike-in genomes are configured (e.g., lambda DNA, pUC19), aligned reads are split by genome based on chromosome prefix. Reference and spike-in reads are then processed independently through all downstream steps.</li> <li>Bias Correction: MethylDackel calculates the M-bias plot for each genome (reference and spike-in separately), identifying positions with systematic bias at read ends. These biased positions are excluded during extraction to avoid skewing methylation estimates.</li> <li>Conversion Rate QC: Conversion rates are calculated from the M-bias data for each sample and genome, and aggregated into a summary table (<code>methylation_conversion.tsv</code>) and visualisation (<code>methylation_conversion.png</code>). For spike-in DNA (which is unmethylated), conversion should be &gt;95% \u2014 a low spike-in conversion rate indicates incomplete bisulfite treatment and unreliable methylation calls. Read 1 and Read 2 are reported separately to detect strand-specific bias.</li> <li>Methylation Calls: MethylDackel extracts per-cytosine methylation levels from the aligned reads, producing CpG bedGraph files for each sample-genome combination. This gives you both the biological methylation state (from the reference genome) and the technical control (from the spike-in).</li> </ul>"},{"location":"pipeline/#mcc-mcc","title":"MCC (MCC)","text":"<p>Micro Capture-C maps chromatin interactions at high resolution using targeted capture of specific viewpoints.</p> <p>The MCC pipeline follows a multi-phase workflow:</p> <p>Phase 1: Viewpoint Preparation </p> <ul> <li>Viewpoint FASTA Generation: Viewpoint coordinates from the BED file are extracted as FASTA sequences from the reference genome using bedtools. These serve as alignment targets for identifying which capture probe pulled down each read.</li> <li>Exclusion Regions: Buffer zones around each viewpoint are defined (configurable via <code>exclusion_zone</code>) to exclude self-ligation and undigested fragments from the analysis.</li> </ul> <p>Phase 2: Read-to-Viewpoint Assignment </p> <ul> <li>Viewpoint Alignment: Trimmed reads (merged with FLASH for overlapping pairs) are aligned to the viewpoint FASTA using minimap2 with short-read settings (<code>-k 8 -w 1</code>). This identifies which capture probe each read originated from.</li> <li>Read Splitting: Reads that aligned to a viewpoint are extracted and converted back to FASTQ for re-alignment to the full genome.</li> </ul> <p>Phase 3: Genome Alignment </p> <ul> <li>Primary Genome Alignment: Viewpoint-assigned reads are aligned to the reference genome with Bowtie2 to determine the genomic location of each captured fragment.</li> <li>Sensitive Re-alignment: Reads that failed to map in the primary alignment are re-aligned with <code>--very-sensitive-local</code> settings to recover additional mappings. Both sets are then merged.</li> </ul> <p>Phase 4: Per-Replicate Processing </p> <ul> <li>Query Name Sorting: BAMs are sorted by read name to group paired reads for junction identification.</li> <li>Viewpoint Annotation: Each read pair is annotated with a viewpoint (VP) tag indicating which capture probe it originated from.</li> <li>Deduplication: PCR duplicates are removed using viewpoint-aware deduplication to avoid inflating contact frequencies.</li> <li>Ligation Junction Extraction: Read pairs representing capture-C ligation junctions are identified for each viewpoint. These are output as pairs files (chromosome, position for each end of the contact).</li> <li>Ligation Statistics: Per-sample cis and trans contact counts are extracted for normalisation and QC. A high cis ratio (contacts on the same chromosome as the viewpoint) indicates good capture efficiency.</li> </ul> <p>Phase 5: Group Merging and Aggregation </p> <ul> <li>BAM Merging: Replicate BAMs within each consensus group are merged for increased statistical power.</li> <li>Grouped Junction Extraction: Ligation junctions are re-extracted from the merged BAMs for each viewpoint, providing group-level contact data.</li> </ul> <p>Phase 6: Contact Matrix Generation </p> <ul> <li>Cooler Creation: Pairs files are loaded into Cooler format (HDF5-based) at the primary resolution defined in the config.</li> <li>Multi-resolution Zoomification: Each Cooler is zoomified to create <code>.mcool</code> files with multiple resolution levels for browsing at different scales.</li> <li>Cooler Aggregation: Per-viewpoint Cooler files are combined into a single group-level <code>.mcool</code> file.</li> </ul> <p>Phase 7: Signal Tracks </p> <ul> <li>Per-Replicate BigWigs: BigWig tracks are generated for each sample and viewpoint, normalised by the number of cis contacts (n_cis CPM) to allow comparison between samples with different capture efficiencies.</li> <li>Group BigWigs: Both normalised (n_cis-scaled) and raw (unscaled) BigWigs are generated for each consensus group.</li> <li>Aggregated BigWigs: Replicate BigWigs are averaged within each condition to produce mean signal tracks.</li> <li>Comparison BigWigs: Subtraction BigWigs are generated between conditions (e.g., treatment minus control) to highlight differential interactions.</li> </ul> <p>Phase 8: Peak Calling </p> <ul> <li>LanceOtron-MCC: A deep-learning peak caller identifies significant interaction peaks from the unscaled group BigWigs. This runs on GPU when available.</li> </ul>"},{"location":"pipeline/#crispr-screens-crispr","title":"CRISPR Screens (CRISPR)","text":"<p>Quantifies guide RNA representation across pooled CRISPR screen experiments.</p> <ul> <li>Adapter Detection: Automatically detects CRISPR-specific adapter sequences in the reads to ensure correct trimming.</li> <li>Quantification: Counts the number of reads mapping to each guide RNA in the library, producing a guide-level count matrix across samples.</li> <li>Analysis: MAGeCK performs statistical analysis to identify guides and genes that are enriched or depleted between conditions (e.g., treatment vs. control). Both the test module (rank-based) and MLE module (maximum likelihood) are available, accounting for the multiple guides per gene.</li> </ul>"},{"location":"pipeline/#multiomics-multiomics","title":"Multiomics (MULTIOMICS)","text":"<p>Run multiple assay types together in one project for integrated outputs. This is useful when you have matched samples across assays (e.g., ATAC + RNA from the same conditions) and want to analyse them in a single coordinated run. Configure per-assay sections and enable multiomics mode in the config.</p>"},{"location":"pipeline/#downstream-analysis","title":"Downstream Analysis","text":""},{"location":"pipeline/#motif-analysis","title":"Motif Analysis","text":"<p>Identifies DNA sequence motifs enriched in peak regions, helping to determine which transcription factors may be driving binding or accessibility.</p> <ul> <li>MEME-ChIP: Performs both de novo motif discovery and comparison against known motif databases in a single analysis.</li> <li>HOMER: Runs <code>findMotifsGenome</code> for de novo and known motif enrichment, with broader database support.</li> </ul>"},{"location":"pipeline/#heatmaps-and-metaplots","title":"Heatmaps and Metaplots","text":"<p>Deeptools generates signal heatmaps and average profile plots (metaplots) centred on peak regions or gene features. These provide a visual summary of signal distribution across all peaks or genes in a single figure.</p>"},{"location":"pipeline/#visualisation","title":"Visualisation","text":"<ul> <li>UCSC Genome Browser Hub: When enabled, SeqNado generates a track hub that can be loaded directly into the UCSC Genome Browser for interactive exploration of BigWig tracks and peak calls.</li> <li>Plotnado: An interactive browser visualisation for exploring signal at specific loci.</li> </ul>"},{"location":"pipeline/#merged-quantification","title":"Merged Quantification","text":"<p>When consensus peaks are defined from merged sample groups, reads from individual samples are counted across the consensus peak set to produce a peaks-by-samples count matrix \u2014 analogous to the gene count matrix in RNA-seq.</p>"},{"location":"pipeline/#technical-details","title":"Technical Details","text":""},{"location":"pipeline/#resource-management","title":"Resource Management","text":"<p>SeqNado automatically calculates required cores and memory for each step based on your provided configuration and the available system resources.</p>"},{"location":"pipeline/#parallelization","title":"Parallelization","text":"<p>The pipeline leverages Snakemake's ability to run samples in parallel, scaling from local machines to large high-performance computing (HPC) clusters.</p> <p>For command-line options (presets, queues, scaling), see seqnado pipeline.</p> <p>See Also:</p> <ul> <li>Outputs Reference - Understanding your results</li> <li>HPC Clusters - Configure for HPC environments</li> <li>Troubleshooting - Pipeline execution issues</li> <li>Output Examples - Example analysis results</li> </ul>"},{"location":"quick_start/","title":"Quick Start","text":"<p>\u2190 Back to main page</p>"},{"location":"quick_start/#quick-start","title":"Quick Start","text":"<p>Get started with SeqNado in just a few steps.</p> <p>Tip</p> <p>For a complete reference of all CLI commands and options, see the CLI Reference. This page provides detailed examples and common workflows.</p> <p>SeqNado can be run for any of the following assay types, as well as in multiomics mode:</p> <ul> <li>ATAC-seq: <code>atac</code></li> <li>ChIP-seq: <code>chip</code></li> <li>CRISPR analysis: <code>crispr</code></li> <li>CUT&amp;Tag: <code>cat</code></li> <li>MCC: <code>mcc</code></li> <li>Methylation: <code>meth</code></li> <li>RNA-seq: <code>rna</code></li> <li>SNP analysis: <code>snp</code></li> </ul>"},{"location":"quick_start/#example-workflow","title":"Example Workflow","text":""},{"location":"quick_start/#1-install-seqnado","title":"1. Install SeqNado","text":"<p>The fastest method to install SeqNado is from bioconda via mamba.</p> <pre><code>mamba create -n seqnado -c bioconda seqnado\nmamba activate seqnado\n</code></pre>"},{"location":"quick_start/#2-initialise-seqnado","title":"2. Initialise SeqNado","text":"<p>The <code>seqnado init</code> command initializes the SeqNado user environment. This step ensures that the necessary configuration files and dependencies are set up for the package to function correctly.</p>"},{"location":"quick_start/#usage","title":"Usage","text":"<pre><code>seqnado init [OPTIONS]\n</code></pre>"},{"location":"quick_start/#options","title":"Options","text":"<ul> <li><code>--preset, --no-preset</code>: Use packaged preset genomes instead of the editable template (default: disabled).</li> <li><code>--dry-run, --no-dry-run</code>: Show actions without writing files or running scripts (default: disabled).</li> <li><code>--verbose, -v</code>: Increase logging verbosity.</li> </ul>"},{"location":"quick_start/#actions-performed","title":"Actions Performed","text":"<ul> <li>Logs the current Conda environment if active (optional).</li> <li>Runs the packaged Apptainer/Singularity initialization if <code>apptainer</code> is available on the system PATH.</li> <li>Ensures the <code>~/.config/seqnado/genome_config.json</code> file exists, either as a template or using a preset.</li> </ul>"},{"location":"quick_start/#example","title":"Example","text":"<p>Initialize SeqNado with default settings: <pre><code>seqnado init\n</code></pre></p> <p>For more details, see seqnado init.</p>"},{"location":"quick_start/#3-set-up-genome-references-for-seqnado","title":"3. Set up genome references for SeqNado","text":"<p>The <code>seqnado genomes</code> command manages genome configurations, including listing, editing, building, or generating <code>fastq-screen</code> configurations.</p>"},{"location":"quick_start/#usage_1","title":"Usage","text":"<pre><code>seqnado genomes COMMAND [OPTIONS]\n</code></pre>"},{"location":"quick_start/#commands","title":"Commands","text":"<ul> <li>list <code>[ASSAY]</code>: List available genome configurations (default assay: <code>atac</code>).</li> <li>edit: Edit the genome configuration file in your <code>$EDITOR</code>.</li> <li>build: Build a new genome from UCSC (downloads FASTA/GTF and builds indices).</li> <li>fastqscreen: Generate a <code>fastq-screen</code> configuration file.</li> </ul>"},{"location":"quick_start/#main-options","title":"Main Options","text":"<p>For <code>build</code> command: - <code>--name, -n</code>: Genome name(s), comma-separated for multiple (e.g., <code>hg38</code> or <code>hg38,mm39,dm6</code>) [required] - <code>--outdir, -o</code>: Output directory for genome builds (default: <code>genome_build</code>). - <code>--spikein, -sp</code>: Spike-in genome name for composite builds (e.g., <code>mm39</code>). - <code>--cores, -c</code>: Number of Snakemake cores (default: 4). - <code>--dry-run</code>: Preview without executing.</p> <p>For <code>fastqscreen</code> command: - <code>--screen, -s</code>: Output path for <code>fastq-screen</code> config (default: <code>~/.config/seqnado/fastq_screen.conf</code>). - <code>--threads, -t</code>: Number of threads for Bowtie2 (default: 8). - <code>--no-contaminants</code>: Exclude contaminant databases. - <code>--contaminant-path</code>: Path to contaminant reference files.</p> <p>Global options: - <code>--verbose, -v</code>: Increase logging verbosity.</p>"},{"location":"quick_start/#examples","title":"Examples","text":"<p>Build a single genome: <pre><code>seqnado genomes build --name hg38 --outdir /path/to/output\n</code></pre></p> <p>Build multiple genomes: <pre><code>seqnado genomes build --name hg38,mm39,dm6 --outdir /path/to/output\n</code></pre></p> <p>List configured genomes for ATAC-seq: <pre><code>seqnado genomes list atac\n</code></pre></p> <p>Edit genome configuration: <pre><code>seqnado genomes edit\n</code></pre></p> <p>For more details, see seqnado genomes.</p>"},{"location":"quick_start/#4-configure-a-seqnado-run","title":"4. Configure a SeqNado run","text":"<p>The <code>seqnado config</code> command builds a workflow configuration YAML for the selected assay. If no assay is provided, the command operates in multiomics mode.</p>"},{"location":"quick_start/#usage_2","title":"Usage","text":"<pre><code>seqnado config [OPTIONS] [ASSAY]\n</code></pre>"},{"location":"quick_start/#arguments","title":"Arguments","text":"<ul> <li>ASSAY: Assay type. Options include <code>rna</code>, <code>atac</code>, <code>snp</code>, <code>chip</code>, <code>cat</code>, <code>meth</code>, <code>mcc</code>, <code>crispr</code>. If omitted, multiomics mode is used.</li> </ul>"},{"location":"quick_start/#options_1","title":"Options","text":"<ul> <li><code>--make-dirs, --no-make-dirs</code>: Create or skip creating the output project directory or FASTQ subdirectory (default: create).</li> <li><code>--render-options, --no-render-options</code>: Render all options, even if not used by the workflow (default: disabled).</li> <li><code>--output, -o</code>: Specify the explicit path for the rendered configuration file.</li> <li><code>--interactive, --no-interactive</code>: Enable or disable interactive prompts for configuration values (default: enabled).</li> <li><code>--verbose, -v</code>: Increase logging verbosity.</li> </ul>"},{"location":"quick_start/#example_1","title":"Example","text":"<p>Generate a configuration file: <pre><code>seqnado config atac\n</code></pre></p> <p>You can edit the generated YAML file to customize the workflow for your specific needs.</p> <p>For more details, see seqnado config.</p>"},{"location":"quick_start/#5-download-fastq-files-from-geosra","title":"5. Download fastq files from GEO/SRA","text":"<p>The <code>seqnado download</code> command downloads FASTQ files from GEO/SRA using a metadata TSV file and optionally generates a design file for downstream analysis.</p>"},{"location":"quick_start/#usage_3","title":"Usage","text":"<pre><code>seqnado download [OPTIONS] METADATA_TSV\n</code></pre>"},{"location":"quick_start/#arguments_1","title":"Arguments","text":"<ul> <li>METADATA_TSV: Path to TSV file from GEO/ENA with run information. Must contain columns: <code>run_accession</code>, <code>sample_title</code>, <code>library_name</code>, and <code>library_layout</code>.</li> </ul>"},{"location":"quick_start/#options_2","title":"Options","text":"<ul> <li><code>--outdir, -o</code>: Output directory for downloaded FASTQ files (default: <code>fastqs</code>).</li> <li><code>--assay, -a</code>: Assay type for generating design file after download. If not provided, only downloads FASTQs.</li> <li><code>--design-output, -d</code>: Output path for design CSV (default: <code>metadata_{assay}.csv</code> in outdir).</li> <li><code>--cores, -c</code>: Number of parallel download jobs (default: 4).</li> <li><code>--preset</code>: Snakemake job profile preset for downloads (default: <code>le</code>).</li> <li><code>--dry-run, -n</code>: Show what would be downloaded without downloading.</li> <li><code>--verbose, -v</code>: Increase logging verbosity.</li> </ul>"},{"location":"quick_start/#example_2","title":"Example","text":"<p>Download FASTQ files and generate an RNA-seq design file: <pre><code>seqnado download filereport_read_run_PRJNA1234567.tsv --outdir geo_data --assay rna -c 8\n</code></pre></p> <p>Info</p> <p>The TSV file is typically downloaded from the ENA Browser. Required columns are:</p> <ul> <li><code>run_accession</code>: SRA run ID (e.g., SRR123456)</li> <li><code>sample_title</code>: Sample name</li> <li><code>library_name</code>: GSM identifier or library name</li> <li><code>library_layout</code>: Must be <code>PAIRED</code> or <code>SINGLE</code> to correctly format output files</li> </ul> <p>For more details, see GEO/SRA Download Guide.</p>"},{"location":"quick_start/#6-generate-experiment-design","title":"6. Generate experiment design","text":"<p>The <code>seqnado design</code> command generates a metadata design CSV from FASTQ files for a specific assay. If no assay is provided, the command operates in multiomics mode. The generated CSV outlines the structure of the experiment, including sample names, conditions, and other relevant metadata.</p>"},{"location":"quick_start/#usage_4","title":"Usage","text":"<pre><code>seqnado design [OPTIONS] [ASSAY] [FASTQ ...]\n</code></pre>"},{"location":"quick_start/#arguments_2","title":"Arguments","text":"<ul> <li>ASSAY: Assay type. Options include <code>rna</code>, <code>atac</code>, <code>snp</code>, <code>chip</code>, <code>cat</code>, <code>meth</code>, <code>mcc</code>, <code>crispr</code>. If omitted, multiomics mode is used.</li> <li>FASTQ: One or more FASTQ files to include in the design.</li> </ul>"},{"location":"quick_start/#options_3","title":"Options","text":"<ul> <li><code>--output, -o</code>: Specify the output CSV filename (default: <code>metadata_{assay}.csv</code>).</li> <li><code>--group-by</code>: Group samples by a regular expression or a column.</li> <li><code>--auto-discover</code>: Automatically search common folders for FASTQ files if none are provided (default: enabled).</li> <li><code>--interactive</code>: Interactively add missing columns using schema defaults (default: enabled).</li> <li><code>--accept-all-defaults</code>: Non-interactive mode; auto-add only columns with schema defaults.</li> <li><code>--verbose, -v</code>: Increase logging verbosity.</li> </ul>"},{"location":"quick_start/#example_3","title":"Example","text":"<p>Generate a design CSV for ATAC-seq: <pre><code>seqnado design atac\n</code></pre></p> <p>The generated CSV can be reviewed and edited to ensure all experimental details are correctly specified.</p> <p>For more details, see seqnado design.</p>"},{"location":"quick_start/#7-run-seqnado-pipeline","title":"7. Run SeqNado pipeline","text":"<p>The <code>seqnado pipeline</code> command runs the data processing pipeline for the specified assay. It uses Snakemake under the hood to manage the workflow.</p>"},{"location":"quick_start/#usage_5","title":"Usage","text":"<pre><code>seqnado pipeline [OPTIONS] [ASSAY]\n</code></pre>"},{"location":"quick_start/#arguments_3","title":"Arguments","text":"<ul> <li>ASSAY: Assay type. Required for single-assay workflows, optional for multiomics mode.</li> </ul>"},{"location":"quick_start/#options_4","title":"Options","text":"<ul> <li><code>--configfile</code>: Path to a SeqNado configuration YAML file (default: <code>config_&lt;ASSAY&gt;.yaml</code>).</li> <li><code>--preset</code>: Snakemake job profile preset. Options include:</li> </ul> Preset Profile Description <code>le</code> <code>local_environment</code> Local execution, no containers (default) <code>ls</code> <code>local_singularity</code> Local execution with Apptainer/Singularity <code>lc</code> <code>local_conda</code> Local execution with Conda + Apptainer <code>ld</code> <code>local_docker</code> Local execution with Conda + Docker <code>ss</code> <code>slurm_singularity</code> SLURM cluster with Apptainer <code>t</code> Test For testing and development <ul> <li><code>--clean-symlinks, --no-clean-symlinks</code>: Remove symlinks created by previous runs (default: disabled).</li> <li><code>--scale-resources, -s</code>: Scale memory and time resources (default: 1.0).</li> <li><code>--verbose, -v</code>: Increase logging verbosity.</li> <li><code>--queue, -q</code>: Specify the SLURM queue/partition for the <code>ss</code> preset (default: <code>short</code>).</li> <li><code>--print-cmd</code>: Print the Snakemake command before running it.</li> </ul>"},{"location":"quick_start/#examples_1","title":"Examples","text":"<p>Run the pipeline locally for ATAC-seq: <pre><code>seqnado pipeline atac --preset le\n</code></pre></p> <p>Run on an HPC cluster with SLURM and increased resources: <pre><code>seqnado pipeline atac --preset ss --queue short --scale-resources 1.5\n</code></pre></p> <p>For more details, see seqnado pipeline or the HPC Clusters guide for cluster-specific configuration.</p>"},{"location":"tool-config-examples/","title":"Usage Examples","text":""},{"location":"tool-config-examples/#basic-usage","title":"Basic Usage","text":""},{"location":"tool-config-examples/#create-configuration-for-specific-assay","title":"Create Configuration for Specific Assay","text":"<pre><code>from seqnado import Assay\nfrom your_module import ThirdPartyToolsConfig\n\n# Create configuration with assay-specific defaults\nconfig = ThirdPartyToolsConfig.for_assay(Assay.ATAC)\n\n# Export to dictionary\nconfig_dict = config.model_dump(exclude_none=True)\n</code></pre>"},{"location":"tool-config-examples/#custom-tool-configuration","title":"Custom Tool Configuration","text":"<pre><code># Override specific tools during creation\nconfig = ThirdPartyToolsConfig.for_assay(\n    Assay.ATAC,\n    bowtie2=Bowtie2(\n        align=ToolConfig(threads=16, options=\"--very-fast\")\n    ),\n    samtools=Samtools(\n        sort=ToolConfig(threads=12, options=\"-@ {threads} -m 4G\")\n    )\n)\n</code></pre>"},{"location":"tool-config-examples/#manual-configuration","title":"Manual Configuration","text":"<pre><code># Create empty configuration and add tools manually\nconfig = ThirdPartyToolsConfig()\n\n# Add specific tools\nconfig.bowtie2 = Bowtie2()\nconfig.samtools = Samtools()\nconfig.deeptools = Deeptools()\n\n# Check which tools are configured\nconfigured_tools = config.get_configured_tools()\nprint(f\"Configured tools: {list(configured_tools.keys())}\")\n</code></pre>"},{"location":"tool-config-examples/#advanced-usage","title":"Advanced Usage","text":""},{"location":"tool-config-examples/#option-filtering","title":"Option Filtering","text":"<pre><code>from your_module import OptionsBase, ToolConfig\n\n# Create options with exclusions\noptions = OptionsBase(\n    value=\"--very-sensitive --threads 8 --fast\",\n    exclude={\"--fast\"}  # This option will be filtered out\n)\n\n# The filtered result will be: \"--very-sensitive --threads 8\"\nprint(options.option_string_filtered)\n</code></pre>"},{"location":"tool-config-examples/#dynamic-thread-configuration","title":"Dynamic Thread Configuration","text":"<pre><code># Use template strings for dynamic values\nconfig = ThirdPartyToolsConfig.for_assay(\n    Assay.RNA,\n    samtools=Samtools(\n        sort=ToolConfig(\n            threads=16,\n            options=\"-@ {threads} -m 2G\"  # {threads} will be replaced\n        )\n    )\n)\n</code></pre>"},{"location":"tool-config-examples/#serialization-options","title":"Serialization Options","text":"<pre><code># Standard dictionary export\nconfig_dict = config.model_dump(exclude_none=True)\n\n# Include descriptions as help fields\nconfig_with_help = config.dump_with_descriptions()\n\n# Export to YAML with comments (requires PyYAML)\nyaml_output = config.dump_yaml_with_comments()\n\n# Export to TOML with comments (requires tomli-w)  \ntoml_output = config.dump_toml_with_comments()\n</code></pre>"},{"location":"tool-config-examples/#integration-examples","title":"Integration Examples","text":""},{"location":"tool-config-examples/#with-configuration-files","title":"With Configuration Files","text":"<pre><code>import json\nfrom pathlib import Path\n\n# Save configuration\nconfig = ThirdPartyToolsConfig.for_assay(Assay.CHIP)\nconfig_path = Path(\"config.json\")\nconfig_path.write_text(config.model_dump_json(indent=2, exclude_none=True))\n\n# Load configuration\nconfig_data = json.loads(config_path.read_text())\nloaded_config = ThirdPartyToolsConfig(**config_data)\n</code></pre>"},{"location":"tool-config-examples/#with-environment-specific-overrides","title":"With Environment-Specific Overrides","text":"<pre><code>import os\n\ndef create_config_for_environment():\n    # Base configuration\n    config = ThirdPartyToolsConfig.for_assay(Assay.ATAC)\n\n    # Override based on environment\n    if os.getenv(\"HIGH_MEMORY\") == \"true\":\n        config.samtools.sort.options = \"-@ {threads} -m 8G\"\n\n    if os.getenv(\"FAST_MODE\") == \"true\":\n        config.bowtie2.align.align.options = \"--very-fast\"\n\n    return config\n</code></pre>"},{"location":"tool-config-examples/#validation-and-error-handling","title":"Validation and Error Handling","text":"<pre><code>try:\n    # This will raise validation error for invalid options\n    config = ThirdPartyToolsConfig(\n        bowtie2=Bowtie2(\n            align=ToolConfig(\n                threads=0,  # Invalid: less than minimum\n                options=\"--invalid'quote\"  # Invalid: bad quoting\n            )\n        )\n    )\nexcept ValueError as e:\n    print(f\"Configuration error: {e}\")\n</code></pre>"},{"location":"tools/","title":"Third-Party Tools","text":"<p>SeqNado integrates multiple best-in-class bioinformatics tools to provide comprehensive genomics analysis pipelines. For a full list of tools with references, see the Citation Guidelines.</p>"},{"location":"tools/#checking-tool-versions","title":"Checking Tool Versions","text":"<p>All tools are version-locked in SeqNado containers to ensure reproducibility. To check versions and get tool information, use the <code>seqnado tools</code> command:</p> <pre><code># List all tools with versions\nseqnado tools\n\n# List tools in a specific category (e.g., Download, Alignment, Analysis)\nseqnado tools --category\n\n# View detailed information about a specific tool\nseqnado tools macs2\n\n# Show tool help/options from the container\nseqnado tools macs2 --options\n</code></pre> <p>See the CLI Reference for complete documentation of the <code>tools</code> command.</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>\u2190 Back to main page</p>"},{"location":"troubleshooting/#troubleshooting","title":"Troubleshooting","text":"<p>This page covers common errors you may encounter at each stage of the SeqNado workflow, along with their causes and fixes.</p> <p>Tip</p> <p>For HPC/cluster-specific issues (SLURM, resource limits, container downloads), see the HPC Clusters guide.</p>"},{"location":"troubleshooting/#installation","title":"Installation","text":""},{"location":"troubleshooting/#condamamba-cannot-find-the-seqnado-package","title":"Conda/Mamba cannot find the <code>seqnado</code> package","text":"<pre><code>PackagesNotFoundError: The following packages are not available from current channels: seqnado\n</code></pre> <p>Cause: The bioconda channel is not configured.</p> <p>Fix: Add the required channels and retry:</p> <pre><code>conda config --add channels defaults\nconda config --add channels bioconda\nconda config --add channels conda-forge\nmamba create -n seqnado seqnado\n</code></pre>"},{"location":"troubleshooting/#dependency-conflicts-during-installation","title":"Dependency conflicts during installation","text":"<pre><code>LibMambaUnsatisfiableError: Encountered problems while solving...\n</code></pre> <p>Cause: An existing environment has conflicting packages.</p> <p>Fix: Create a fresh environment rather than installing into an existing one:</p> <pre><code>mamba create -n seqnado -c bioconda seqnado\n</code></pre> <p>If the problem persists, try installing with <code>pip</code> in a clean environment:</p> <pre><code>mamba create -n seqnado python=3.12\nmamba activate seqnado\npip install seqnado\n</code></pre>"},{"location":"troubleshooting/#initialisation-seqnado-init","title":"Initialisation (<code>seqnado init</code>)","text":""},{"location":"troubleshooting/#apptainer-singularity-not-found","title":"<code>apptainer</code> / <code>singularity</code> not found","text":"<pre><code>`apptainer` not found on PATH.\n</code></pre> <p>Cause: Apptainer (or Singularity) is not installed or not loaded.</p> <p>Fix: On most HPC systems, you need to load the module first:</p> <pre><code>module load apptainer\n# or\nmodule load singularity\n</code></pre> <p>If neither is available, ask your cluster admin to install Apptainer, or use a local environment preset (<code>le</code>) which does not require containers:</p> <pre><code>seqnado pipeline atac --preset le\n</code></pre>"},{"location":"troubleshooting/#failed-to-pull-singularity-image-remote-has-no-library-client","title":"Failed to pull singularity image \u2014 remote has no library client","text":"<pre><code>FATAL: Unable to get library client configuration:\nremote has no library client\n</code></pre> <p>Cause: The default Apptainer remote endpoint is not configured.</p> <p>Fix: Re-run <code>seqnado init</code>, or manually add the SylabsCloud remote:</p> <pre><code>apptainer remote add --no-login SylabsCloud cloud.sylabs.io\napptainer remote use SylabsCloud\n</code></pre> <p>Then re-run <code>seqnado init</code>.</p>"},{"location":"troubleshooting/#genome-setup-seqnado-genomes","title":"Genome Setup (<code>seqnado genomes</code>)","text":""},{"location":"troubleshooting/#no-bowtie2-index-files-found","title":"No Bowtie2 index files found","text":"<pre><code>ValueError: No Bowtie2 index files found for prefix '...'\n</code></pre> <p>Cause: The genome was not built yet, or the path in the genome config points to the wrong location.</p> <p>Fix: Check your genome configuration and rebuild if needed:</p> <pre><code>seqnado genomes list           # check what's configured\nseqnado genomes edit           # fix paths if wrong\nseqnado genomes build \\\n  --name hg38 \\\n  --outdir /path/to/output     # rebuild if missing\n</code></pre>"},{"location":"troubleshooting/#star-index-directory-does-not-exist","title":"STAR index directory does not exist","text":"<pre><code>ValueError: The directory ... does not exist or is not a directory\n</code></pre> <p>Cause: The STAR index path in the genome config is incorrect or the index has not been built.</p> <p>Fix: Build the genome, which generates both Bowtie2 and STAR indices:</p> <pre><code>seqnado genomes build --name hg38 --outdir /path/to/output\n</code></pre> <p>Then verify the path with <code>seqnado genomes edit</code>.</p>"},{"location":"troubleshooting/#genome-build-runs-out-of-memory","title":"Genome build runs out of memory","text":"<p>Cause: STAR index building requires significant RAM (~32 GB for the human genome).</p> <p>Fix: Run the build on a node with enough memory. On an HPC cluster, request an interactive session with sufficient resources before building:</p> <pre><code>srun --mem=40G --cpus-per-task=8 --time=2:00:00 --pty bash\nmamba activate seqnado\nseqnado genomes build --name hg38 --outdir /path/to/output --cores 8\n</code></pre>"},{"location":"troubleshooting/#configuration-seqnado-config","title":"Configuration (<code>seqnado config</code>)","text":""},{"location":"troubleshooting/#yaml-syntax-errors","title":"YAML syntax errors","text":"<pre><code>yaml.scanner.ScannerError: while scanning ...\n</code></pre> <p>Cause: The YAML config file has a formatting error. YAML is sensitive to indentation and special characters.</p> <p>Fix: Common YAML pitfalls to check:</p> <ul> <li>Use spaces, not tabs for indentation</li> <li>Keep indentation consistent (2 spaces per level)</li> <li>Strings containing colons or special characters need quoting: <code>name: \"my:sample\"</code></li> <li>Boolean values are <code>true</code>/<code>false</code> (lowercase)</li> </ul> <p>Tip</p> <p>Run <code>seqnado config</code> interactively to regenerate the config file rather than editing YAML by hand. This avoids most syntax issues: <pre><code>seqnado config atac --interactive\n</code></pre></p>"},{"location":"troubleshooting/#invalid-strandedness-value","title":"Invalid strandedness value","text":"<pre><code>ValueError: strandedness must be 0 (unstranded), 1 (forward), or 2 (reverse).\n</code></pre> <p>Cause: The strandedness field in the config has an invalid value.</p> <p>Fix: Set it to one of the accepted values:</p> <ul> <li><code>0</code> \u2014 unstranded (most common for standard RNA-seq library preps)</li> <li><code>1</code> \u2014 forward stranded</li> <li><code>2</code> \u2014 reverse stranded (common for dUTP-based library preps)</li> </ul> <p>If unsure, check with whoever prepared the library, or use <code>0</code> as a starting point and examine the infer_experiment results in the QC report.</p>"},{"location":"troubleshooting/#project-name-contains-invalid-characters","title":"Project name contains invalid characters","text":"<pre><code>ValueError: Name contains invalid characters. Use alphanumerics, hyphens, and underscores.\n</code></pre> <p>Cause: The project name contains spaces or special characters.</p> <p>Fix: Use only letters, numbers, hyphens (<code>-</code>), and underscores (<code>_</code>):</p> <pre><code># Bad\nname: My ChIP Experiment (2024)\n\n# Good\nname: my-chip-experiment-2024\n</code></pre>"},{"location":"troubleshooting/#design-files-seqnado-design","title":"Design Files (<code>seqnado design</code>)","text":""},{"location":"troubleshooting/#sample-id-contains-invalid-characters","title":"Sample ID contains invalid characters","text":"<pre><code>ValueError: sample_id must match ^[a-zA-Z0-9_-]+$\n</code></pre> <p>Cause: Sample names in your FASTQ filenames or design CSV contain spaces, dots, or other special characters.</p> <p>Fix: Rename your FASTQ files to use only letters, numbers, hyphens, and underscores. For example:</p> <pre><code># Bad\nSample 1.Rep1_R1.fastq.gz\nsample.name_R1.fastq.gz\n\n# Good\nSample1-Rep1_R1.fastq.gz\nsample_name_R1.fastq.gz\n</code></pre>"},{"location":"troubleshooting/#duplicate-sample-ids","title":"Duplicate sample IDs","text":"<pre><code>ValueError: sample_id values are not unique\n</code></pre> <p>Cause: Two or more rows in the design CSV have the same sample ID, or multiple FASTQ file pairs resolve to the same sample name.</p> <p>Fix: Check your design CSV for duplicate entries. For IP-based assays (ChIP-seq, CUT&amp;Tag), duplicates are allowed only if the <code>sample_id</code> + <code>ip</code> combination is unique (e.g., same sample with different antibodies).</p>"},{"location":"troubleshooting/#invalid-number-of-fastq-files-for-sample","title":"Invalid number of FASTQ files for sample","text":"<pre><code>ValueError: Invalid number of FASTQ files for sample_name: 3. Expected 1 or 2 files.\n</code></pre> <p>Cause: SeqNado found more than 2 FASTQ files matching the same sample name. This usually happens when file naming is inconsistent or extra files are in the <code>fastqs/</code> directory.</p> <p>Fix: Check the <code>fastqs/</code> directory for unexpected files:</p> <pre><code>ls fastqs/ | sort\n</code></pre> <p>Each sample should have either 1 file (single-end) or exactly 2 files (paired-end, <code>_R1</code> and <code>_R2</code>). Remove or move any extra files.</p>"},{"location":"troubleshooting/#no-fastq-files-found","title":"No FASTQ files found","text":"<pre><code>FileNotFoundError: No FASTQ files found in ...\n</code></pre> <p>Cause: The <code>fastqs/</code> directory is empty or the files don't have a recognised extension (<code>.fastq.gz</code>, <code>.fq.gz</code>).</p> <p>Fix: Check that your symlinks are valid and point to actual files:</p> <pre><code>ls -la fastqs/\n</code></pre> <p>If the symlinks are broken (shown in red), recreate them with the correct source path:</p> <pre><code>ln -s /correct/path/to/fastq/files/* fastqs/\n</code></pre>"},{"location":"troubleshooting/#antibody-must-be-specified-for-chipcuttag-assays","title":"Antibody must be specified for ChIP/CUT&amp;Tag assays","text":"<pre><code>ValueError: Antibody must be specified for ChIP-seq assays.\n</code></pre> <p>Cause: The design file for a ChIP-seq or CUT&amp;Tag run is missing the <code>ip</code> column, or it contains empty values.</p> <p>Fix: Ensure your design CSV has an <code>ip</code> column specifying the antibody or \"input\" for each sample. See the Design Guide for examples.</p>"},{"location":"troubleshooting/#ip-control-pairing-errors","title":"IP control pairing errors","text":"<pre><code>ValueError: Multiple control samples matched ..., but no manual mapping provided\n</code></pre> <p>Cause: SeqNado found more than one \"input\" sample and cannot automatically determine which control belongs to which IP sample.</p> <p>Fix: Explicitly map controls in your design CSV by ensuring each IP sample has a unique control, or add a <code>control</code> column to specify the pairing manually.</p>"},{"location":"troubleshooting/#pipeline-execution-seqnado-pipeline","title":"Pipeline Execution (<code>seqnado pipeline</code>)","text":""},{"location":"troubleshooting/#snakemake-not-found","title":"<code>snakemake</code> not found","text":"<pre><code>`snakemake` not found on PATH. Install/activate the environment that provides it.\n</code></pre> <p>Cause: The SeqNado conda environment is not activated.</p> <p>Fix:</p> <pre><code>mamba activate seqnado\n</code></pre>"},{"location":"troubleshooting/#config-file-not-found","title":"Config file not found","text":"<pre><code>Workflow defines configfile config_atac.yaml but it is not present or accessible.\n</code></pre> <p>Cause: You are running the pipeline from the wrong directory, or <code>seqnado config</code> was not run first.</p> <p>Fix: Make sure you are in the project directory that contains your config file:</p> <pre><code>ls config_*.yaml   # check if config exists in current directory\n</code></pre> <p>If not, either <code>cd</code> into the correct project directory, or point to the config explicitly:</p> <pre><code>seqnado pipeline atac --configfile /path/to/config_atac.yaml\n</code></pre>"},{"location":"troubleshooting/#snakemake-rule-fails-with-a-cryptic-error","title":"Snakemake rule fails with a cryptic error","text":"<p>Cause: A specific step in the pipeline failed. Snakemake error output can be verbose and hard to parse.</p> <p>Fix: Look for the actual error by scrolling up past the Snakemake traceback. The key information is usually in these lines:</p> <ol> <li>The rule name \u2014 tells you which step failed (e.g., <code>rule align_bowtie2</code>)</li> <li>The log file path \u2014 Snakemake prints <code>log: seqnado_output/.../logs/...</code> which contains the tool's actual error output</li> <li>The return code \u2014 a non-zero exit code from the underlying tool</li> </ol> <p>Read the log file for the specific error:</p> <pre><code>cat seqnado_output/atac/logs/&lt;rule_name&gt;/&lt;sample&gt;.log\n</code></pre> <p>Tip</p> <p>Use <code>--verbose</code> and <code>--print-cmd</code> to get more diagnostic information: <pre><code>seqnado pipeline atac --preset le --verbose --print-cmd\n</code></pre></p>"},{"location":"troubleshooting/#pipeline-killed-out-of-memory","title":"Pipeline killed \u2014 out of memory","text":"<pre><code>slurmstepd: error: Detected 1 oom_kill event in StepId=...\n</code></pre> <p>Cause: A pipeline step exceeded the allocated memory on the cluster.</p> <p>Fix: Increase the resource scaling factor:</p> <pre><code>seqnado pipeline atac --preset ss --scale-resources 2.0\n</code></pre> <p>For persistent memory issues, see the HPC Clusters troubleshooting guide.</p>"},{"location":"troubleshooting/#pipeline-hangs-or-seems-stuck","title":"Pipeline hangs or seems stuck","text":"<p>Cause: This is usually normal \u2014 some steps (alignment, peak calling) take a long time on large datasets.</p> <p>Fix: Check if jobs are actually running:</p> <pre><code># On SLURM clusters\nsqueue -u $USER\n\n# For local execution, check CPU usage\ntop\n</code></pre> <p>If jobs are queued but not starting, your cluster partition may be busy. Consider switching to a less-busy queue with <code>--queue</code>.</p>"},{"location":"troubleshooting/#geosra-downloads-seqnado-download","title":"GEO/SRA Downloads (<code>seqnado download</code>)","text":""},{"location":"troubleshooting/#missing-required-columns-in-tsv","title":"Missing required columns in TSV","text":"<pre><code>Missing required columns in TSV: run_accession, sample_title\n</code></pre> <p>Cause: The metadata TSV downloaded from ENA is missing expected columns.</p> <p>Fix: Ensure your TSV file contains these columns: <code>run_accession</code>, <code>sample_title</code>, <code>library_name</code>, and ideally <code>library_layout</code>. Download the file from the ENA Browser using the \"Download report\" option with the correct column selection.</p>"},{"location":"troubleshooting/#unknown-library_layout-value","title":"Unknown library_layout value","text":"<pre><code>Unknown library_layout '...' for sample_name\n</code></pre> <p>Cause: The <code>library_layout</code> column contains a value other than <code>PAIRED</code> or <code>SINGLE</code>.</p> <p>Fix: Edit the TSV to correct the layout values. Valid values are <code>PAIRED</code> or <code>SINGLE</code> (case-insensitive). If unknown, check the GEO page for the experiment to determine the sequencing type.</p>"},{"location":"troubleshooting/#downloads-fail-or-are-very-slow","title":"Downloads fail or are very slow","text":"<p>Cause: Network issues, or the SRA servers are under load.</p> <p>Fix: Try reducing the number of parallel downloads and retrying:</p> <pre><code>seqnado download metadata.tsv --cores 2\n</code></pre> <p>If downloads consistently fail, check that you have internet access from your compute environment and that no firewall rules are blocking SRA/ENA traffic.</p>"},{"location":"troubleshooting/#general-tips","title":"General Tips","text":""},{"location":"troubleshooting/#enable-verbose-logging","title":"Enable verbose logging","text":"<p>Add <code>--verbose</code> (or <code>-v</code>) to any SeqNado command to see detailed log output. This is the single most useful thing you can do when debugging:</p> <pre><code>seqnado pipeline atac --preset le --verbose\n</code></pre>"},{"location":"troubleshooting/#print-the-underlying-snakemake-command","title":"Print the underlying Snakemake command","text":"<p>Use <code>--print-cmd</code> to see exactly what Snakemake command SeqNado is running. This is helpful when asking for help or reporting bugs:</p> <pre><code>seqnado pipeline atac --preset le --print-cmd\n</code></pre>"},{"location":"troubleshooting/#check-snakemake-log-files","title":"Check Snakemake log files","text":"<p>Pipeline logs are stored in the output directory. Each rule writes its own log:</p> <pre><code>seqnado_output/&lt;assay&gt;/logs/&lt;rule_name&gt;/&lt;sample&gt;.log\n</code></pre> <p>These log files contain the actual output from the underlying tools (Bowtie2, MACS2, DESeq2, etc.) and are usually more informative than the Snakemake error summary.</p>"},{"location":"troubleshooting/#resume-a-failed-pipeline-run","title":"Resume a failed pipeline run","text":"<p>Snakemake automatically tracks completed steps. If a run fails partway through, simply re-run the same command \u2014 it will pick up where it left off:</p> <pre><code>seqnado pipeline atac --preset le\n</code></pre>"},{"location":"troubleshooting/#dry-run-to-check-your-setup","title":"Dry run to check your setup","text":"<p>Use Snakemake's dry-run mode to verify that your config, design, and files are correct without actually running anything:</p> <pre><code>seqnado pipeline atac --preset le -- --dry-run\n</code></pre> <p>This shows you what steps would be executed and can catch configuration errors early.</p>"},{"location":"troubleshooting/#still-stuck","title":"Still stuck?","text":"<ol> <li>Check the FAQ for other common questions</li> <li>Open an issue on GitHub with the error message and your <code>--verbose --print-cmd</code> output</li> </ol>"},{"location":"api/","title":"API Reference","text":"<p>Welcome to the SeqNado API reference documentation. This section provides detailed information about the internal Python API of SeqNado, which is useful for developers and advanced users who want to extend or integrate SeqNado into their own workflows.</p>"},{"location":"api/#modules","title":"Modules","text":"<ul> <li>Core Types: Enums and basic data structures.</li> <li>Configuration: Pydantic models for workflow configuration.</li> <li>Inputs: Classes for handling FASTQ, BAM, and BigWig inputs.</li> <li>Outputs: Logic for managing Snakemake workflow outputs.</li> </ul> <p>\u2190 Back to main page</p>"},{"location":"api/config/","title":"Configuration API","text":"<p>SeqNado uses Pydantic for its configuration management. This page documents the primary configuration models.</p>"},{"location":"api/config/#main-configuration","title":"Main Configuration","text":""},{"location":"api/config/#seqnado.config.SeqnadoConfig","title":"seqnado.config.SeqnadoConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for the SeqNado workflow.</p>"},{"location":"api/config/#seqnado.config.SeqnadoConfig.organism","title":"organism  <code>property</code>","text":"<pre><code>organism: str\n</code></pre> <p>Return the organism (string) from the genome configuration.</p>"},{"location":"api/config/#seqnado.config.SeqnadoConfig.shift_for_tn5_insertion","title":"shift_for_tn5_insertion  <code>property</code>","text":"<pre><code>shift_for_tn5_insertion: bool\n</code></pre> <p>Return the Tn5 shift configuration for the specified assay.</p>"},{"location":"api/config/#seqnado.config.SeqnadoConfig.mcc_viewpoints","title":"mcc_viewpoints  <code>property</code>","text":"<pre><code>mcc_viewpoints: str\n</code></pre> <p>Return the MCC viewpoints file path.</p>"},{"location":"api/config/#seqnado.config.SeqnadoConfig.set_default_pcr_duplicates","title":"set_default_pcr_duplicates","text":"<pre><code>set_default_pcr_duplicates(values)\n</code></pre> <p>Set default PCR duplicate handling based on assay type.</p> Source code in <code>seqnado/config/core.py</code> <pre><code>@model_validator(mode=\"before\")\ndef set_default_pcr_duplicates(cls, values):\n    \"\"\"Set default PCR duplicate handling based on assay type.\"\"\"\n    from seqnado import PCRDuplicateHandling\n\n    if \"pcr_duplicates\" not in values or values[\"pcr_duplicates\"] is None:\n        assay = values.get(\"assay\")\n        # Normalize assay to Assay enum if it's a string\n        if isinstance(assay, str):\n            assay = Assay(assay)\n        # Default to REMOVE for ATAC, ChIP, CAT, SNP, and METH; KEEP for RNA\n        if assay in [Assay.ATAC, Assay.CHIP, Assay.CAT, Assay.SNP, Assay.METH]:\n            values[\"pcr_duplicates\"] = PCRDuplicatesConfig(strategy=PCRDuplicateHandling.REMOVE)\n        else:\n            values[\"pcr_duplicates\"] = PCRDuplicatesConfig(strategy=PCRDuplicateHandling.NONE)\n\n    return values\n</code></pre>"},{"location":"api/config/#seqnado.config.SeqnadoConfig.from_yaml","title":"from_yaml  <code>classmethod</code>","text":"<pre><code>from_yaml(path: Path) -&gt; SeqnadoConfig\n</code></pre> <p>Load configuration from a YAML file.</p> Source code in <code>seqnado/config/core.py</code> <pre><code>@classmethod\ndef from_yaml(cls, path: Path) -&gt; \"SeqnadoConfig\":\n    \"\"\"Load configuration from a YAML file.\"\"\"\n    import yaml\n\n    with open(path, \"r\") as f:\n        data = yaml.safe_load(f)\n\n    return cls(**data)\n</code></pre>"},{"location":"api/config/#seqnado.config.SeqnadoConfig.validate_remove_blacklist","title":"validate_remove_blacklist","text":"<pre><code>validate_remove_blacklist(v)\n</code></pre> <p>Can only be set to True if genome blacklist is provided.</p> Source code in <code>seqnado/config/core.py</code> <pre><code>@field_validator(\"remove_blacklist\")\ndef validate_remove_blacklist(cls, v):\n    \"\"\"Can only be set to True if genome blacklist is provided.\"\"\"\n    if v and not cls.genome.blacklist:\n        raise ValueError(\n            \"remove_blacklist can only be True if genome blacklist is provided.\"\n        )\n    return v\n</code></pre>"},{"location":"api/config/#seqnado.config.SeqnadoConfig.validate_assay_config_matches_assay","title":"validate_assay_config_matches_assay","text":"<pre><code>validate_assay_config_matches_assay(v, info)\n</code></pre> <p>Ensure the assay_config type matches the specified assay.</p> Source code in <code>seqnado/config/core.py</code> <pre><code>@field_validator(\"assay_config\", mode=\"before\")\ndef validate_assay_config_matches_assay(cls, v, info):\n    \"\"\"Ensure the assay_config type matches the specified assay.\"\"\"\n    if v is None:\n        return v\n\n    assay = info.data.get(\"assay\")\n    if assay is None:\n        return v\n\n    expected_config_class = ASSAY_CONFIG_MAP.get(assay)\n    if expected_config_class and not isinstance(v, expected_config_class):\n        if isinstance(v, dict):\n            # Try to create the appropriate config from dict\n            return expected_config_class(**v)\n        else:\n            raise ValueError(\n                f\"assay_config must be of type {expected_config_class.__name__} for assay {assay.value}\"\n            )\n\n    return v\n</code></pre>"},{"location":"api/config/#seqnado.config.SeqnadoConfig.create_assay_config","title":"create_assay_config  <code>classmethod</code>","text":"<pre><code>create_assay_config(\n    assay: Assay, **kwargs\n) -&gt; AssaySpecificConfig\n</code></pre> <p>Create the appropriate assay config for the given assay type.</p> Source code in <code>seqnado/config/core.py</code> <pre><code>@classmethod\ndef create_assay_config(cls, assay: Assay, **kwargs) -&gt; AssaySpecificConfig:\n    \"\"\"Create the appropriate assay config for the given assay type.\"\"\"\n    config_class = cls._ASSAY_CONFIG_MAP.get(assay)\n    if config_class is None:\n        raise ValueError(\n            f\"No configuration class available for assay {assay.value}\"\n        )\n\n    return config_class(**kwargs)\n</code></pre>"},{"location":"api/config/#seqnado.config.ProjectConfig","title":"seqnado.config.ProjectConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for the SeqNado project.</p>"},{"location":"api/config/#genome-configuration","title":"Genome Configuration","text":""},{"location":"api/config/#seqnado.config.GenomeConfig","title":"seqnado.config.GenomeConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for genome-related files and indices.</p>"},{"location":"api/config/#assay-specific-configurations","title":"Assay Specific Configurations","text":"<p>\u2190 Back to API Overview</p>"},{"location":"api/config/#seqnado.config.ATACAssayConfig","title":"seqnado.config.ATACAssayConfig","text":"<p>               Bases: <code>BaseAssayConfig</code>, <code>PeakCallingMixin</code></p> <p>Configuration specific to ATAC-seq assays.</p>"},{"location":"api/config/#seqnado.config.ChIPAssayConfig","title":"seqnado.config.ChIPAssayConfig","text":"<p>               Bases: <code>BaseAssayConfig</code>, <code>PeakCallingMixin</code></p> <p>Configuration specific to ChIP-seq assays.</p>"},{"location":"api/config/#seqnado.config.RNAAssayConfig","title":"seqnado.config.RNAAssayConfig","text":"<p>               Bases: <code>BaseAssayConfig</code></p> <p>Configuration specific to RNA-seq assays.</p>"},{"location":"api/core/","title":"Core Types API","text":"<p>This module contains the core enumerations and basic data models used throughout SeqNado.</p> <p>\u2190 Back to API Overview</p>"},{"location":"api/core/#seqnado.core","title":"seqnado.core","text":""},{"location":"api/core/#seqnado.core.Assay","title":"Assay","text":"<p>               Bases: <code>Enum</code></p> <p>Supported sequencing assay types.</p>"},{"location":"api/core/#seqnado.core.Assay.clean_name","title":"clean_name  <code>property</code>","text":"<pre><code>clean_name\n</code></pre> <p>Return a short name for the assay.</p>"},{"location":"api/core/#seqnado.core.Assay.all_assays","title":"all_assays  <code>classmethod</code>","text":"<pre><code>all_assays()\n</code></pre> <p>Return all supported assays.</p> Source code in <code>seqnado/core.py</code> <pre><code>@classmethod\ndef all_assays(cls):\n    \"\"\"Return all supported assays.\"\"\"\n    return list(cls)\n</code></pre>"},{"location":"api/core/#seqnado.core.Assay.from_clean_name","title":"from_clean_name  <code>classmethod</code>","text":"<pre><code>from_clean_name(clean_name)\n</code></pre> <p>Return the assay type from a short name.</p> Source code in <code>seqnado/core.py</code> <pre><code>@classmethod\ndef from_clean_name(cls, clean_name):\n    \"\"\"Return the assay type from a short name.\"\"\"\n    for assay in cls:\n        if assay.clean_name == clean_name:\n            return assay\n    raise ValueError(f\"Unknown clean name: {clean_name}\")\n</code></pre>"},{"location":"api/core/#seqnado.core.Assay.all_assay_clean_names","title":"all_assay_clean_names  <code>classmethod</code>","text":"<pre><code>all_assay_clean_names()\n</code></pre> <p>Return a list of all clean names for assays.</p> Source code in <code>seqnado/core.py</code> <pre><code>@classmethod\ndef all_assay_clean_names(cls):\n    \"\"\"Return a list of all clean names for assays.\"\"\"\n    return [assay.clean_name for assay in cls]\n</code></pre>"},{"location":"api/core/#seqnado.core.Assay.non_multiomics_assays","title":"non_multiomics_assays  <code>classmethod</code>","text":"<pre><code>non_multiomics_assays()\n</code></pre> <p>Return assays that are not multiomics.</p> Source code in <code>seqnado/core.py</code> <pre><code>@classmethod\ndef non_multiomics_assays(cls):\n    \"\"\"Return assays that are not multiomics.\"\"\"\n    return [assay for assay in cls if assay != cls.MULTIOMICS]\n</code></pre>"},{"location":"api/core/#seqnado.core.Assay.non_ip_assays","title":"non_ip_assays  <code>classmethod</code>","text":"<pre><code>non_ip_assays()\n</code></pre> <p>Return assays that don't require IP (immunoprecipitation).</p> Source code in <code>seqnado/core.py</code> <pre><code>@classmethod\ndef non_ip_assays(cls):\n    \"\"\"Return assays that don't require IP (immunoprecipitation).\"\"\"\n    ip_assays = {cls.CHIP, cls.CAT}\n    return [assay for assay in cls if assay not in ip_assays]\n</code></pre>"},{"location":"api/core/#seqnado.core.Assay.ip_assays","title":"ip_assays  <code>classmethod</code>","text":"<pre><code>ip_assays()\n</code></pre> <p>Return assays that require IP (immunoprecipitation).</p> Source code in <code>seqnado/core.py</code> <pre><code>@classmethod\ndef ip_assays(cls):\n    \"\"\"Return assays that require IP (immunoprecipitation).\"\"\"\n    return [cls.CHIP, cls.CAT]\n</code></pre>"},{"location":"api/core/#seqnado.core.FileType","title":"FileType","text":"<p>               Bases: <code>Enum</code></p> <p>Supported file types.</p>"},{"location":"api/core/#seqnado.core.PileupMethod","title":"PileupMethod","text":"<p>               Bases: <code>Enum</code></p> <p>Methods for creating pileup files.</p>"},{"location":"api/core/#seqnado.core.DataScalingTechnique","title":"DataScalingTechnique","text":"<p>               Bases: <code>Enum</code></p> <p>Methods for scaling genomic data.</p>"},{"location":"api/core/#seqnado.core.PeakCallingMethod","title":"PeakCallingMethod","text":"<p>               Bases: <code>Enum</code></p> <p>Methods for calling peaks.</p>"},{"location":"api/core/#seqnado.core.MotifMethod","title":"MotifMethod","text":"<p>               Bases: <code>Enum</code></p> <p>Methods for motif analysis.</p>"},{"location":"api/core/#seqnado.core.PCRDuplicateHandling","title":"PCRDuplicateHandling","text":"<p>               Bases: <code>Enum</code></p> <p>Methods for handling PCR duplicates.</p>"},{"location":"api/core/#seqnado.core.SpikeInMethod","title":"SpikeInMethod","text":"<p>               Bases: <code>Enum</code></p> <p>Methods for spike-in normalization.</p>"},{"location":"api/core/#seqnado.core.SNPCallingMethod","title":"SNPCallingMethod","text":"<p>               Bases: <code>Enum</code></p> <p>Methods for SNP calling.</p>"},{"location":"api/core/#seqnado.core.QuantificationMethod","title":"QuantificationMethod","text":"<p>               Bases: <code>Enum</code></p> <p>Methods for quantification.</p>"},{"location":"api/core/#seqnado.core.MethylationMethod","title":"MethylationMethod","text":"<p>               Bases: <code>Enum</code></p> <p>Methods for methylation calling.</p>"},{"location":"api/core/#seqnado.core.Organism","title":"Organism","text":"<p>               Bases: <code>Enum</code></p> <p>Supported organisms.</p>"},{"location":"api/core/#seqnado.core.LibraryType","title":"LibraryType","text":"<p>               Bases: <code>Enum</code></p> <p>Supported library types.</p>"},{"location":"api/core/#seqnado.core.GenomicCoordinate","title":"GenomicCoordinate","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for genomic coordinates.</p>"},{"location":"api/core/#seqnado.core.GenomicCoordinate.from_string","title":"from_string  <code>classmethod</code>","text":"<pre><code>from_string(coord_str: str) -&gt; GenomicCoordinate\n</code></pre> <p>Create a GenomicCoordinate instance from a string representation.</p> Source code in <code>seqnado/core.py</code> <pre><code>@classmethod\ndef from_string(cls, coord_str: str) -&gt; \"GenomicCoordinate\":\n    \"\"\"\n    Create a GenomicCoordinate instance from a string representation.\n    \"\"\"\n    chromosome, positions = coord_str.split(\":\")\n    start, end = map(int, positions.split(\"-\"))\n    return cls(chromosome=chromosome, start=start, end=end)\n</code></pre>"},{"location":"api/inputs/","title":"Inputs API","text":"<p>This module handles the discovery and validation of input sequencing files.</p> <p>\u2190 Back to API Overview</p>"},{"location":"api/inputs/#seqnado.inputs.Metadata","title":"seqnado.inputs.Metadata","text":"<p>               Bases: <code>BaseModel</code></p> <p>Metadata for samples. Optional fields can be set to None.</p>"},{"location":"api/inputs/#seqnado.inputs.Metadata.set_mcc_defaults","title":"set_mcc_defaults","text":"<pre><code>set_mcc_defaults() -&gt; Self\n</code></pre> <p>Set default consensus_group for MCC assay.</p> Source code in <code>seqnado/inputs/core.py</code> <pre><code>@model_validator(mode='after')\ndef set_mcc_defaults(self) -&gt; Self:\n    \"\"\"Set default consensus_group for MCC assay.\"\"\"\n    if self.assay == Assay.MCC and self.consensus_group is None:\n        self.consensus_group = 'default'\n    return self\n</code></pre>"},{"location":"api/inputs/#seqnado.inputs.FastqCollection","title":"seqnado.inputs.FastqCollection","text":"<p>               Bases: <code>BaseFastqCollection</code></p> <p>Represents a collection of sequencing samples (FASTQ files) grouped into named sets, with optional per-sample metadata.</p> <p>Attributes:</p> Name Type Description <code>fastq_sets</code> <code>list[FastqSet]</code> <p>List of FastqSet objects (paired or single-end samples).</p> <code>metadata</code> <code>list[Metadata]</code> <p>List of Metadata objects corresponding one-to-one with fastq_sets.</p>"},{"location":"api/inputs/#seqnado.inputs.FastqCollection.sample_ids","title":"sample_ids  <code>property</code>","text":"<pre><code>sample_ids: list[str]\n</code></pre> <p>Returns all sample IDs in the design.</p>"},{"location":"api/inputs/#seqnado.inputs.FastqCollection.sample_names","title":"sample_names  <code>property</code>","text":"<pre><code>sample_names: list[str]\n</code></pre> <p>Returns all sample names in the design.</p>"},{"location":"api/inputs/#seqnado.inputs.FastqCollection.fastq_paths","title":"fastq_paths  <code>property</code>","text":"<pre><code>fastq_paths: list[Path]\n</code></pre> <p>Flattens all R1/R2 file paths into a single list.</p>"},{"location":"api/inputs/#seqnado.inputs.FastqCollection.fastq_pairs","title":"fastq_pairs  <code>property</code>","text":"<pre><code>fastq_pairs: dict[str, list[Path]]\n</code></pre> <p>Returns a dictionary mapping sample names to their FASTQ file paths.</p>"},{"location":"api/inputs/#seqnado.inputs.FastqCollection.validate_non_ip_assay","title":"validate_non_ip_assay  <code>classmethod</code>","text":"<pre><code>validate_non_ip_assay(v: Assay) -&gt; Assay\n</code></pre> <p>Ensure the assay doesn't require IP (immunoprecipitation).</p> Source code in <code>seqnado/inputs/fastq.py</code> <pre><code>@field_validator(\"assay\")\n@classmethod\ndef validate_non_ip_assay(cls, v: Assay) -&gt; Assay:\n    \"\"\"Ensure the assay doesn't require IP (immunoprecipitation).\"\"\"\n    if v in Assay.ip_assays():\n        raise ValueError(\n            f\"Assay '{v.value}' requires IP and should use IPSampleCollection instead\"\n        )\n    return v\n</code></pre>"},{"location":"api/inputs/#seqnado.inputs.FastqCollection.query","title":"query","text":"<pre><code>query(sample_name: str) -&gt; FastqSet\n</code></pre> <p>Retrieve the FastqSet by its sample name.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If sample_name not found.</p> Source code in <code>seqnado/inputs/fastq.py</code> <pre><code>def query(self, sample_name: str) -&gt; FastqSet:\n    \"\"\"\n    Retrieve the FastqSet by its sample name.\n\n    Raises:\n        ValueError: If sample_name not found.\n    \"\"\"\n    try:\n        return next(fs for fs in self.fastq_sets if fs.sample_id == sample_name)\n    except StopIteration:\n        raise ValueError(f\"Sample '{sample_name}' not found in SampleCollection\")\n</code></pre>"},{"location":"api/inputs/#seqnado.inputs.FastqCollection.is_paired_end","title":"is_paired_end","text":"<pre><code>is_paired_end(uid: str) -&gt; bool\n</code></pre> <p>Check if the given sample ID is paired-end.</p> Source code in <code>seqnado/inputs/fastq.py</code> <pre><code>def is_paired_end(self, uid: str) -&gt; bool:\n    \"\"\"\n    Check if the given sample ID is paired-end.\n    \"\"\"\n    return self.to_dataframe().loc[uid, \"r2\"] is not None\n</code></pre>"},{"location":"api/inputs/#seqnado.inputs.FastqCollection.from_fastq_files","title":"from_fastq_files  <code>classmethod</code>","text":"<pre><code>from_fastq_files(\n    assay: Assay,\n    files: Iterable[str | Path],\n    metadata: (\n        Callable[[str], Metadata] | Metadata | None\n    ) = None,\n    **fastqset_kwargs: Any\n) -&gt; FastqCollection\n</code></pre> <p>Build a SampleCollection by scanning a list of FASTQ paths:</p> <ol> <li>Convert raw paths to FastqFile.</li> <li>Group by <code>sample_base</code> and sort by read_number.</li> <li>Create FastqSet (single- or paired-end) for each sample.</li> <li>Generate Metadata via <code>metadata(sample_name)</code>, or default.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>files</code> <code>Iterable[str | Path]</code> <p>Iterable of file paths (strings or Path).</p> required <code>metadata</code> <code>Callable[[str], Metadata] | Metadata | None</code> <ul> <li>Callable(sample_name) \u2192 Metadata to customize per-sample metadata.</li> <li>Single Metadata instance applied to all.</li> <li>None \u2192 defaults to Metadata().</li> </ul> <code>None</code> <code>fastqset_kwargs</code> <code>Any</code> <p>Extra fields forwarded to FastqSet constructor.</p> <code>{}</code> Source code in <code>seqnado/inputs/fastq.py</code> <pre><code>@classmethod\ndef from_fastq_files(\n    cls,\n    assay: Assay,\n    files: Iterable[str | Path],\n    metadata: Callable[[str], Metadata] | Metadata | None = None,\n    **fastqset_kwargs: Any,\n) -&gt; FastqCollection:\n    \"\"\"\n    Build a SampleCollection by scanning a list of FASTQ paths:\n\n    1. Convert raw paths to FastqFile.\n    2. Group by `sample_base` and sort by read_number.\n    3. Create FastqSet (single- or paired-end) for each sample.\n    4. Generate Metadata via `metadata(sample_name)`, or default.\n\n    Args:\n        files: Iterable of file paths (strings or Path).\n        metadata:\n            - Callable(sample_name) \u2192 Metadata to customize per-sample metadata.\n            - Single Metadata instance applied to all.\n            - None \u2192 defaults to Metadata().\n        fastqset_kwargs: Extra fields forwarded to FastqSet constructor.\n    \"\"\"\n    # Convert and sort\n    fq_files = [FastqFile(path=Path(f)) for f in files]\n    fq_files.sort(key=lambda x: (x.sample_base, x.read_number))\n\n    # Group by sample_stem\n    groups: dict[str, list[FastqFile]] = defaultdict(list)\n    for fq in fq_files:\n        groups[fq.sample_base].append(fq)\n\n    _fastq_sets: list[FastqSet] = []\n    _metadata: list[Metadata] = []\n    for sample, fqs in groups.items():\n        # Build FastqSet\n        if len(fqs) == 1:\n            fs = FastqSet(sample_id=sample, r1=fqs[0], **fastqset_kwargs)\n        elif len(fqs) == 2:\n            fs = FastqSet(sample_id=sample, r1=fqs[0], r2=fqs[1], **fastqset_kwargs)\n        else:\n            raise ValueError(\n                f\"Unexpected number of FASTQ files for '{sample}': {len(fqs)}\"\n            )\n        _fastq_sets.append(fs)\n\n        # Build Metadata using base class method\n        _metadata.append(cls._build_metadata(sample, metadata, assay))\n\n    return cls(assay=assay, fastq_sets=_fastq_sets, metadata=_metadata)\n</code></pre>"},{"location":"api/inputs/#seqnado.inputs.FastqCollection.from_directory","title":"from_directory  <code>classmethod</code>","text":"<pre><code>from_directory(\n    assay: Assay,\n    directory: str | Path,\n    glob_patterns: Iterable[str] = (\n        \"*.fq\",\n        \"*.fq.gz\",\n        \"*.fastq\",\n        \"*.fastq.gz\",\n    ),\n    metadata: (\n        Callable[[str], Metadata] | Metadata | None\n    ) = None,\n    **kwargs: Any\n) -&gt; FastqCollection\n</code></pre> <p>Recursively scan a directory for FASTQ files and build a SampleCollection.</p> <p>Parameters:</p> Name Type Description Default <code>directory</code> <code>str | Path</code> <p>Root path to search.</p> required <code>glob_patterns</code> <code>Iterable[str]</code> <p>Filename patterns to include.</p> <code>('*.fq', '*.fq.gz', '*.fastq', '*.fastq.gz')</code> <code>metadata</code> <code>Callable[[str], Metadata] | Metadata | None</code> <p>Callable(sample_name) \u2192 Metadata or single Metadata instance.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Extra fields converted directly to a shared Metadata.</p> <code>{}</code> Source code in <code>seqnado/inputs/fastq.py</code> <pre><code>@classmethod\ndef from_directory(\n    cls,\n    assay: Assay,\n    directory: str | Path,\n    glob_patterns: Iterable[str] = (\"*.fq\", \"*.fq.gz\", \"*.fastq\", \"*.fastq.gz\"),\n    metadata: Callable[[str], Metadata] | Metadata | None = None,\n    **kwargs: Any,\n) -&gt; FastqCollection:\n    \"\"\"\n    Recursively scan a directory for FASTQ files and build a SampleCollection.\n\n    Args:\n        directory: Root path to search.\n        glob_patterns: Filename patterns to include.\n        metadata: Callable(sample_name) \u2192 Metadata or single Metadata instance.\n        **kwargs: Extra fields converted directly to a shared Metadata.\n    \"\"\"\n    files = cls._discover_files(directory, glob_patterns)\n    metadata = cls._prepare_metadata_for_directory(metadata, **kwargs)\n    return cls.from_fastq_files(assay=assay, files=files, metadata=metadata)\n</code></pre>"},{"location":"api/inputs/#seqnado.inputs.FastqCollection.to_dataframe","title":"to_dataframe","text":"<pre><code>to_dataframe(validate: bool = True) -&gt; pd.DataFrame\n</code></pre> <p>Export the design to a pandas DataFrame, validated by DataFrameDesign.</p> <p>Columns: sample_name, r1, r2, plus all metadata fields.</p> Source code in <code>seqnado/inputs/fastq.py</code> <pre><code>def to_dataframe(self, validate: bool = True) -&gt; pd.DataFrame:\n    \"\"\"\n    Export the design to a pandas DataFrame, validated by DataFrameDesign.\n\n    Columns: sample_name, r1, r2, plus all metadata fields.\n    \"\"\"\n    import pandas as pd\n\n    rows: list[dict[str, Any]] = []\n\n    if self.metadata:\n        for fs, md in zip(self.fastq_sets, self.metadata):\n            row: dict[str, Any] = {\n                \"sample_id\": fs.sample_id,\n                \"r1\": fs.r1.path,\n                \"r2\": fs.r2.path if fs.r2 else None,\n                \"uid\": f\"{fs.sample_id}\",\n            }\n            metadata_dict = md.model_dump(exclude_none=True)\n            # Convert Assay enum to string value for schema validation\n            if \"assay\" in metadata_dict and hasattr(metadata_dict[\"assay\"], \"value\"):\n                metadata_dict[\"assay\"] = metadata_dict[\"assay\"].value\n            row.update(metadata_dict)\n            rows.append(row)\n    else:\n        for fs in self.fastq_sets:\n            row = {\n                \"sample_id\": fs.sample_id,\n                \"r1\": fs.r1.path,\n                \"r2\": fs.r2.path if fs.r2 else None,\n                \"uid\": f\"{fs.sample_id}\",\n            }\n            rows.append(row)\n\n    if not rows:\n        # Return empty DataFrame with expected columns\n        df = pd.DataFrame(columns=[\"sample_id\", \"r1\", \"r2\", \"uid\"]).set_index(\"uid\")\n    else:\n        df = pd.DataFrame(rows).sort_values(\"sample_id\").set_index(\"uid\")\n\n    # Define column order: critical columns first (assay, sample info, files), then other metadata\n    core_cols = [\"assay\", \"sample_id\", \"r1\", \"r2\"]\n    metadata_cols = [col for col in df.columns if col not in core_cols]\n    ordered_cols = core_cols + sorted(metadata_cols)\n    df = df[[col for col in ordered_cols if col in df.columns]]\n\n    if validate:\n        return DataFrame[DesignDataFrame](df)\n    else:\n        return df\n</code></pre>"},{"location":"api/inputs/#seqnado.inputs.FastqCollection.from_dataframe","title":"from_dataframe  <code>classmethod</code>","text":"<pre><code>from_dataframe(\n    assay: Assay,\n    df: DataFrame,\n    validate_deseq2: bool = False,\n    assay_for_validation: Assay | None = None,\n    **fastqset_kwargs: Any\n) -&gt; FastqCollection\n</code></pre> <p>Build a SampleCollection from a DataFrame, validated by DataFrameDesign.</p> <p>Expects columns: sample_name, r1, r2, plus any metadata fields.</p> <p>Parameters:</p> Name Type Description Default <code>assay</code> <code>Assay</code> <p>The assay type</p> required <code>df</code> <code>DataFrame</code> <p>DataFrame with sample metadata</p> required <code>validate_deseq2</code> <code>bool</code> <p>If True, require deseq2 field to be non-null (for RNA assays)</p> <code>False</code> <code>assay_for_validation</code> <code>Assay | None</code> <p>Assay type to check in validation context</p> <code>None</code> <code>**fastqset_kwargs</code> <code>Any</code> <p>Additional kwargs for FastqSet</p> <code>{}</code> Source code in <code>seqnado/inputs/fastq.py</code> <pre><code>@classmethod\ndef from_dataframe(\n    cls, assay: Assay, df: pd.DataFrame, validate_deseq2: bool = False, assay_for_validation: Assay | None = None, **fastqset_kwargs: Any\n) -&gt; FastqCollection:\n    \"\"\"\n    Build a SampleCollection from a DataFrame, validated by DataFrameDesign.\n\n    Expects columns: sample_name, r1, r2, plus any metadata fields.\n\n    Args:\n        assay: The assay type\n        df: DataFrame with sample metadata\n        validate_deseq2: If True, require deseq2 field to be non-null (for RNA assays)\n        assay_for_validation: Assay type to check in validation context\n        **fastqset_kwargs: Additional kwargs for FastqSet\n    \"\"\"\n    df = DesignDataFrame.validate(df)\n    fastq_sets: list[FastqSet] = []\n    metadata: list[Metadata] = []\n    metadata_fields = set(Metadata.model_fields.keys())\n\n    # Use provided assay_for_validation or fall back to assay\n    validation_assay = assay_for_validation or assay\n\n    for rec in df.to_dict(orient=\"records\"):\n        # Build FastqSet\n        r2_path = rec.get(\"r2\")\n        fs = FastqSet(\n            sample_id=rec[\"sample_id\"],\n            r1=FastqFile(path=rec[\"r1\"]),\n            r2=FastqFile(path=r2_path) if pd.notna(r2_path) else None,\n            **fastqset_kwargs,\n        )\n        fastq_sets.append(fs)\n\n        # Collect metadata with validation context\n        meta_fields = {k: rec.get(k) for k in metadata_fields if k in rec}\n        metadata.append(Metadata.model_validate(meta_fields, context={'validate_deseq2': validate_deseq2, 'assay': validation_assay}))\n\n    return cls(assay=assay, fastq_sets=fastq_sets, metadata=metadata)\n</code></pre>"},{"location":"api/inputs/#seqnado.inputs.BamCollection","title":"seqnado.inputs.BamCollection","text":"<p>               Bases: <code>BaseCollection</code></p> <p>Collection of BAM files with optional per-sample metadata.</p> <p>Provides convenience constructors analogous to <code>SampleCollection</code> but without paired-end logic.</p>"},{"location":"api/inputs/#seqnado.inputs.BamCollection.from_dataframe","title":"from_dataframe  <code>classmethod</code>","text":"<pre><code>from_dataframe(\n    assay: Assay,\n    df: Any,\n    validate_deseq2: bool = False,\n    assay_for_validation: Assay | None = None,\n    **kwargs: Any\n) -&gt; BamCollection\n</code></pre> <p>Build a BamCollection from a DataFrame.</p> <p>Expects columns: sample_id, bam, plus any metadata fields.</p> <p>Parameters:</p> Name Type Description Default <code>assay</code> <code>Assay</code> <p>The assay type</p> required <code>df</code> <code>Any</code> <p>DataFrame with sample metadata</p> required <code>validate_deseq2</code> <code>bool</code> <p>If True, require deseq2 field to be non-null (for RNA assays)</p> <code>False</code> <code>assay_for_validation</code> <code>Assay | None</code> <p>Assay type to check in validation context</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional kwargs</p> <code>{}</code> Source code in <code>seqnado/inputs/bam.py</code> <pre><code>@classmethod\ndef from_dataframe(\n    cls, assay: Assay, df: Any, validate_deseq2: bool = False, assay_for_validation: Assay | None = None, **kwargs: Any\n) -&gt; BamCollection:\n    \"\"\"Build a BamCollection from a DataFrame.\n\n    Expects columns: sample_id, bam, plus any metadata fields.\n\n    Args:\n        assay: The assay type\n        df: DataFrame with sample metadata\n        validate_deseq2: If True, require deseq2 field to be non-null (for RNA assays)\n        assay_for_validation: Assay type to check in validation context\n        **kwargs: Additional kwargs\n    \"\"\"\n    import pandas as pd\n\n    bam_files: list[BamFile] = []\n    metadata: list[Metadata] = []\n    metadata_fields = set(Metadata.model_fields.keys())\n\n    # Use provided assay_for_validation or fall back to assay\n    validation_assay = assay_for_validation or assay\n\n    for rec in df.to_dict(orient=\"records\"):\n        # Build BamFile\n        bam_files.append(BamFile(path=Path(rec[\"bam\"])))\n\n        # Collect metadata with validation context\n        meta_fields = {k: rec.get(k) for k in metadata_fields if k in rec}\n        metadata.append(Metadata.model_validate(meta_fields, context={'validate_deseq2': validate_deseq2, 'assay': validation_assay}))\n\n    return cls(assay=assay, bam_files=bam_files, metadata=metadata)\n</code></pre>"},{"location":"api/outputs/","title":"Outputs API","text":"<p>This module manages the file structure and tracking of Snakemake workflow outputs.</p> <p>\u2190 Back to API Overview</p>"},{"location":"api/outputs/#seqnado.outputs.SeqnadoOutputFiles","title":"seqnado.outputs.SeqnadoOutputFiles","text":"<p>               Bases: <code>BaseModel</code></p> <p>Collection of output files generated by SeqNado.</p>"},{"location":"api/outputs/#seqnado.outputs.SeqnadoOutputFiles.all_files","title":"all_files  <code>property</code>","text":"<pre><code>all_files: List[str]\n</code></pre> <p>Return all files in the output collection.</p>"},{"location":"api/outputs/#seqnado.outputs.SeqnadoOutputFiles.has_consensus_peaks","title":"has_consensus_peaks  <code>property</code>","text":"<pre><code>has_consensus_peaks\n</code></pre> <p>Check if consensus peaks are present in the output files.</p>"},{"location":"api/outputs/#seqnado.outputs.SeqnadoOutputFiles.select_files","title":"select_files","text":"<pre><code>select_files(\n    suffix: str,\n    include: str | None = None,\n    exclude: str | None = None,\n    must_include_all_patterns: bool = False,\n    use_regex: bool = False,\n    case_sensitive: bool = False,\n) -&gt; List[str]\n</code></pre> <p>Filter files by suffix and optional substring.</p> <p>Parameters:</p> Name Type Description Default <code>suffix</code> <code>str</code> <p>The file suffix to filter by (e.g. \".txt\" or \"csv\").</p> required <code>include</code> <code>str</code> <p>Substring or regex pattern that must be present in the file path.</p> <code>None</code> <code>exclude</code> <code>str</code> <p>Substring or regex pattern that must NOT be present in the file path.</p> <code>None</code> <code>must_include_all_patterns</code> <code>bool</code> <p>If True, all include patterns must match (AND). If False, any match suffices (OR).</p> <code>False</code> <code>use_regex</code> <code>bool</code> <p>If True, treat include/exclude as regex patterns.</p> <code>False</code> <code>case_sensitive</code> <code>bool</code> <p>If True, matching is case-sensitive.</p> <code>False</code> <p>Returns:     List[str]: A list of file paths matching the criteria.</p> Source code in <code>seqnado/outputs/core.py</code> <pre><code>def select_files(\n    self,\n    suffix: str,\n    include: str | None = None,\n    exclude: str | None = None,\n    must_include_all_patterns: bool = False,\n    use_regex: bool = False,\n    case_sensitive: bool = False,\n) -&gt; List[str]:\n    \"\"\"Filter files by suffix and optional substring.\n\n    Args:\n        suffix (str): The file suffix to filter by (e.g. \".txt\" or \"csv\").\n        include (str, optional): Substring or regex pattern that must be present in the file path.\n        exclude (str, optional): Substring or regex pattern that must NOT be present in the file path.\n        must_include_all_patterns (bool): If True, all include patterns must match (AND). If False, any match suffices (OR).\n        use_regex (bool): If True, treat include/exclude as regex patterns.\n        case_sensitive (bool): If True, matching is case-sensitive.\n    Returns:\n        List[str]: A list of file paths matching the criteria.\n    \"\"\"\n    fs = FileSelector(self.files)\n    return fs.select(\n        suffix=suffix,\n        includes=include,\n        excludes=exclude,\n        case_sensitive=case_sensitive,\n        use_regex=use_regex,\n        includes_all=must_include_all_patterns,\n    )\n</code></pre>"},{"location":"api/outputs/#seqnado.outputs.SeqnadoOutputFiles.select_bigwig_subtype","title":"select_bigwig_subtype","text":"<pre><code>select_bigwig_subtype(\n    method: PileupMethod = PileupMethod.DEEPTOOLS,\n    scale: DataScalingTechnique = DataScalingTechnique.UNSCALED,\n    spikein_method: str | None = None,\n    assay: Assay | None = None,\n    is_merged: bool = False,\n    ip_only: bool = False,\n)\n</code></pre> <p>Select bigWig files of a specific subtype.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>PileupMethod</code> <p>The pileup method to filter by.</p> <code>DEEPTOOLS</code> <code>scale</code> <code>DataScalingTechnique</code> <p>The scale method to filter by.</p> <code>UNSCALED</code> <code>spikein_method</code> <code>str</code> <p>The spike-in method to filter by orlando or with_input. Defaults to None. </p> <code>None</code> <code>assay</code> <code>Assay</code> <p>The assay type to filter by. Defaults to None.</p> <code>None</code> <code>is_merged</code> <code>bool</code> <p>If True, select merged (consensus) bigWigs only.</p> <code>False</code> <code>ip_only</code> <code>bool</code> <p>If True, exclude control/input samples (requires ip_sample_names to be set).</p> <code>False</code> <p>Returns:</p> Type Description <p>List[str]: A list of bigWig files matching the specified subtype.</p> Source code in <code>seqnado/outputs/core.py</code> <pre><code>def select_bigwig_subtype(\n    self,\n    method: PileupMethod = PileupMethod.DEEPTOOLS,\n    scale: DataScalingTechnique = DataScalingTechnique.UNSCALED,\n    spikein_method: str | None = None,\n    assay: Assay | None = None,\n    is_merged: bool = False,\n    ip_only: bool = False,\n):\n    \"\"\"Select bigWig files of a specific subtype.\n\n    Args:\n        method (PileupMethod): The pileup method to filter by.\n        scale (DataScalingTechnique): The scale method to filter by.\n        spikein_method (str, optional): The spike-in method to filter by orlando or with_input. Defaults to None. \n        assay (Assay, optional): The assay type to filter by. Defaults to None.\n        is_merged (bool): If True, select merged (consensus) bigWigs only.\n        ip_only (bool): If True, exclude control/input samples (requires ip_sample_names to be set).\n\n    Returns:\n        List[str]: A list of bigWig files matching the specified subtype.\n    \"\"\"\n    includes = [method.value, scale.value]\n    if is_merged:\n        includes.append(\"merged\")\n    if spikein_method is not None:\n        includes.append(spikein_method)\n    if assay is not None:\n        includes.append(assay.value.lower())\n\n    results = self.select_files(\n        \".bigWig\",\n        include=includes,\n        exclude=\"/geo_submission/\",\n        must_include_all_patterns=True,\n        case_sensitive=False,\n    )\n    # Separate individual from merged: both paths contain the scale string,\n    # so filter explicitly on the presence/absence of \"/merged/\".\n    if is_merged:\n        results = [f for f in results if \"/merged/\" in f]\n    else:\n        results = [f for f in results if \"/merged/\" not in f]\n\n    # Optionally filter to IP samples only (exclude control/input samples)\n    if ip_only and self.ip_sample_names:\n        ip_set = set(self.ip_sample_names)\n        results = [f for f in results if Path(f).stem in ip_set]\n\n    return results\n</code></pre>"},{"location":"api/outputs/#seqnado.outputs.SeqnadoOutputFiles.select_heatmap_matrix","title":"select_heatmap_matrix","text":"<pre><code>select_heatmap_matrix(\n    scale: DataScalingTechnique,\n    method: PileupMethod = PileupMethod.DEEPTOOLS,\n    is_merged: bool = False,\n    spikein_method: str | None = None,\n) -&gt; str\n</code></pre> <p>Return the matrix path (temp file, not in self.files).</p> Source code in <code>seqnado/outputs/core.py</code> <pre><code>def select_heatmap_matrix(\n    self,\n    scale: DataScalingTechnique,\n    method: PileupMethod = PileupMethod.DEEPTOOLS,\n    is_merged: bool = False,\n    spikein_method: str | None = None,\n) -&gt; str:\n    \"\"\"Return the matrix path (temp file, not in self.files).\"\"\"\n    return f\"{self._heatmap_dir(scale, method, is_merged, spikein_method)}/matrix.mat.gz\"\n</code></pre>"},{"location":"api/outputs/#seqnado.outputs.SeqnadoOutputFiles.select_genome_browser_plots","title":"select_genome_browser_plots","text":"<pre><code>select_genome_browser_plots(\n    scale: DataScalingTechnique,\n    method: PileupMethod = PileupMethod.DEEPTOOLS,\n    is_merged: bool = False,\n    spikein_method: str | None = None,\n) -&gt; list[str]\n</code></pre> <p>Select genome browser plot files for a specific method/scale/merged combination.</p> <p>When scale is SPIKEIN and spikein_method is provided, only plots for that specific spike-in method are returned.</p> Source code in <code>seqnado/outputs/core.py</code> <pre><code>def select_genome_browser_plots(\n    self,\n    scale: DataScalingTechnique,\n    method: PileupMethod = PileupMethod.DEEPTOOLS,\n    is_merged: bool = False,\n    spikein_method: str | None = None,\n) -&gt; list[str]:\n    \"\"\"Select genome browser plot files for a specific method/scale/merged combination.\n\n    When scale is SPIKEIN and spikein_method is provided, only plots for\n    that specific spike-in method are returned.\n    \"\"\"\n    prefix = \"merged/\" if is_merged else \"\"\n    if scale == DataScalingTechnique.SPIKEIN and spikein_method is not None:\n        target = f\"genome_browser_plots/{prefix}{method.value}/spikein/{spikein_method}/\"\n    else:\n        target = f\"genome_browser_plots/{prefix}{method.value}/{scale.value}/\"\n    return [f for f in self.files if target in f]\n</code></pre>"}]}